<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category label="r/deeplearning" term="deeplearning"></category><updated> 2023-05-29T01:20:45+00:00</updated><icon> https://www.redditstatic.com/icon.png/</icon><id> /r/深度学习/.rss </id><link href="https://www.reddit.com/r/deeplearning/.rss" rel="self" type="application/atom+xml"/><link href="https://www.reddit.com/r/deeplearning/" rel="alternate" type="text/html"/><title>深度学习</title><entry><author><name>/u/神经符号</name><uri>https://www.reddit.com/user/Neurosymbolic</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Neurosymbolic&quot;>; /u/Neurosymbolic &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://youtube.com/watch? v=xjzem-10Two&amp;amp;feature=share&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13uedrg/pt_4_neural_networks_temporal_logic_verification/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13uedrg </id><link href="https://www.reddit.com/r/deeplearning/comments/13uedrg/pt_4_neural_networks_temporal_logic_verification/"/><updated> 2023-05-28T23:25:28+00:00</updated><published> 2023-05-28T23:25:28+00:00</published><title> （第 4 部分）使用 STL Net 的神经网络时间逻辑验证</title></entry><entry><author><name>/u/VonSquiggles</name><uri> https://www.reddit.com/user/VonSquiggles</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我这几天一直在做的事情。出于某种原因，我发现在我的 PC 上对本地模型进行推理很令人满意，这是我想要运行的一个特定应用程序！&lt;/p>; &lt;p>;“这个 repo 旨在将播客作为 youtube 链接，下载 .wav 文件，分解每个演讲者的播客，并通过 huggingface.co 的开源语言模型传递音频和文字记录，以分析演讲者的情绪”&lt;/p>; &lt;/div>;&lt;!-- SC_ON -- >; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/VonSquiggles&quot;>; /u/VonSquiggles &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://github.com/VonSquiggles/ speaker_emotion&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13ty295/podcast_speaker_sentiment_emotion_tool_that_runs/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13ty295 </id><link href="https://www.reddit.com/r/deeplearning/comments/13ty295/podcast_speaker_sentiment_emotion_tool_that_runs/"/><updated> 2023-05-28T11:22:28+00:00</updated><published> 2023-05-28T11:22:28+00:00</published><title>本地运行的 Podcast Speaker Sentiment/Emotion 工具！</title></entry><entry><author><name> /你/AvvYaa</name><uri> https://www.reddit.com/user/AvvYaa</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好！我刚刚在我的 Youtube 上上传了一段视频，涵盖了训练多模态模型的所有主要技术和挑战，这些模型可以结合图像、文本、音频等多种输入源来执行惊人的跨模态任务，如文本图像检索、多模态向量算术、视觉问答和语言建模。 &lt;/p>; &lt;p>;我认为现在是制作有关该主题的视频的好时机，因为越来越多的近期 LLM 正从纯文本转向视觉语言领域（GPT-4、PaLM-2 等） .因此，在视频中，我尽可能多地介绍了这个领域的一些直觉 - 从对比学习（CLIP、ImageBind）等基础知识，一直到生成语言模型（如 Flamingo）。&lt;/p>; &lt;p>; &amp;#x200B;&lt;/p>; &lt;p>;这是视频的链接：&lt;br/>; &lt;a href=&quot;https://youtu.be/-llkMpNH160&quot;>;https://youtu.be/-llkMpNH160 &lt;/a>;&lt;/p>; &lt;p>;如果上述方法不起作用，也许可以试试这个：&lt;/p>; &lt;p>;&lt;a href=&quot;https://m.youtube.com/watch?v=- llkMpNH160&amp;amp;feature=youtu.be&quot;>;https://m.youtube.com/watch?v=-llkMpNH160&amp;amp;feature=youtu.be&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -- >; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/AvvYaa&quot;>; /u/AvvYaa &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/deeplearning/comments/13u6ptq/essentials_of_multimodalvisuallanguage_models_a/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13u6ptq/essentials_of_multimodalvisuallanguage_models_a/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13u6ptq </id><link href="https://www.reddit.com/r/deeplearning/comments/13u6ptq/essentials_of_multimodalvisuallanguage_models_a/"/><updated> 2023-05-28T17:56:31+00:00</updated><published> 2023-05-28T17:56:31+00:00</published><title>多模态/视觉语言模型的要点（视频）</title></entry><entry><author><name> /u/__god_bless_you_</name><uri> https://www.reddit.com/user/__god_bless_you_</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;嘿！&lt;/p>; &lt;p>;只是想与您分享我们即将在社区举办的活动。&lt;/p>; &lt;p>;这周四 13:00 GMT+0（6 月 1 日），我们将主持 Advait Bhat 的演讲，他是来自 Microsoft 的杰出人才。他将探讨这个话题——“法学硕士如何改变我们的思维和行为方式”。澄清一下——这些活动对所有人开放，你不必加入我们的社区就可以参与 =)&lt;/p >; &lt;p>;如果您有兴趣，请在下方发表评论，我会将链接私信给您（我尝试发布链接，但模组已自动将其删除...）&lt;/p>; &lt;p>;干杯！&lt;/p>; &lt;/div>;&lt; !-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/__god_bless_you_&quot;>; /u/__god_bless_you_ &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/deeplearning/comments/13u467p/live_event_on_the_dangers_of_llms_with_a_fellow/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13u467p/live_event_on_the_dangers_of_llms_with_a_fellow/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13u467p </id><link href="https://www.reddit.com/r/deeplearning/comments/13u467p/live_event_on_the_dangers_of_llms_with_a_fellow/"/><updated> 2023-05-28T16:11:12+00:00</updated><published> 2023-05-28T16:11:12+00:00</published><title>与研究员@Microsoft 一起现场直播 LLM 的危险</title></entry><entry><author><name>/u/普通艺术家</name><uri>https://www.reddit.com/user/oridnary_artist</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/oridnary_artist&quot;>; /u/oridnary_artist &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.youtube.com/ watch?v=ZQpKY6oow4o&amp;amp;t=90s&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13ttu0e/mov2mov_a_new_video2video_extension_in_stable/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13ttu0e </id><link href="https://www.reddit.com/r/deeplearning/comments/13ttu0e/mov2mov_a_new_video2video_extension_in_stable/"/><updated> 2023-05-28T07:04:12+00:00</updated><published> 2023-05-28T07:04:12+00:00</published><title> Mov2Mov：稳定扩散中的新 Video2Video 扩展</title></entry><entry><author><name>/u/奥扎达尔</name><uri>https://www.reddit.com/user/Ortzadar</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;在涉及公司多年历史数据的深度学习项目（或任何项目）中（假设 8过去几年），如果我们想建立一个预测模型，我们是否应该使用 COVID 时代的数据，即使它代表了一种不太可能重复的异常现象？&lt;/p>; &lt;p>;我考虑过合并这个数据，但赋予它的权重低于其他数据，尽管我对这种方法并不完全满意。&lt;/p>; &lt;p>;在这种情况下你会怎么做？&lt;/p>; &lt;/div>;&lt;!- - SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Ortzadar&quot;>; /u/Ortzadar &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/deeplearning/comments/13teyi2/should_i_include_data_from_the_covid_era/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13teyi2/should_i_include_data_from_the_covid_era/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13teyi2 </id><link href="https://www.reddit.com/r/deeplearning/comments/13teyi2/should_i_include_data_from_the_covid_era/"/><updated> 2023-05-27T18:44:38+00:00</updated><published> 2023-05-27T18:44:38+00:00</published><title>我应该包括 covid 时代的数据吗？</title></entry><entry><author><name> /u/V1自行车</name><uri>https://www.reddit.com/user/V1bicycle</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;当谈到“梯度流”的概念时，找到一个广泛认可且定义明确的资源来提供全面的解释可能具有挑战性。虽然许多搜索结果包括来自机器学习专家的见解或对涉及梯度流的论文的引用，但没有一个单一的、权威的来源广泛深入研究该主题。&lt;/p>; &lt;p>;是否有可用的推荐资源可以提供对梯度流的详细了解？感谢您的帮助。谢谢。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/V1bicycle&quot;>; /u/V1bicycle &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/deeplearning/comments/13tf2tz/understanding_the_concept_of_gradient_flow/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13tf2tz/understanding_the_concept_of_gradient_flow/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13tf2tz </id><link href="https://www.reddit.com/r/deeplearning/comments/13tf2tz/understanding_the_concept_of_gradient_flow/"/><updated> 2023-05-27T18:49:52+00:00</updated><published> 2023-05-27T18:49:52+00:00</published><title>理解梯度流的概念</title></entry><entry><author><name>/u/OnlyProggingForFun</name><uri> https://www.reddit.com/user/OnlyProggingForFun</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/OnlyProggingForFun&quot;>; /u/OnlyProggingForFun &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://youtu.be/r1mh- IqBEjg&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13t63l3/transform_any_image_with_a_single_movement_of/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13t63l3 </id><link href="https://www.reddit.com/r/deeplearning/comments/13t63l3/transform_any_image_with_a_single_movement_of/"/><updated> 2023-05-27T12:25:21+00:00</updated><published> 2023-05-27T12:25:21+00:00</published><title>只需移动鼠标即可转换任何图像：DragGan 解释</title></entry><entry><author><name>/u/Dangerous-Soft899</name><uri> https://www.reddit.com/user/Dangerous-Soft899</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我目前正在开发轨道确定软件。一切进行得都很顺利。该软件似乎在我们从客户拥有的卫星中获得的真实数据集上运行良好。然而，由于我们测试软件的数据量很少，我们并不完全确定该软件是否做得很好。我一直在寻找任何类型的开源 GPS 卫星数据，但我找不到。 &lt;/p>; &lt;p>;所以，我想出了这个主意。如何在我们目前拥有的 GPS 数据上训练一个预训练的 GPT，并让模型生成合理的 GPS 数据。&lt;/p>; &lt;p>;我对 LLM 或一般的深度学习并不是很了解。 Generative Pre-trained Transformers 能否生成 GPS 数据？或者你可以训练一个生成 GPS 数据吗？&lt;/p>; &lt;p>;谢谢！&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Dangerous-Soft899&quot;>; /u/Dangerous-Soft899 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www. reddit.com/r/deeplearning/comments/13tg26x/can_gpt_generate_gps_data/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13tg26x/can_gpt_generate_gps_data/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13tg26x </id><link href="https://www.reddit.com/r/deeplearning/comments/13tg26x/can_gpt_generate_gps_data/"/><updated> 2023-05-27T19:32:26+00:00</updated><published> 2023-05-27T19:32:26+00:00</published><title> GPT 可以生成 GPS 数据吗？</title></entry><entry><author><name> /u/The_artist_999</name><uri> https://www.reddit.com/user/The_artist_999</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我有一个包含 3 个类的数据集。第 1 类和第 2 类各有 1500 多个数据，第三类恰好有 1 个数据。可以删除第 3 类吗？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/The_artist_999&quot;>; /u/The_artist_999 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/deeplearning/comments/13taiy7/d_is_it_ok_to_remove_1_class_from_dataset_if_its/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13taiy7/d_is_it_ok_to_remove_1_class_from_dataset_if_its/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13taiy7 </id><link href="https://www.reddit.com/r/deeplearning/comments/13taiy7/d_is_it_ok_to_remove_1_class_from_dataset_if_its/"/><updated> 2023-05-27T15:36:48+00:00</updated><published> 2023-05-27T15:36:48+00:00</published><title> [D] 如果与其他类相比数量非常少，是否可以从数据集中删除 1 个类？</title></entry><entry><author><name> /u/False_Mobile_8823</name><uri> https://www.reddit.com/user/False_Mobile_8823</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我一直在通过我的大学进行无薪实习以获得一些行业准入，我们的小组被分配了一个主题 - 构建一个对话式 AI，它可以使用变压器回答医疗保健问题（变压器必须从头开始构建）。我已尽力了解变压器的工作原理，尽管我对它背后的数学知识仍然有些薄弱，但我对它的工作原理有一个不错的了解。这是我们计划参考的代码链接 - &lt;a href=&quot;https://machinelearningmastery.com/building-transformer-models-with-attention-crash-course-build-a-neural-machine-translator- in-12-days/&quot;>;https://machinelearningmastery.com/building-transformer-models-with-attention-crash-course-build-a-neural-machine-translator-in-12-days/&lt;/a>; &lt;/p>; &lt;p>;我真的不明白如何训练 transformer 进行对话，大多数教程都使用预训练的 transformer 来完成此类任务。我需要一些关于我应该执行哪些步骤的指导，因为我们的行业导师真的很难联系到。任何帮助将非常感激。谢谢 :)&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/False_Mobile_8823&quot;>; /u/False_Mobile_8823 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/deeplearning/comments/13t5bey/need_help_with_a_chatbot_mini_project/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13t5bey/need_help_with_a_chatbot_mini_project/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13t5bey </id><link href="https://www.reddit.com/r/deeplearning/comments/13t5bey/need_help_with_a_chatbot_mini_project/"/><updated> 2023-05-27T11:47:12+00:00</updated><published> 2023-05-27T11:47:12+00:00</published><title>需要聊天机器人迷你项目的帮助</title></entry><entry><author><name>/你/保持冷静</name><uri>https://www.reddit.com/user/keepucalm</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/keepucalm&quot;>; /u/keepucalm &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://medium.com/@helpurself /你探索过胶原蛋白的难以置信的好处-415c8b8ee454&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13tr657/have_you_explored_the_incredible_benefits_of/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13tr657 </id><link href="https://www.reddit.com/r/deeplearning/comments/13tr657/have_you_explored_the_incredible_benefits_of/"/><updated> 2023-05-28T04:19:03+00:00</updated><published> 2023-05-28T04:19:03+00:00</published><title>您是否探索过胶原蛋白的不可思议的好处？</title></entry><entry><author><name> /u/V1自行车</name><uri>https://www.reddit.com/user/V1bicycle</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我发现“梯度范数”没有通用资源和定义明确的定义，大多数搜索结果都是基于 ML 专家提供的答案，其中涉及梯度范数或引用它并提供单个句子介绍的论文。&lt;/p>; &lt;p>;是否有任何明确定义的资源我可以参考以获得对它的具体理解？谢谢&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/V1bicycle&quot;>; /u/V1bicycle &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/deeplearning/comments/13sw02m/what_exactly_is_gradient_norm/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13sw02m/what_exactly_is_gradient_norm/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13sw02m </id><link href="https://www.reddit.com/r/deeplearning/comments/13sw02m/what_exactly_is_gradient_norm/"/><updated> 2023-05-27T02:47:10+00:00</updated><published> 2023-05-27T02:47:10+00:00</published><title> Gradient norm 到底是什么？</title></entry><entry><author><name> /u/公平竞争</name><uri>https://www.reddit.com/user/Play-Equal</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Play-Equal&quot;>; /u/Play-Equal &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://v. redd.it/fvf4ka4qs62b1&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13s8e6h/building_a_3_layered_neural_network_from_scratch/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13s8e6h </id><link href="https://www.reddit.com/r/deeplearning/comments/13s8e6h/building_a_3_layered_neural_network_from_scratch/"/><updated> 2023-05-26T09:35:36+00:00</updated><published> 2023-05-26T09:35:36+00:00</published><title>仅使用 NumPy 从头开始​​构建 3 层神经网络 https://youtu.be/w7Hn3jmbj1A 如需完整视频，请参阅评论部分</title></entry><entry><author><name>/u/CodingButStillAlive</name><uri> https://www.reddit.com/user/CodingButStillAlive</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我在 2018 年底购买了基于 Intel 的 Macbook Pro。专用的 AMD 显卡已经没用了。因此，我正在寻找最便宜的 Apple 硬件来在本地运行一些深度学习 ML 项目（主要是 LLM）。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/CodingButStillAlive&quot;>; /u/CodingButStillAlive &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/deeplearning/comments/13t9kox/what_apple_hardware_do_i_need_for_cudabased_deep/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13t9kox/what_apple_hardware_do_i_need_for_cudabased_deep/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13t9kox </id><link href="https://www.reddit.com/r/deeplearning/comments/13t9kox/what_apple_hardware_do_i_need_for_cudabased_deep/"/><updated> 2023-05-27T14:56:14+00:00</updated><published> 2023-05-27T14:56:14+00:00</published><title>基于 CUDA 的深度学习任务需要哪些 Apple 硬件？</title></entry><entry><author><name> /u/SeparateConcert9041</name><uri> https://www.reddit.com/user/SeparateConcert9041</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/SeparateConcert9041&quot;>; /u/SeparateConcert9041 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.youtube.com/ watch?v=EKlRxMOUU-o&amp;amp;t=717s&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13stz86/wilderness_passion_project/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13stz86 </id><link href="https://www.reddit.com/r/deeplearning/comments/13stz86/wilderness_passion_project/"/><updated> 2023-05-27T01:05:19+00:00</updated><published> 2023-05-27T01:05:19+00:00</published><title>荒野激情项目</title></entry><entry><author><name>/u/爱范探</name><uri>https://www.reddit.com/user/ADfantan</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;有没有你希望以前知道的 PyTorch 技巧？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32 ;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/ADfantan&quot;>; /u/ADfantan &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/deeplearning/comments/13skqhq/torch_tips/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13skqhq/torch_tips/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13skqhq</id><link href="https://www.reddit.com/r/deeplearning/comments/13skqhq/torch_tips/"/><updated> 2023-05-26T18:27:44+00:00</updated><published> 2023-05-26T18:27:44+00:00</published><title>手电筒提示</title></entry><entry><author><name>/u/笑佛_</name><uri> https://www.reddit.com/user/SmilingBuddha_</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，我对深度学习中使用的不同优化器有所了解，但我想深入了解著名优化器的细节，包括证明、直觉等. 你能推荐任何相同的教科书/在线资源吗？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/SmilingBuddha_&quot;>; /u/SmilingBuddha_ &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/deeplearning/comments/13sjddd/some_help_to_find_resources_for_optimisation/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13sjddd/some_help_to_find_resources_for_optimisation/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13sjddd </id><link href="https://www.reddit.com/r/deeplearning/comments/13sjddd/some_help_to_find_resources_for_optimisation/"/><updated> 2023-05-26T17:30:53+00:00</updated><published> 2023-05-26T17:30:53+00:00</published><title>一些帮助找到优化方法的资源。</title></entry><entry><author><name> /u/Kian5658</name><uri> https://www.reddit.com/user/Kian5658</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，需要帮助！！&lt;/p>; &lt;p>;我一直在尝试训练我的药物审查数据集（一个非常大的 csv 文件）在 BERT 上有一段时间了，在阅读了大量文档之后，我能够训练模型并想出这样的东西......&lt;/p>; &lt;p>;我已经一直在使用 Kaggle 来运行它，但是上面的代码只使用了 5GB 的 GPU 内存，并且在第一个纪元（1+ 小时）中途吃掉了整个 CPU 内存（14.8GB），你能给我一些改进代码的建议吗？告诉我如何减少 CPU 内存消耗？&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;import torch&lt;/p>; &lt;p>;from &lt;a href=&quot;https://torch .utils.data&quot;>;torch.utils.data&lt;/a>; import Dataset, DataLoader&lt;/p>; &lt;p>;from transformers import BertTokenizer, BertForSequenceClassification, AdamW&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt; p>;# 定义自定义数据集&lt;/p>; &lt;p>;class ReviewDataset(Dataset):&lt;/p>; &lt;p>;def __init__(self, reviews, tokenizer, max_length):&lt;/p>; &lt;p>;&lt;a href= &quot;https://self.reviews&quot;>;self.reviews&lt;/a>; = 评论&lt;/p>; &lt;p>;self.tokenizer = tokenizer&lt;/p>; &lt;p>;self.max_length = max_length&lt;/p>; &lt;p>; def __len__(self):&lt;/p>; &lt;p>;return len(&lt;a href=&quot;https://self.reviews&quot;>;self.reviews&lt;/a>;)&lt;/p>; &lt;p>;def __getitem__(self, idx):&lt;/p>; &lt;p>;review = str(&lt;a href=&quot;https://self.reviews&quot;>;self.reviews&lt;/a>;[&quot;review&quot;][idx])&lt;/p>; &lt; p>;rating = &lt;a href=&quot;https://self.reviews&quot;>;self.reviews&lt;/a>;[&quot;rating&quot;][idx]&lt;/p>; &lt;p>;encoding = self.tokenizer.encode_plus(&lt; /p>; &lt;p>;review,&lt;/p>; &lt;p>;add_special_tokens=True,&lt;/p>; &lt;p>;max_length=self.max_length,&lt;/p>; &lt;p>;padding=&amp;#39;max_length&amp;#39;, &lt;/p>; &lt;p>;truncation=True,&lt;/p>; &lt;p>;return_tensors=&amp;#39;pt&amp;#39;&lt;/p>; &lt;p>;)&lt;/p>; &lt;p>;input_ids = encoding[&amp;#39 ;input_ids&amp;#39;].squeeze().to(device)&lt;/p>; &lt;p>;attention_mask = encoding[&amp;#39;attention_mask&amp;#39;].squeeze().to(device)&lt;/p>; &lt;p >;return {&lt;/p>; &lt;p>;&amp;#39;input_ids&amp;#39;: input_ids,&lt;/p>; &lt;p>;&amp;#39;attention_mask&amp;#39;: attention_mask,&lt;/p>; &lt;p>;&amp;#39; rating&amp;#39;: torch.tensor((rating - 1), dtype=torch.float)&lt;/p>; &lt;p>;}&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;#设置设备&lt;/p>; &lt;p>;device = torch.device(&#39;cuda&#39;;如果 torch.cuda.is_available() else &amp;#39;cpu&amp;#39;)&lt;/p>; &lt;p>;tokenizer = BertTokenizer.from_pretrained(&amp;#39;bert-base-uncased&amp;#39;)&lt;/p>; &lt;p >;model = BertModel.from_pretrained(&#39;bert-base-uncased&#39;).to(device)&lt;/p>; &lt;p>;分类器 = torch.nn.Linear(768, 10)&lt;/p>; &lt;p >;&lt;a href=&quot;https://classifier.to&quot;>;classifier.to&lt;/a>;(device)&lt;/p>; &lt;p>;#准备数据集和数据加载器&lt;/p>; &lt;p>;&amp;#x200B;&lt; /p>; &lt;p>;dataset = ReviewDataset(train_imp, tokenizer, 512)&lt;/p>; &lt;p>;batch_size = 4&lt;/p>; &lt;p>;dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)&lt;/p >; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;# 设置优化器和学习率&lt;/p>; &lt;p>;optimizer = AdamW(model.parameters(), lr=1e-4)&lt;/p>; &lt; p>;&amp;#x200B;&lt;/p>; &lt;p>;#训练循环&lt;/p>; &lt;p>;num_epochs = 5&lt;/p>; &lt;p>;loss = torch.nn.CrossEntropyLoss()&lt;/p>; &lt;p>;for范围内的纪元(num_epochs):&lt;/p>; &lt;p>;model.train()&lt;/p>; &lt;p>;total_loss = 0&lt;/p>; &lt;p>;对于 n ，在 tqdm(enumerate(dataloader)) 中批处理：&lt; /p>; &lt;p>;print(n) if n%100 == 0 else None&lt;/p>; &lt;p>;input_ids = batch[&amp;#39;input_ids&amp;#39;]&lt;/p>; &lt;p>;# input_ids = input_ids .type(torch.LongTensor)&lt;/p>; &lt;p>;attention_mask = batch[&amp;#39;attention_mask&amp;#39;]&lt;/p>; &lt;p>;labels = batch[&amp;#39;rating&amp;#39;]&lt;/p >; &lt;p>;labels = labels.type(torch.cuda.LongTensor)&lt;/p>; &lt;p>;&lt;a href=&quot;https://labels.to&quot;>;labels.to&lt;/a>;（设备）&lt;/p >; &lt;p>;optimizer.zero_grad()&lt;/p>; &lt;p>;outputs = model(&lt;/p>; &lt;p>;input_ids=input_ids.to(device),&lt;/p>; &lt;p>;attention_mask=attention_mask.to(device ),&lt;/p>; &lt;p>;)&lt;/p>; &lt;p>;logits = classifier(outputs.pooler_output)&lt;/p>; &lt;p>;losses = loss(logits, labels)&lt;/p>; &lt;p>;total_loss +=损失&lt;/p>; &lt;p>;losses.backward()&lt;/p>; &lt;p>;optimizer.step()&lt;/p>; &lt;p>;average_loss = total_loss / len(dataloader)&lt;/p>; &lt;p>;print(f&amp; #39;epoch {epoch + 1}/{num_epochs}，损失：{average_loss}&amp;#39;)&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -- >; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Kian5658&quot;>; /u/Kian5658 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/deeplearning/comments/13scsgb/code_optimization_for_better_gpu_usage/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13scsgb/code_optimization_for_better_gpu_usage/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13scsgb </id><link href="https://www.reddit.com/r/deeplearning/comments/13scsgb/code_optimization_for_better_gpu_usage/"/><updated> 2023-05-26T13:07:20+00:00</updated><published> 2023-05-26T13:07:20+00:00</published><title>代码优化以更好地使用 GPU</title></entry><entry><author><name> /u/kateklink</name><uri> https://www.reddit.com/user/kateklink</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/kateklink&quot;>; /u/kateklink &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://refact.ai/blog/ 2023/applying-recent-innovations-to-train-model/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13sd795/applying_all_recent_innovations_to_train_a_code/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13sd795 </id><link href="https://www.reddit.com/r/deeplearning/comments/13sd795/applying_all_recent_innovations_to_train_a_code/"/><updated> 2023-05-26T13:24:52+00:00</updated><published> 2023-05-26T13:24:52+00:00</published><title>应用所有最新创新来训练代码模型</title></entry><entry><author><name>/你/unrahul</name><uri> https://www.reddit.com/user/unrahul</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我无法在网上找到如何在 Intel dGPU 上微调 LLM，所以我做了一个简单的版本。这个特别的可以用来根据你最喜欢的书（例如）生成文本。如果您拥有 Intel 独立 GPU，我希望它对您有用：&lt;a href=&quot;https://github.com/rahulunair/tiny_llm_finetuning&quot;>;https://github.com/rahulunair/tiny_llm_finetuning&lt;/a>;/ p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/unrahul&quot;>; /u/unrahul &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/deeplearning/comments/13s0xqu/tiny_llm_finetuning_a_finetuner_for_openllama_llm/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13s0xqu/tiny_llm_finetuning_a_finetuner_for_openllama_llm/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13s0xqu </id><link href="https://www.reddit.com/r/deeplearning/comments/13s0xqu/tiny_llm_finetuning_a_finetuner_for_openllama_llm/"/><updated> 2023-05-26T02:36:01+00:00</updated><published> 2023-05-26T02:36:01+00:00</published><title> tiny_llm_finetuning - 英特尔离散 GPU 上 openLLaMA LLM 模型的微调器</title></entry><entry><author><name>/你/米尔赫</name><uri>https://www.reddit.com/user/mirhec</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/mirhec&quot;>; /u/mirhec &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://wordsabout.dev/posts/如何提高迁移学习中的表现/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13s4ogw/how_to_improve_performance_in_transfer_learning/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13s4ogw </id><link href="https://www.reddit.com/r/deeplearning/comments/13s4ogw/how_to_improve_performance_in_transfer_learning/"/><updated> 2023-05-26T05:52:46+00:00</updated><published> 2023-05-26T05:52:46+00:00</published><title>如何提高迁移学习的性能</title></entry><entry><author><name>/u/钶钽铁矿3</name><uri> https://www.reddit.com/user/coltan3</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/coltan3&quot;>; /u/coltan3 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://help.medium.com/ hc/zh-cn/articles/360018677974&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13sfljp/i_just_wrote_a_comprehensive_breakdown_of_mass/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13sfljp </id><link href="https://www.reddit.com/r/deeplearning/comments/13sfljp/i_just_wrote_a_comprehensive_breakdown_of_mass/"/><updated> 2023-05-26T15:03:06+00:00</updated><published> 2023-05-26T15:03:06+00:00</published><title>我刚刚写了一份关于大规模流离失所的全面分类，你可能不知道生成 AI 已经发生了</title></entry><entry><author><name>/u/Ready-Signature748</name><uri> https://www.reddit.com/user/Ready-Signature748</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Ready-Signature748&quot;>; /u/Ready-Signature748 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://github. com/TransformerOptimus/SuperAGI&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13s9xye/github_transformeroptimussuperagi_build_and_run/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13s9xye </id><link href="https://www.reddit.com/r/deeplearning/comments/13s9xye/github_transformeroptimussuperagi_build_and_run/"/><updated> 2023-05-26T10:57:46+00:00</updated><published> 2023-05-26T10:57:46+00:00</published><title> GitHub - TransformerOptimus/SuperAGI: 构建和运行有用的自主代理</title></entry><entry><author><name>/u/快乐使命-5901</name><uri> https://www.reddit.com/user/Happy-Mission-5901</uri></author><category label="r/deeplearning" term="deeplearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;以下哪些技术可以帮助降低视觉转换器训练中梯度消失问题的概率？&lt;/p>; &lt;p>;&lt;a href=&quot;https: //www.reddit.com/poll/13s89m2&quot;>;查看投票&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Happy-Mission-5901&quot;>; /u/Happy-Mission-5901 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https: //www.reddit.com/r/deeplearning/comments/13s89m2/quiz_vanishing_problems_in_vit/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/deeplearning/comments/13s89m2/quiz_vanishing_problems_in_vit/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13s89m2 </id><link href="https://www.reddit.com/r/deeplearning/comments/13s89m2/quiz_vanishing_problems_in_vit/"/><updated> 2023-05-26T09:27:46+00:00</updated><published> 2023-05-26T09:27:46+00:00</published><title>测验：ViT 中消失的问题</title></entry></feed>