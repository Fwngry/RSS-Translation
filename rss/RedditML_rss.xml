<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category label="r/MachineLearning" term="MachineLearning"></category><updated> 2023-05-30T14:13:22+00:00</updated><icon> https://www.redditstatic.com/icon.png/</icon><id> /r/机器学习/.rss </id><link href="https://www.reddit.com/r/MachineLearning/.rss" rel="self" type="application/atom+xml"/><link href="https://www.reddit.com/r/MachineLearning/" rel="alternate" type="text/html"/><logo> https://b.thumbs.redditmedia.com/18a2I44a4l7fNrTWHDoJuWVy79_ptU7Y-a2sqWt4YKQ.png</logo><title>机器学习</title><entry><author><name>/u/自动版主</name><uri>https://www.reddit.com/user/AutoModerator </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人改为在此处发帖！&lt;/p>; &lt;p>;帖子将一直存在到下一个帖子，因此请在标题中的日期之后继续发帖。&lt;/p>; &lt;p>;感谢大家回答问题在上一个线程中！&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/AutoModerator&quot;>; /u/AutoModerator &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13nx7t0 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/"/><updated> 2023-05-21T15:00:21+00:00</updated><published> 2023-05-21T15:00:21+00:00</published><title> [D] 简单问题线程</title></entry><entry><author><name>/u/MTGTraner</name><uri> https://www.reddit.com/user/MTGTraner </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/MTGTraner&quot;>; /u/MTGTraner &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_120f4oy </id><link href="https://www.reddit.com/r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/"/><updated> 2023-03-24T09:32:29+00:00</updated><published> 2023-03-24T09:32:29+00:00</published><title>提醒：使用举报按钮并阅读规则！</title></entry><entry><author><name> /u/丹尼尔·亨德里克斯</name><uri>https://www.reddit.com/user/DanielHendrycks </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我们最近发布了一份&lt;a href=&quot;https://www.safe.ai/statement-on-ai-risk&quot;>;关于人工智能风险&lt;/a>;，由人工智能和其他领域的广泛专家联盟共同签署。 Geoffrey Hinton 和 Yoshua Bengio 以及来自主要 AI 实验室的科学家——Ilya Sutskever、David Silver 和 Ian Goodfellow——以及微软和谷歌的高管以及 AI 研究领域领先大学的教授也已签约。这种担忧超越了 AI 行业和学术界。签署者包括著名的哲学家、伦理学家、法学家、经济学家、物理学家、政治学家、大流行病科学家、核科学家和气候科学家。&lt;/p>; &lt;p>;声明如下：&lt;strong>;“减轻人工智能灭绝的风险应该与流行病和核战争等其他社会规模的风险一起成为全球优先事项。”&lt;/strong>;&lt;/p>; &lt;p>;我们希望声明简短，特别是因为不同的签署方有不同的信仰。一些人写了内容来解释他们的一些担忧：&lt;/p>; &lt;ul>; &lt;li>;Yoshua Bengio – &lt;a href=&quot;https://yoshuabengio.org/2023/05/22/how-rogue-ais-may -arise/&quot;>;流氓 AI 如何出现&lt;/a>;&lt;/li>; &lt;li>;Emad Mostaque（稳定性）&lt;a href=&quot;https://www.bbc.com/news/uk-politics-65582386&quot;>;关于风险、机遇以及它如何使人类变得“无聊”&lt;/a>;&lt;/li>; &lt;li>;David Krueger（剑桥）– &lt;a href=&quot;https://arxiv.org/abs /2302.10329&quot;>;越来越智能化的算法系统带来的危害&lt;/a>;&lt;/li>; &lt;/ul>; &lt;p>;正如签名页第一句所指出的，存在许多“来自 AI 的重要且紧迫的风险”，除了潜在的灭绝风险。人工智能以各种形式提出了当前的重大挑战，例如恶意使用、错误信息、缺乏透明度、深度造假、网络攻击、网络钓鱼和致命的自主武器。这些风险是巨大的，应该与灾难性后果的可能性一起加以解决。归根结底，关注和减轻所有类型的人工智能相关风险至关重要。&lt;/p>; &lt;p>;声明的签署者包括：&lt;/p>; &lt;ul>; &lt;li>;人工智能标准教科书的作者（Stuart Russell 和 Peter Norvig）&lt;/li>; &lt;li>;深度学习标准教科书的两位作者（Ian Goodfellow 和 Yoshua Bengio）&lt;/li>; &lt;li>;强化学习标准教科书的作者（Andrew Barto） &lt;/li>; &lt;li>;三位图灵奖获得者（Geoffrey Hinton、Yoshua Bengio 和 Martin Hellman）&lt;/li>; &lt;li>;顶级人工智能实验室的首席执行官：Sam Altman、Demis Hassabis 和 Dario Amodei&lt;/li>; &lt;li >;Microsoft、OpenAI、Google、Google DeepMind 和 Anthropic 的高管&lt;/li>; &lt;li>;中国大学的 AI 教授&lt;/li>; &lt;li>;AlphaGo 和各个版本的 GPT 等著名 AI 系统背后的科学家（David Silver , Ilya Sutskever)&lt;/li>; &lt;li>;被引用次数最多的两位计算机科学家（Hinton 和 Bengio），以及被引用次数最多的计算机安全和隐私学者（Dawn Song）&lt;/li>; &lt;/ul>; &lt;/div>; &lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/DanielHendrycks&quot;>; /u/DanielHendrycks &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13vls63/n_hinton_bengio_and_other_ai_experts_sign/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13vls63/n_hinton_bengio_and_other_ai_experts_sign/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13vls63 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13vls63/n_hinton_bengio_and_other_ai_experts_sign/"/><updated> 2023-05-30T09:45:35+00:00</updated><published> 2023-05-30T09:45:35+00:00</published><title> [N] Hinton、Bengio 等 AI 专家签署关于 AI 风险的集体声明</title></entry><entry><author><name>/u/DocBrownMS</name><uri> https://www.reddit.com/user/DocBrownMS </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13vpran/interactively_explore_your_ai_datasets_with/&quot;>; &lt;img src=&quot;https://b.thumbs.redditmedia .com/lb11KK-kvW2fLPRhHYRTHWJE1pwnBeHh6PsOZ8yGoqA.jpg&quot; alt=&quot;使用 Spotlight [P] 交互式探索您的 AI 数据集&quot; title=&quot;使用 Spotlight [P] 交互式探索您的 AI 数据集&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;嘿 &lt;a href=&quot;/r/MachineLearning&quot;>;r/MachineLearning&lt;/a>;，&lt;/p>; &lt;p>;我们很高兴与大家分享一个来自 Renumics 的新开源工具：Spotlight。 &lt;a href=&quot;https://github.com/Renumics/spotlight&quot;>;github.com/Renumics/spotlight&lt;/a>; 上的 Spotlight OSS 版本于 2023 年 5 月 30 日今天发布。&lt;/p>; &lt;p >;Spotlight 提供了一种交互式方式来探索您的数据集。它提供了一个可定制的布局，您可以在其中利用基于嵌入的相似性地图，以及各种图表，如直方图或散点图。此外，它还支持图像、3D 网格和音频数据的详细视图。&lt;/p>; &lt;p>;为了说明其功能，让我们考虑 CIFAR100 数据集。在此示例中，嵌入是使用 &lt;a href=&quot;https://huggingface.co/edumunozsala/vit_base-224-in21k-ft-cifar100&quot;>;Vision Transformer&lt;/a>; 添加的：&lt;/p>; &lt;pre>;代码>;从 renumics 导入数据集 import spotlight dataset = datasets.load_dataset(&quot;renumics/cifar100-enriched&quot;, split=&quot;test&quot;) df = dataset.to_pandas() df_show = df.drop(columns=[&amp;#39; embedding&amp;#39;]) # drop large embeddings spotlight.show(df_show, dtype={&amp;quot;image&amp;quot;: spotlight.Image, &amp;quot;embedding_reduced&amp;quot;: spotlight.Embedding}) &lt;/code>;&lt;/pre>; &lt;p>;&lt; a href =“ https://preview.redd.it/1ze14id7703b1.png？ d.it/1ze14ID7703B1.png？width =1485&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a0890accb1a48ec9d02db07b3527cb8508c0da02&lt;/a>;&lt;/p>; &lt;p>;开始使用 Spotlight 非常简单。你需要 Python 版本 3.8-3.10，你可以通过运行以下命令通过 pip 安装 Spotlight：&lt;/p>; &lt;pre>;&lt;code>;pip install renumics-spotlight datasets &lt;/code>;&lt;/pre>; &lt;p>;之后安装后，您就可以加载数据框并开始使用 Spotlight 进行探索。&lt;/p>; &lt;p>;我们邀请您使用自己的用例和数据集试用 Spotlight。如果您遇到任何问题或需要支持，请随时在 Reddit 上报告或在我们的 &lt;a href=&quot;https://github.com/Renumics/Spotlight&quot;>;GitHub 页面&lt;/a>; 上提出问题.&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/DocBrownMS&quot;>; /u/DocBrownMS &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13vpran/interactively_explore_your_ai_datasets_with/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13vpran/interactively_explore_your_ai_datasets_with/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13vpran </id><media:thumbnail url="https://b.thumbs.redditmedia.com/lb11KK-kvW2fLPRhHYRTHWJE1pwnBeHh6PsOZ8yGoqA.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13vpran/interactively_explore_your_ai_datasets_with/"/><updated> 2023-05-30T13:03:35+00:00</updated><published> 2023-05-30T13:03:35+00:00</published><title>使用 Spotlight 交互式探索您的 AI 数据集 [P]</title></entry><entry><author><name> /u/Public-Mechanic-5476</name><uri> https://www.reddit.com/user/Public-Mechanic-5476 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我是一名计算机视觉工程师，主要处理分类和对象检测问题。工作要求很高，所以无论何时，我都会尝试搜索计算机视觉/深度学习领域发生的新事物。&lt;/p>; &lt;p>;我通常依赖 LinkedIn、Twitter 和 Reddit。有时我会在滚动时找到好东西，但并非总是如此。&lt;/p>; &lt;p>;我真的想要很少的固定资源（也许 3-4 个站点？），这让我在这个领域保持最新状态。我知道保持 100% 最新是非常困难的。&lt;/p>; &lt;p>;此外，不仅限于分类和对象检测的空间，它可以是计算机视觉中的任何领域（零样本学习，新优化器、调查论文、LLM + CV 等）&lt;/p>; &lt;p>;除上述之外，我参考的资源很少（虽然不是很常规）&lt;/p>; &lt;ol>; &lt;li>;有代码的论文&lt;/li>; &lt; li>;Arxiv&lt;/li>; &lt;li>;Meta/Google 博客&lt;/li>; &lt;/ol>; &lt;p>;寻求指导和帮助🙏&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32 ;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Public-Mechanic-5476&quot;>; /u/Public-Mechanic-5476 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https: //www.reddit.com/r/MachineLearning/comments/13v1y6k/discussion_guidance_to_stay_somewhat_upto_date_in/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13v1y6k/discussion_guidance_to_stay_somewhat_upto_date_in/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13v1y6k </id><link href="https://www.reddit.com/r/MachineLearning/comments/13v1y6k/discussion_guidance_to_stay_somewhat_upto_date_in/"/><updated> 2023-05-29T18:04:09+00:00</updated><published> 2023-05-29T18:04:09+00:00</published><title> [讨论] 保持 AI 最新状态的指南</title></entry><entry><author><name>/u/jef_107</name><uri> https://www.reddit.com/user/jef_107 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我正在尝试使用图表创建赛马预测模型。每场比赛都有一个图表，每个图表都有不同号码的骑师和马匹。马和骑师也将有不同的功能。该模型的最终目标是进行节点分类，获胜的马将被标记为 1（或最高概率）。然而，我正在纠结使用哪种模型，有没有适合我的建议。&lt;/p>; &lt;p>;注意：每匹马之间的优势将基于他们的比赛记录，因为很多马都有没有相互竞争，图形有点稀疏。我在网上看到有些人会将图表合并成一个更大的图表，并通过它们之间没有边缘来分隔每个较小的图表，但在我的情况下，骑师在种族之间大多相同，所以我认为这种方法不合适。 &lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/jef_107&quot;>; /u/jef_107 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13vltlf/d_graph_neural_network_on_multiple_graphs/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13vltlf/d_graph_neural_network_on_multiple_graphs/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13vltlf </id><link href="https://www.reddit.com/r/MachineLearning/comments/13vltlf/d_graph_neural_network_on_multiple_graphs/"/><updated> 2023-05-30T09:47:57+00:00</updated><published> 2023-05-30T09:47:57+00:00</published><title> [D] 多图上的图神经网络</title></entry><entry><author><name>/u/技术-Vast1314</name><uri> https://www.reddit.com/user/Technical-Vast1314 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13uzfo5/r_lavin_large_visionlanguage_instructed_model/&quot;>; &lt;img src=&quot;https://b.thumbs.redditmedia .com/FJz4OFh64bzUquec6c2SZ9x48mmGI_jYvRPqDvB15dg.jpg&quot; alt=&quot;[R] LaVIN：大视觉-语言指导模型&quot; title=&quot;[R] LaVIN：大视觉-语言指导模型&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/t37xwe9i6u2b1.png?width =1440&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5a19d3002f4cd20fd292b183aa7833033da1ee1b&quot;>;https://preview.redd.it/t37xwe9i6u2b1.png?width=1440&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5a 19d3002f4cd20fd292b183aa7833033da1ee1b&lt;/a>;&lt; /p>; &lt;p>;论文：&lt;a href=&quot;https://arxiv.org/pdf/2305.15023.pdf&quot;>;https://arxiv.org/pdf/2305.15023.pdf&lt;/a>;&lt;/p>; &lt; p>;项目：&lt;a href=&quot;https://github.com/luogen1996/LaVIN&quot;>;https://github.com/luogen1996/LaVIN&lt;/a>;&lt;/p>; &lt;p>;&amp;#x200B;&lt;/ p>; &lt;p>;使大型语言模型适应多模式指令通常需要大量的训练时间。 BLIP2 和 mini-GPT4 都需要大量成对的文本和图像样本进行预训练。此外，LLaVA 需要对整个大型语言模型进行微调。这些方法大大增加了多模态适应的成本，并可能导致大型语言模型的文本能力下降。&lt;/p>; &lt;p>;在本文中，我们提出了&lt;strong>;一种高效的多模态指令微调方法&lt; /strong>; 使大型语言模型能够快速适应纯文本指令和文本+图像指令。基于这种方法，我们提出了一种新的多模态大型模型（LaVIN-7B，LaVIN-13B），具有以下优点：&lt;/p>; &lt;p>;- &lt;strong>;Parameter Efficiency&lt;/strong>;：LaVIN 只有&lt;strong>; 3~5M&lt;/strong>;训练参数。&lt;/p>; &lt;p>;- &lt;strong>;训练效率&lt;/strong>;：LaVIN在ScienceQA数据集上微调仅需&lt;strong>;1.4小时&lt;/strong>;&lt;/p >; &lt;p>;- &lt;strong>;强大的性能&lt;/strong>;：LaVIN 在 ScienceQA 数据集上达到 &lt;strong>;90.8% 的准确度&lt;/strong>;，以大约 6% 的准确度优于 LLaMA-Adapter。&lt;/p>; &lt;p>;- &lt;strong>;多模式&lt;/strong>;：LaVIN 支持纯文本和文本图像指令。&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/vnr8m18g7y2b1.png?width=1656&amp;amp ;format=png&amp;amp;auto=webp&amp;amp;s=e6cfeba67004605322dab5f0adb4bf486c4d890f&quot;>;https://preview.redd.it/vnr8m18g7y2b1.png?width=1656&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e6cfeba6700 4605322dab5f0adb4bf486c4d890f&lt;/a>;&lt;/p >; &lt;p>;&lt;a href=&quot;https://preview.redd.it/kmqn64ue7y2b1.png?width=1566&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f7d91b316bf581f49f24415f7f2be5198148b4eb&quot;>;https://preview.redd.it/ kmqn64ue7y2b1.png?width=1566&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f7d91b316bf581f49f24415f7f2be5198148b4eb&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/n14ni8dh7y2b1.png?width =1604&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=94dbad21ab43b1c3cb0fba9ccdbdaf867212ba9d&quot;>;https://preview.redd.it/n14ni8dh7y2b1.png?width=1604&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=94dbad21ab4 3b1c3cb0fba9ccdbdaf867212ba9d&lt;/a>;&lt; /p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/vz48i7298u2b1.png?width=2816&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d1c5c748d4f7810a1f81f57b3c96654558b04085&quot;>;https://preview.redd。它/vz48i7298u2b1.png?width=2816&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d1c5c748d4f7810a1f81f57b3c96654558b04085&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://i.redd.it/91qc617r7y2b1 .gif &quot;>;https://i.redd.it/91qc617r7y2b1.gif&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Technical-Vast1314&quot;>; /u/Technical-Vast1314 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www. reddit.com/r/MachineLearning/comments/13uzfo5/r_lavin_large_visionlanguage_instructed_model/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13uzfo5/r_lavin_large_visionlanguage_instructed_model/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13uzfo5 </id><media:thumbnail url="https://b.thumbs.redditmedia.com/FJz4OFh64bzUquec6c2SZ9x48mmGI_jYvRPqDvB15dg.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13uzfo5/r_lavin_large_visionlanguage_instructed_model/"/><updated> 2023-05-29T16:24:18+00:00</updated><published> 2023-05-29T16:24:18+00:00</published><title> [R] LaVIN：大型视觉语言指导模型</title></entry><entry><author><name>/u/维克托基穆尤</name><uri>https://www.reddit.com/user/victorkimuyu </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我收集了大量的车辆图像，包括轿车（轿车）、旅行车、SUV、卡车、皮卡车、货车和所有车辆&lt;/p>; &lt;p>;为了评估和估价报告的目的，这些车辆将被拍照。因此，它们是在不同的位置（车库、路边、树下）从至少 4 个角度（左前、左后、右后、右前、内部、仪表板、发动机、VIN）和不同的照明条件。然而，总的来说，光线很好，因为大部分时间照片都是白天在户外拍摄的。&lt;/p>; &lt;p>;我想用标签丰富这个集合，我可以用这些标签在未来训练模型进行各种自动化便利。我可能还会探索 ML 数据集市场，但这不是目前的优先事项。&lt;/p>; &lt;p>;有哪些有用的标记技术可以简化流程，哪些标签最有实用性和多功能性？&lt; /p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/victorkimuyu&quot;>; /u/victorkimuyu &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13vlxei/r_1m_high_res_vehicle_images/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13vlxei/r_1m_high_res_vehicle_images/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13vlxei </id><link href="https://www.reddit.com/r/MachineLearning/comments/13vlxei/r_1m_high_res_vehicle_images/"/><updated> 2023-05-30T09:54:27+00:00</updated><published> 2023-05-30T09:54:27+00:00</published><title> [R] 1m+ 高分辨率。车辆图像</title></entry><entry><author><name>/你/mesqz</name><uri> https://www.reddit.com/user/mesqz </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&lt;a href=&quot;https://medium.com/@tiago-mesquita/from-algorithms-to-antibiotics-ai-guides-scientists -to-novel-antibiotic-for-drug-resistant-6a902e9e33f6&quot;>;https://medium.com/@tiago-mesquita/from-algorithms-to-antibiotics-ai-guides-scientists-to-novel-antibiotic-for -drug-resistant-6a902e9e33f6&lt;/a>; &lt;/p>; &lt;p>;为了开发他们的计算模型，研究人员在实验室环境中将 A. baumannii 暴露于大约 7,500 种化合物。&lt;/p>; &lt;p>;通过喂养结构将每个分子添加到模型中并表明它是否抑制细菌生长，算法学习与生长抑制相关的化学特征。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/mesqz&quot;>; /u/mesqz &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13v0ags/n_researchers_from_mit_and_mcmaster_university/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13v0ags/n_researchers_from_mit_and_mcmaster_university/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13v0ags </id><link href="https://www.reddit.com/r/MachineLearning/comments/13v0ags/n_researchers_from_mit_and_mcmaster_university/"/><updated> 2023-05-29T16:57:13+00:00</updated><published> 2023-05-29T16:57:13+00:00</published><title> [N] 麻省理工学院和麦克马斯特大学的研究人员利用机器学习人工智能算法发现了一种新抗生素，用于治疗由鲍曼不动杆菌引起的耐药性感染</title></entry><entry><author><name>/u/伊梅内查比</name><uri>https://www.reddit.com/user/ImeneCharabi </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;你好，如果我想构建一个 CNN-SVM 混合模型，其中 CNN 用于特征提取，SVM 用于分类，哪种方法会更好：使用端到端可训练模型或从最后一个 CNN 层提取特征并将它们传递给另一个 SVM 模型进行分类？我想知道最好的方法是什么以及背后的原因。这两种方法是否同样有效？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/ImeneCharabi&quot;>; /u/ImeneCharabi &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13vmygz/hybrid_cnnsvm_model_p/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13vmygz/hybrid_cnnsvm_model_p/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13vmygz</id><link href="https://www.reddit.com/r/MachineLearning/comments/13vmygz/hybrid_cnnsvm_model_p/"/><updated> 2023-05-30T10:51:38+00:00</updated><published> 2023-05-30T10:51:38+00:00</published><title>混合 CNN-SVM 模型 [p]</title></entry><entry><author><name> /u/隐秘典范</name><uri>https://www.reddit.com/user/CrypticParagon </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，&lt;/p>; &lt;p>;我很容易将我的团队的各种表现联系起来模型到公司级 KPI、收入、EBITDA 等。但是，我很难为我的团队提出 KPI，该团队主要负责开发模型。&lt;/p>; &lt;p>;我不喜欢模型性能指标作为 KPI，因为这些指标取决于我们无法控制的太多因素，例如我们可用数据的质量和问题的易处理性。完成实验的比率没有多大意义，因为随着模型训练的爆发，可能会编写大量代码。似乎我可以衡量的唯一真正的 KPI 是某种 LoE 速度，例如 Jira Story Points。&lt;/p>; &lt;p>;还有哪些其他想法？您在团队中使用什么作为 KPI？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/CrypticParagon&quot;>; /u/CrypticParagon &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13viobp/d_kpis_for_machine_learning_teams_in_an_industry/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13viobp/d_kpis_for_machine_learning_teams_in_an_industry/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13viobp </id><link href="https://www.reddit.com/r/MachineLearning/comments/13viobp/d_kpis_for_machine_learning_teams_in_an_industry/"/><updated> 2023-05-30T06:37:47+00:00</updated><published> 2023-05-30T06:37:47+00:00</published><title> [D] 行业环境中机器学习团队的 KPI</title></entry><entry><author><name> /u/r1a2k3i4b</name><uri> https://www.reddit.com/user/r1a2k3i4b </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;是否有任何廉价或推荐的方法将一些机器学习模型部署为 REST API？&lt;/p>; &lt;p>;我的应用程序使用一些稳定的扩散模型来生成图像，但我们依赖于另一个经常出现故障的服务的 API...我们为此支付大约 150 美元/月，但认为支付 GPU 会更贵&lt;/p>; &lt;p>;有没有人有什么建议或想法吗？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/r1a2k3i4b&quot;>; /u/r1a2k3i4b &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13vr1yw/cheap_ways_to_deploy_ml_models_d/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13vr1yw/cheap_ways_to_deploy_ml_models_d/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13vr1yw </id><link href="https://www.reddit.com/r/MachineLearning/comments/13vr1yw/cheap_ways_to_deploy_ml_models_d/"/><updated> 2023-05-30T13:56:47+00:00</updated><published> 2023-05-30T13:56:47+00:00</published><title>部署 ML 模型的廉价方法 [D]？</title></entry><entry><author><name> /u/04RR</name><uri> https://www.reddit.com/user/04RR </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，我正在寻找建议和执行此操作时要记住的事项。 &lt;/p>; &lt;p>;我基本上想在面向代码生成的数据集上微调 LLaMA。经过一番研究后，我发现 &lt;a href=&quot;https://github.com/FSoft-AI4Code/TheVault&quot;>;TheVault&lt;/a>; 似乎足以胜任这项工作（如果有更好的数据集，请告诉我） . &lt;/p>; &lt;p>;对于微调部分，我希望使用 LoRA 或其他类似方法。这是我第一次对 LLM 进行微调，所以如果您有任何建议或提示，请告诉我。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/04RR&quot;>; /u/04RR &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13vpd0y/p_finetuning_llama_on_thevault_by_ai4code/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13vpd0y/p_finetuning_llama_on_thevault_by_ai4code/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13vpd0y </id><link href="https://www.reddit.com/r/MachineLearning/comments/13vpd0y/p_finetuning_llama_on_thevault_by_ai4code/"/><updated> 2023-05-30T12:47:15+00:00</updated><published> 2023-05-30T12:47:15+00:00</published><title> [P] 通过 AI4Code 在 TheVault 上微调 LLaMA</title></entry><entry><author><name> /u/Tekno-12345</name><uri> https://www.reddit.com/user/Tekno-12345 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我正在寻求一些帮助，以在不超支的情况下为轻型深度学习训练站选择最佳组件，您认为这些合理吗？&lt;/p>; &lt;p>;规格：&lt;br/>;第 12 代英特尔酷睿 i7-12700 处理器 - Alder Lake 12 核 LGA 1700 CPU | 12700&lt;/p>; &lt;p>;技嘉 GeForce RTX 3060 WINDFORCE OC 12G（修订版 2.0）| RTX 3060 WINDFORCE OC &lt;/p>; &lt;p>;海康威视内存 16GB DDR4 3000MHz- 适用于台式机 | HKED4161DAA2D1ZA2 &lt;/p>; &lt;p>;Xigmatek LUX A Shadow 金属灰 ATX 4PCS RGB FANS GALAXY II | EN48274&lt;/p>; &lt;p>;金士顿 1TB NV2 M.2 2280 PCIe 4.0 x4 NVMe SSD | SNV2S/1000G &lt;/p>; &lt;p>;Xigmatek Hydra M 750W 电源 | EN44221&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Tekno-12345&quot;>; /u/Tekno-12345 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www. reddit.com/r/MachineLearning/comments/13voar0/d_building_a_pc_for_light_mldl_training/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13voar0/d_building_a_pc_for_light_mldl_training/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13voar0 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13voar0/d_building_a_pc_for_light_mldl_training/"/><updated> 2023-05-30T11:59:29+00:00</updated><published> 2023-05-30T11:59:29+00:00</published><title> [D] 构建用于轻型 ML/DL 训练的 PC</title></entry><entry><author><name> /u/pp314159</name><uri> https://www.reddit.com/user/pp314159 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我们正在开发开源 Web 框架 Mercury，它可以将 Python 笔记本转换为 Web 应用程序。&lt;/p>; &lt;p>;它非常棒自以为是：&lt;/p>; &lt;ul>; &lt;li>;&lt;p>;它没有回调——我们自动重新执行更新的小部件下面的单元格&lt;/p>;&lt;/li>; &lt;li>;&lt;p>;它没有布局小部件，所有输入小部件始终位于左侧边栏中&lt;/p>;&lt;/li>; &lt;/ul>; &lt;p>;由于上述决定，您无需更改笔记本代码以适应框架 UI 范例，您获得 Web 应用程序的最小更改。&lt;/p>; &lt;p>;框架的简单性对我们来说非常重要。我们还关心部署的简单性。这就是我们创建名为 Mercury Cloud 的共享托管服务的原因。您可以通过上传文件来部署笔记本。&lt;/p>; &lt;p>;GitHub 存储库 &lt;a href=&quot;https://github.com/mljar/mercury&quot;>;https://github.com/mljar/mercury&lt;/ a>;&lt;/p>; &lt;p>;文档 &lt;a href=&quot;https://RunMercury.com/docs/&quot;>;https://RunMercury.com/docs/&lt;/a>;&lt;/p>; &lt;p>;Mercury Cloud &lt;a href=&quot;https://cloud.runmercury.com&quot;>;https://cloud.runmercury.com&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/pp314159&quot;>; /u/pp314159 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13vo5qk/p_opinionated_web_framework_for_converting/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13vo5qk/p_opinionated_web_framework_for_converting/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13vo5qk </id><link href="https://www.reddit.com/r/MachineLearning/comments/13vo5qk/p_opinionated_web_framework_for_converting/"/><updated> 2023-05-30T11:52:23+00:00</updated><published> 2023-05-30T11:52:23+00:00</published><title> [P] 用于将 Jupyter Notebook 转换为 Web 应用程序的自定 Web 框架</title></entry><entry><author><name>/你/极客酋长</name><uri>https://www.reddit.com/user/geekinchief </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13ujsy7/n_nvidia_ace_brings_ai_to_game_characters_allows/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/sn7y0_ZzyL6A1Z0c8kbCVNhHxJMA4TVhtzWh4AEpcTU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b38cf19809b41a1f7a20ac618d26df9e9ed93614&quot; alt=&quot;[N] Nvidia ACE 带来s AI 到游戏角色，允许逼真的对话&quot; title=&quot;[N] Nvidia ACE Brings AI 到游戏角色，让对话栩栩如生&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/geekinchief&quot;>; /u/geekinchief &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.tomshardware.com/新闻/nvidia-ace-brings-npcs-to-life&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13ujsy7/n_nvidia_ace_brings_ai_to_game_characters_allows/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13ujsy7 </id><media:thumbnail url="https://external-preview.redd.it/sn7y0_ZzyL6A1Z0c8kbCVNhHxJMA4TVhtzWh4AEpcTU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b38cf19809b41a1f7a20ac618d26df9e9ed93614"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13ujsy7/n_nvidia_ace_brings_ai_to_game_characters_allows/"/><updated> 2023-05-29T03:39:37+00:00</updated><published> 2023-05-29T03:39:37+00:00</published><title> [N] Nvidia ACE 为游戏角色带来 AI，让对话栩栩如生</title></entry><entry><author><name>/u/ching7788</name><uri> https://www.reddit.com/user/ching7788 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13uuli6/unicontrol_a_unified_diffusion_model_for/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=72b056142e7533b5628a2a34f37f7e5415727075&quot; alt=&quot;UniControl: A Un野外可控视觉生成的扩散模型 [P]&quot; title=&quot;UniControl:野外可控视觉生成的统一扩散模型 [P]&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;UniControl: A野外可控视觉生成的统一扩散模型&lt;/p>; &lt;p>;论文：&lt;a href=&quot;https://arxiv.org/abs/2305.11147&quot;>;https://arxiv.org/abs/2305.11147&lt;/ a>;&lt;/p>; &lt;p>;代码：&lt;a href=&quot;https://github.com/salesforce/UniControl&quot;>;https://github.com/salesforce/UniControl&lt;/a>;&lt;/p>; &lt;p >;秦灿†⋆, 张舒†, 宁宇†, Yihao Feng†, Xinyi Yang†, Yingbo Zhou†, Huan Wang†, Juan Carlos Niebles†, Caiming Xiong†, Silvio Savarese†, Stefano Ermon‡, Yun Fu⋆ , and Ran Xu†&lt;/p>; &lt;p>;†Salesforce AI Research, ⋆Northeastern University, ‡Stanford University&lt;/p>; &lt;p>;&lt;strong>;Overview:&lt;/strong>;&lt;/p>; &lt;p>;&lt;a href =&quot;https://preview.redd.it/7i81ugz7sr2b1.png?width=5030&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4c6bb321f62eae67272e4d99bb082349dcb07e17&quot;>;UniControl 使用统一模型进行多项任务训练，进一步展示了有前途的能力在零样本任务泛化中，上面显示了视觉示例结果。&lt;/a>;&lt;/p>; &lt;p>;UniControl 的贡献：&lt;/p>; &lt;ul>; &lt;li>;UniControl 是一个统一模型（1.4B #params，5.78 GB 检查点）能够处理可控视觉生成的各种视觉条件。&lt;/li>; &lt;li>;为多条件视觉生成收集了一个新的数据集，其中包含超过 2000 万个图像-文本-条件（图像大小>;=512）三元组超过五个类别的九个不同任务。我们将很快开源训练数据。&lt;/li>; &lt;li>;大量实验表明，由于学习了不同视觉条件之间的内在关系，UniControl 优于每个单任务控制图像生成。&lt;/li>; &lt;li>; UniControl 展示了以零样本方式适应未知任务的能力，突出了它的多功能性和在野外广泛采用的潜力。&lt;/li>; &lt;/ul>; &lt;p>;&lt;strong>;方法：&lt;/strong>;&lt;/ p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/obznwqi9sr2b1.png?width=2018&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d64f6da1e99102c4cf439c8951e5c79ec597df5b&quot;>;为了适应不同的任务，我们设计了一个混合专家（MOE）适配器，包含每个任务大约 ∼70K #params，以及一个任务感知 HyperNet（∼12M #params）来调制 N（即 7）个零卷积层。这种结构允许在单一模型中实现多任务功能，与等效的单任务模型堆栈相比显着减小了模型大小，每个模型具有大约 1.4B #params。&lt;/a>;&lt;/p>; &lt;p>;&lt;strong >;预训练任务结果：&lt;/strong>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/hpqn2vdbsr2b1.png?width=8061&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s =ef2796fee6d116586f702331b963cea3846b7df2&quot;>;官方或重新实现的任务特定 ControlNet 与我们提出的模型之间的视觉比较。示例数据是从我们从 COCO 和 Laion 采样的测试集中收集的。&lt;/a>;&lt;/p>; &lt;p>;&lt;strong>;零样本任务结果：&lt;/strong>;&lt;/p>; &lt;p>;&lt;a href= &quot;https://preview.redd.it/hk3ewfndsr2b1.png?width=3930&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c5fc63350ea9ea61020f915740a29f0fcba2811e&quot;>;(a)-(b): UniControl over hybrid（看不见的组合）的示例结果带有关键字“背景”的条件和“前景”附在提示中。 (c)-(e)：UniControl 在三个未见过的任务（去模糊、着色、修复）上的示例结果。&lt;/a>;&lt;/p>; &lt;p>;&lt;strong>;Gradio 演示结果：&lt;/strong>;&lt;/p>; &lt;p>;所有任务的渐变 UI：&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/tfjmlsdfsr2b1.png?width=3134&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cdca67175d8d6eb066b8e294437ff3174288a007 &quot;>;https://preview.redd.it/tfjmlsdfsr2b1.png?width=3134&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cdca67175d8d6eb066b8e294437ff3174288a007&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https:/ /preview.redd.it/6klax4zgsr2b1.png?width=3084&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=039ffb21fe6e9ff772880ce36b61ee72bcec75bd&quot;>;https://preview.redd.it/6klax4zgsr2b1.png?width=3084&amp; amp;格式=png&amp;amp; auto=webp&amp;amp;s=039ffb21fe6e9ff772880ce36b61ee72bcec75bd&lt;/a>;&lt;/p>; &lt;p>;单个任务的渐变 UI：&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/80mxa1cisr2b1.png? width=3090&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1a7274a1d311f674ea8f39bad9cebb1f5c853c32&quot;>;https://preview.redd.it/80mxa1cisr2b1.png?width=3090&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1a7 274a1d311f674ea8f39bad9cebb1f5c853c32&lt;/a>; &lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/4f4c4qfjs​​r2b1.png?width=3106&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=48fa021e67243490b549a69fd3a9707709c4bd06&quot;>;https://preview.redd .it/4f4c4qfjs​​r2b1.png?width=3106&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=48fa021e67243490b549a69fd3a9707709c4bd06&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/55vrpxzksr2b1 . png?width=3136&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=da2c6efce561f26a7418291ae4941452b26ac913&quot;>;https://preview.redd.it/55vrpxzksr2b1.png?width=3136&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=da2c 6efce561f26a7418291ae4941452b26ac913&lt;/ a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/fq9yolmlsr2b1.png?width=3056&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a3bcd24401c89f0d8993deb25c670ba407488e26&quot;>;https://preview .redd.it/fq9yolmlsr2b1.png?width=3056&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a3bcd24401c89f0d8993deb25c670ba407488e26&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/ 3sfm1q8msr2b1.png?width=3112&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f1166905a7721e40918f8fb33aa1b723e392b68b&quot;>;https://preview.redd.it/3sfm1q8msr2b1.png?width=3112&amp; amp;格式=png&amp;amp;auto=webp&amp;amp;s=f1166905a7721e40918f8fb33aa1b723e392b68b &lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/fp68tk2nsr2b1.png?width=3102&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c2ef1a96e3a2006c0a7f84623233827bae430336&quot;>;https:/ /preview.redd.it/fp68tk2nsr2b1.png?width=3102&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c2ef1a96e3a2006c0a7f84623233827bae430336&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.它/744w1hwnsr2b1.png?width=3124&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=06a330e62a6e5541d2443744e6387085a26e6012&quot;>;https://preview.redd.it/744w1hwnsr2b1.png?width=3124&amp;amp ;格式=png&amp;amp;auto=webp&amp;amp;s =06a330e62a6e5541d2443744e6387085a26e6012&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/cam8g1apsr2b1.png?width=3114&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d935c63132c8a33 a5b0465bb7b94fdfec84bbde1&quot;>;https ://preview.redd.it/cam8g1apsr2b1.png?width=3114&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d935c63132c8a33a5b0465bb7b94fdfec84bbde1&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview. redd.it/77xg2w9qsr2b1.png?width=3092&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fc2a136bee5dfe6c7b3a0735d5db8c534ceaa8fc&quot;>;https://preview.redd.it/77xg2w9qsr2b1.png?width=3092&amp; amp;格式=png&amp;amp;auto=webp&amp;amp ;s=fc2a136bee5dfe6c7b3a0735d5db8c534ceaa8fc&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/ching7788&quot;>; /u/ching7788 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13uuli6/unicontrol_a_unified_diffusion_model_for/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13uuli6/unicontrol_a_unified_diffusion_model_for/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13uuli6 </id><media:thumbnail url="https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13uuli6/unicontrol_a_unified_diffusion_model_for/"/><updated> 2023-05-29T13:13:38+00:00</updated><published> 2023-05-29T13:13:38+00:00</published><title> UniControl：野外可控视觉生成的统一扩散模型 [P]</title></entry><entry><author><name> /u/WeAreDevelopers_</name><uri> https://www.reddit.com/user/WeAreDevelopers_ </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，我们明天（5 月 31 日，星期三）将举办一场关于机器学习的免费虚拟小型会议。它从 10:00 AM (CEST) 开始，但所有的谈话都将被录制下来，并可以在活动结束后点播观看，以防你不能准时参加。此外，所有的演讲都会在每次演讲后进行现场直播和问答环节。&lt;/p>; &lt;p>;查看主题和议程，并确保保留您的位置，以防您有兴趣加入：&lt; href=&quot;https://www.wearedevelopers.com/event/machine-learning-day-may-2023&quot;>;https://www.wearedevelopers.com/event/machine-learning-day-may-2023&lt;/ a>;&lt;/p>; &lt;p>;这篇文章并不是为了自我推销或其他任何目的，只是想为社区做出贡献。希望您会发现这次活动足智多谋，它将对您未来的 ML/AI 项目有所帮助。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/WeAreDevelopers_&quot;>; /u/WeAreDevelopers_ &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13vl1di/n_free_machine_learning_virtual_conference/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13vl1di/n_free_machine_learning_virtual_conference/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13vl1di </id><link href="https://www.reddit.com/r/MachineLearning/comments/13vl1di/n_free_machine_learning_virtual_conference/"/><updated> 2023-05-30T09:01:25+00:00</updated><published> 2023-05-30T09:01:25+00:00</published><title> [N] 明天免费机器学习虚拟会议</title></entry><entry><author><name>/u/yannisassael</name><uri> https://www.reddit.com/user/yannisassael </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我们想分享我们最近发表在计算语言学（麻省理工学院出版社）上的评论论文“Machine learning for ancient languages: a survey”。我们的工作调查了 240 多篇使用机器学习研究以任何语言、文字和媒介编写的古代文本的研究论文。这篇评论旨在促进和支持人文学科与机器学习之间的持续合作动力，并且是我们为人文学科开发 AI 的努力的一部分。&lt;/p>; &lt;p>;&lt;a href=&quot;https://direct. mit.edu/coli/article/doi/10.1162/coli_a_00481/116160/Machine-Learning-for-Ancient-Languages-A-Survey&quot;>;https://direct.mit.edu/coli/article/doi/10.1162/coli_a_00481 /116160/Machine-Learning-for-Ancient-Languages-A-Survey&lt;/a>;&lt;/p>; &lt;p>;我们还创建了一个 GitHub 存储库来托管已审查文献的分类并维护最新目录关于这个主题的积极跨学科研究（鼓励请求！） &lt;a href=&quot;https://github.com/ancientml/ml-for-ancient-languages&quot;>;https://github.com/ancientml/ml-for -古代语言&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/yannisassael&quot;>; /u/yannisassael &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13v4fkg/r_machine_learning_for_ancient_languages/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13v4fkg/r_machine_learning_for_ancient_languages/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13v4fkg </id><link href="https://www.reddit.com/r/MachineLearning/comments/13v4fkg/r_machine_learning_for_ancient_languages/"/><updated> 2023-05-29T19:42:39+00:00</updated><published> 2023-05-29T19:42:39+00:00</published><title> [R] 古代语言的机器学习</title></entry><entry><author><name>/u/datachomper</name><uri> https://www.reddit.com/user/datachomper </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;作为我在内部向一些工作场所同事教授的迷你课程的一部分，我很乐意向他们展示一个不错的 &lt; em>;对抗性计算机视觉&lt;/em>; Colab 笔记本/可运行教程。我的专业领域是 ML、DL 中与 CV 相去甚远的部分，所以我觉得我不是制作&lt;em>;对抗性 CV&lt;/em>; Notebook / 的最佳人选可从头开始运行的教程。&lt;/p>; &lt;p>;我发现了这些：&lt;/p>; &lt;ul>; &lt;li>;从 TensorFlow 文档中，&lt;em>;快速梯度签名方法 (FGSM)&lt;/em>;来自旧 Goodfellow 论文的攻击：&lt;a href=&quot;https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb&quot;>;https:/ /colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb&lt;/a>;&lt;/li>; &lt;li>;阿姆斯特丹大学的深度学习课程：&lt; a href=&quot;https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial10/Adversarial_Attacks.ipynb&quot;>;Github&lt;/a>; 和 &lt;a href=&quot;https://colab.research. google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial10/Adversarial_Attacks.ipynb&quot;>;Colab&lt;/a>; 包括另一个 FGSM 示例&lt;/li>; &lt;/ul>; &lt;p>;我是想知道：是否有人有任何方便的 Colab Notebooks 参考资料，其中显示了除 FGSM 之外的一些其他方法，他们认为这些方法可以作为很好的教材/指南？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/datachomper&quot;>; /u/datachomper &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13uwmkn/d_favorite_colab_notebooks_runnable_tutorials_on/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13uwmkn/d_favorite_colab_notebooks_runnable_tutorials_on/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13uwmkn </id><link href="https://www.reddit.com/r/MachineLearning/comments/13uwmkn/d_favorite_colab_notebooks_runnable_tutorials_on/"/><updated> 2023-05-29T14:35:53+00:00</updated><published> 2023-05-29T14:35:53+00:00</published><title> [D] 最喜欢的 Colab 笔记本/关于对抗性 CV 的可运行教程</title></entry><entry><author><name>/你/玛雅桑</name><uri>https://www.reddit.com/user/mayasang </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;嗨，我最近在一家科技公司的机器学习面试中遇到了这个问题。假设我们构建了一个分类器来预测用户的行为。某些动作（例如，点击广告）。&lt;/p>; &lt;p>;(1) 我们如何评估这个模型（假设它是一个严重不平衡的数据集）&lt;/p>; &lt;p>;- 我提到我们可以使用 AUC 和归一化交叉熵。 （定义：每次展​​示的平均日志损失除以模型预测每次展示的背景点击率 (CTR) 时每次展示的平均日志损失将是多少 [1]）。&lt;/p>; &lt;p>;如下-up 问题，面试官问，&lt;/p>; &lt;p>;(2) 如果我们有两个模型：&lt;/p>; &lt;ul>; &lt;li>;模型 1 在未经采样的原始数据上训练：AUC1，logloss1 在 eval 数据上（非-sampled)&lt;/li>; &lt;li>;Model2 在 10% neg-downampled 数据上训练：AUC2，logloss2 在 eval 数据上（非采样）&lt;/li>; &lt;/ul>; &lt;p>;如果他们的 AUC1 == AUC2，并且logloss1 == logloss2，哪个指标表明模型更好？我们应该看哪个指标？哪个型号更好？ &lt;/p>; &lt;p>;我提到过，如果测试数据集没有被下采样，并且如果它们的 AUC 和交叉熵相同，那么这两个模型的结果是一样的。质量似乎是一样的。我不确定这是否是正确的答案，但我不确定我是否遗漏了任何内容，面试官也没有对我的答案提供任何反馈。你怎么认为？感谢您提前提供见解！&lt;/p>; &lt;p>;[1] Facebook 广告点击预测实践经验，ADKDD 14&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/mayasang&quot;>; /u/mayasang &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13uqbrm/d_interview_question_comparing_two_models_with/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13uqbrm/d_interview_question_comparing_two_models_with/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13uqbrm </id><link href="https://www.reddit.com/r/MachineLearning/comments/13uqbrm/d_interview_question_comparing_two_models_with/"/><updated> 2023-05-29T09:52:50+00:00</updated><published> 2023-05-29T09:52:50+00:00</published><title> [D]（面试题）在测试数据集上比较有负采样和无负采样但 AUC 和 logloss 相同的两个模型：哪个模型更好？</title></entry><entry><author><name> /u/asotos11</name><uri> https://www.reddit.com/user/asotos11 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&lt;strong>;摘要：&lt;/strong>;&lt;/p>; &lt;blockquote>; &lt;p>;大型语言模型 (LLM) 中采用的自回归转换器很难扩展到长序列。尽管有几项工作试图降低其计算成本，但大多数 LLM 仍然在序列中的所有标记对之间采用注意力层，从而产生二次成本。在这项研究中，我们提出了一种新的方法，可以动态修剪上下文信息，同时保留模型的表达能力，从而减少推理过程中的内存和计算需求。我们的方法采用了一种可学习的机制，该机制确定可以在生成过程中的任何时候从上下文中删除哪些无信息的标记。通过这样做，我们的方法不仅解决了性能问题，而且增强了可解释性，为模型的决策过程提供了有价值的见解。我们的技术可以通过简单的微调过程应用于现有的预训练模型，并且修剪强度可以由稀疏参数指定。值得注意的是，我们的实证结果表明，我们可以有效地修剪高达 80% 的上下文，而不会显着降低下游任务的性能，从而为降低推理成本提供了一个有价值的工具。我们的参考实现将推理吞吐量提高了 2 倍，甚至节省了更多内存。&lt;/p>; &lt;/blockquote>; &lt;p>;&lt;strong>;工作原理：&lt;/strong>;&lt;/p>; &lt;blockquote>; &lt;p>;我们发现，&lt;strong>;高达 80% 的上下文可以被成功修剪&lt;/strong>;，&lt;strong>;在困惑度和零样本性能方面的恶化最小&lt;/strong>;，同时在推理过程中需要的资源明显减少。我们展示了这些改进如何带来可衡量的实际收益，方法是&lt;strong>;提供一种有效的实现方式来减少令牌生成期间用于缓存的内存使用量&lt;/strong>;。更具体地说，对于更大的上下文大小，&lt;strong>;我们在每一代&lt;/strong>;步骤中减少了高达 50% 的墙时间延迟，同时仍然&lt;strong>;以高达 2 倍大的批处理大小进行解码&lt;/strong>;，领先从而获得显着的性能优势。这些发现强调了上下文修剪作为一种强大技术的潜力，可以提高 NLP 中 Transformer 的效率和可解释性。&lt;/p>; &lt;/blockquote>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/asotos11&quot;>; /u/asotos11 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13utt6e/r_dynamic_context_pruning_for_efficient_and/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13utt6e/r_dynamic_context_pruning_for_efficient_and/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13utt6e </id><link href="https://www.reddit.com/r/MachineLearning/comments/13utt6e/r_dynamic_context_pruning_for_efficient_and/"/><updated> 2023-05-29T12:41:00+00:00</updated><published> 2023-05-29T12:41:00+00:00</published><title> [R] 高效且可解释的自回归变压器的动态上下文修剪</title></entry><entry><author><name>/u/kkimdev</name><uri> https://www.reddit.com/user/kkimdev </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我想知道我们是否可以使用 LoRA 进行预训练，每 N 步将 LoRA 权重与冻结权重合并。或者有没有类似的预训练研究？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/kkimdev&quot;>; /u/kkimdev &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13upogz/d_lora_weight_merge_every_n_step_for_pretraining/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13upogz/d_lora_weight_merge_every_n_step_for_pretraining/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13upogz </id><link href="https://www.reddit.com/r/MachineLearning/comments/13upogz/d_lora_weight_merge_every_n_step_for_pretraining/"/><updated> 2023-05-29T09:13:59+00:00</updated><published> 2023-05-29T09:13:59+00:00</published><title> [D] [LoRA + weight merge every N step]预训练？</title></entry><entry><author><name> /你/achyutjoshi</name><uri> https://www.reddit.com/user/achyutjoshi </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;有关最新消息的专家见解目前已锁定在语义搜索之外。我们索引了 1000 小时的音频转录本，并在最佳播客中提供超过 100 万个嵌入。开发人员可以将对专家意见的查询路由到单个 API 并检索最相关的上下文。从这里开始：&lt;a href=&quot;https://playground.embedding.store/?__theme=light&quot;>;Embeddings Playground&lt;/a>;&lt;/p>; &lt;p>;我们每周都会推出新的嵌入。如果你想为下一次下降做出贡献或有想法，我们刚刚开始不和谐。 &lt;a href=&quot;https://discord.com/invite/jWgbWxE9&quot;>;加入我们&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/achyutjoshi&quot;>; /u/achyutjoshi &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13v1bl5/project_podcast_embeddings_get_expert_insights_on/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13v1bl5/project_podcast_embeddings_get_expert_insights_on/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13v1bl5 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13v1bl5/project_podcast_embeddings_get_expert_insights_on/"/><updated> 2023-05-29T17:38:28+00:00</updated><published> 2023-05-29T17:38:28+00:00</published><title> [项目] Podcast Embeddings 🎙️ -- 在您的 LLM 中获取有关最新消息的专家见解</title></entry><entry><author><name>/u/kazhdan_d</name><uri> https://www.reddit.com/user/kazhdan_d </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13uurn2/p_fomo_as_a_service_compare_your_models_against/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/wUaSYINqTxMnWIhlJyItg-DE0FBAqsMKmpHSH7cbzHA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3b032be1844bc44c6a94b1164ce57856f1816f5d&quot; alt=&quot;[P] &quot;FoMo 即服务“：将您的模型与 (Fo)undational (Mo) 进行比较用于对象检测的 dels&quot; title=&quot;[P] “FoMo 即服务”：将您的模型与用于对象检测的 (Fo)undational (Mo)dels 进行比较” />; &lt;/a>; &lt;/td>;&lt;td>; &lt;! -- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，&lt;br/>;我们将在 &lt; a href=&quot;https://www.tenyks.ai/&quot;>;Tenyks&lt;/a>;，其中：&lt;/p>; &lt;ul>; &lt;li>;您将最喜欢的对象检测数据集（以及可选的模型预测）上传到 Tenyks平台&lt;/li>; &lt;li>;Tenyks 为您设置最先进的零样本对象检测基线（例如基于 SAM 的基线）&lt;/li>; &lt;li>;您将模型/注释与基础模型/注释进行比较使用平台对您的数据建模&lt;/li>; &lt;li>;=>;gt;您可以就基础模型是否对您的用例有益做出明智的决定&lt;/li>; &lt;/ul>; &lt;p>;如果这听起来令人兴奋 - 请在此处联系：[&lt;a href=&quot;mailto:social@tenyks. ai&quot;>;social@tenyks.ai&lt;/a>;](mailto:&lt;a href=&quot;mailto:social@tenyks.ai&quot;>;social@tenyks.ai&lt;/a>;)（主题为“&lt;strong>; FoMo Offer&lt;/strong>;”)&lt;/p>; &lt;p>;PS 下面是一个零样本拥抱面模型的例子，它把汽车仪表盘当作“汽车”来处理。 :)&lt;/p>; &lt;p>;&lt;a href=&quot;https://reddit.com/link/13uurn2/video/5yluexcosr2b1/player&quot;>;有趣的 Huggingface 模型边缘案例&lt;/a>;&lt;/p>; &lt;/div>; &lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/kazhdan_d&quot;>; /u/kazhdan_d &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13uurn2/p_fomo_as_a_service_compare_your_models_against/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13uurn2/p_fomo_as_a_service_compare_your_models_against/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>;&lt; /表>;</content><id> t3_13uurn2 </id><media:thumbnail url="https://external-preview.redd.it/wUaSYINqTxMnWIhlJyItg-DE0FBAqsMKmpHSH7cbzHA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3b032be1844bc44c6a94b1164ce57856f1816f5d"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13uurn2/p_fomo_as_a_service_compare_your_models_against/"/><updated> 2023-05-29T13:20:39+00:00</updated><published> 2023-05-29T13:20:39+00:00</published><title> [P]“FoMo 即服务”：将您的模型与用于对象检测的 (Fo)undational (Mo)dels 进行比较</title></entry><entry><author><name>/u/姆班多</name><uri>https://www.reddit.com/user/Mbando </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;ol>; &lt;li>;协同驾驶文档/填写表格的模型在概念上是否与问答模型不同？&lt;/li>; &lt;li>;如果是这样，关于训练那种模型的任何资源（博客文章、教程）？&lt;/li>; &lt;/ol>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Mbando&quot;>; /u/Mbando &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13uymug/d_resources_for_documentwriting_models/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13uymug/d_resources_for_documentwriting_models/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13uymug </id><link href="https://www.reddit.com/r/MachineLearning/comments/13uymug/d_resources_for_documentwriting_models/"/><updated> 2023-05-29T15:53:59+00:00</updated><published> 2023-05-29T15:53:59+00:00</published><title> [D] 文档编写模型的资源？</title></entry><entry><author><name> /你/窗口</name><uri>https://www.reddit.com/user/windoze </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;背景：&lt;/p>; &lt;p>;我一直在研究如何创建循环 seq-to-seq 模型，这&amp;# 39;不是变形金刚。我实施的想法行不通。似乎偏离了常走的路，到处都是陷阱——我应该如何调整参数、添加偏差、归一化、这个数据集是不可能的、梯度爆炸和消失等等。&lt;/p>; &lt;p>;来自“research =梯度下降”从一个角度来看，我被困在一个没有梯度的点上——我不知道我做错了什么，或者怎么做才能得到更好的结果。我是否缺少工作流程。直觉、工具或其他东西？&lt;/p>; &lt;p>;你使用什么元方法来获得结果？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/windoze&quot;>; /u/windoze &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13ur6sh/d_research_method_and_advice/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13ur6sh/d_research_method_and_advice/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13ur6sh </id><link href="https://www.reddit.com/r/MachineLearning/comments/13ur6sh/d_research_method_and_advice/"/><updated> 2023-05-29T10:38:19+00:00</updated><published> 2023-05-29T10:38:19+00:00</published><title> [D] 研究方法与建议．</title></entry></feed>