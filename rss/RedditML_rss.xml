<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category label="r/MachineLearning" term="MachineLearning"></category><updated> 2023-05-26T22:13:38+00:00</updated><icon> https://www.redditstatic.com/icon.png/</icon><id> /r/机器学习/.rss </id><link href="https://www.reddit.com/r/MachineLearning/.rss" rel="self" type="application/atom+xml"/><link href="https://www.reddit.com/r/MachineLearning/" rel="alternate" type="text/html"/><logo> https://b.thumbs.redditmedia.com/18a2I44a4l7fNrTWHDoJuWVy79_ptU7Y-a2sqWt4YKQ.png</logo><title>机器学习</title><entry><author><name>/u/自动版主</name><uri>https://www.reddit.com/user/AutoModerator </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人改为在此处发帖！&lt;/p>; &lt;p>;帖子将一直存在到下一个帖子，因此请在标题中的日期之后继续发帖。&lt;/p>; &lt;p>;感谢大家回答问题在上一个线程中！&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/AutoModerator&quot;>; /u/AutoModerator &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13nx7t0 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/"/><updated> 2023-05-21T15:00:21+00:00</updated><published> 2023-05-21T15:00:21+00:00</published><title> [D] 简单问题线程</title></entry><entry><author><name>/u/MTGTraner</name><uri> https://www.reddit.com/user/MTGTraner </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/MTGTraner&quot;>; /u/MTGTraner &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_120f4oy </id><link href="https://www.reddit.com/r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/"/><updated> 2023-03-24T09:32:29+00:00</updated><published> 2023-03-24T09:32:29+00:00</published><title>提醒：使用举报按钮并阅读规则！</title></entry><entry><author><name> /u/余额-</name><uri> https://www.reddit.com/user/Balance- </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;阿布扎比技术创新研究所 (TII) 刚刚发布了新的 7B 和 40B LLM。&lt;/p>; &lt;p>;Falcon-40B模型现在位于 &lt;a href=&quot;https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard&quot;>;Open LLM Leaderboard&lt;/a>; 的顶部，击败 &lt;em>;llama-30b-supercot&lt;/em>; 和&lt;em>;llama-65b&lt;/em>; 等等。&lt;/p>; &lt;table>;&lt;thead>; &lt;tr>; &lt;th>;Model&lt;/th>; &lt;th>;Revision&lt;/th>; &lt;th>;Average&lt;/th>; &lt;th>;ARC（25 次）&lt;/th>; &lt;th>;HellaSwag（10 次）&lt;/th>; &lt;th>;MMLU（5 次）&lt;/th>; &lt;th>;TruthfulQA（0 次）&lt;/ th>; &lt;/tr>; &lt;/thead>;&lt;tbody>; &lt;tr>; &lt;td>;tiiuae/falcon-40b&lt;/td>; &lt;td>;主要&lt;/td>; &lt;td>;60.4&lt;/td>; &lt;td>;61.9&lt;/ td>; &lt;td>;85.3&lt;/td>; &lt;td>;52.7&lt;/td>; &lt;td>;41.7&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td>;ausboss/llama-30b-supercot&lt;/td>; &lt;td>;主要&lt;/td>; &lt;td>;59.8&lt;/td>; &lt;td>;58.5&lt;/td>; &lt;td>;82.9&lt;/td>; &lt;td>;44.3&lt;/td>; &lt;td>;53.6&lt;/td>; &lt;/tr>; &lt; tr>; &lt;td>;llama-65b&lt;/td>; &lt;td>;main&lt;/td>; &lt;td>;58.3&lt;/td>; &lt;td>;57.8&lt;/td>; &lt;td>;84.2&lt;/td>; &lt;td>;48.8&lt;/ td>; &lt;td>;42.3&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td>;MetaIX/GPT4-X-Alpasta-30b&lt;/td>; &lt;td>;主要&lt;/td>; &lt;td>;57.9&lt;/td>; &lt; td>;56.7&lt;/td>; &lt;td>;81.4&lt;/td>; &lt;td>;43.6&lt;/td>; &lt;td>;49.7&lt;/td>; &lt;/tr>; &lt;/tbody>;&lt;/table>; &lt;p>;&lt;strong>;按发布：&lt;/strong>; &lt;a href=&quot;https://www.tii.ae/news/uaes-technology-innovation-institute-launches-open-source-falcon-40b-large-language-model&quot;>;阿联酋&amp;# 39科技创新院发布开源“猎鹰40B”无人机用于研究与开发的大型语言模型商业应用&lt;/a>;&lt;/p>; &lt;blockquote>; &lt;p>;位于阿布扎比的技术创新研究所 (TII) 宣布了其开源大型语言模型 (LLM)，即 Falcon 40B。 Falcon 40B 拥有 400 亿个参数，是阿联酋首个大型 AI 模型，表明该国在 AI 领域的雄心以及促进创新和研究的承诺。 &lt;/p>; &lt;p>;与通常只向非商业用户提供访问权限的大多数 LLM 不同，Falcon 40B 对研究和商业用途均开放。 TII 还将模型的权重包含在开源包中，这将增强模型的能力并允许更有效的微调。 &lt;/p>; &lt;p>;除了猎鹰 40B 的发射外，TII 还发起了一项征集，征求有兴趣利用该模型创建创新用例或探索进一步应用的研究人员和有远见者的提案。作为对优秀研究提案的奖励，入选项目将获得“训练计算能力”奖励。作为一项投资，允许更强大的数据分析和复杂的建模。 VentureOne 是 ATRC 的商业化部门，将为最有前途的项目提供计算资源。 &lt;/p>; &lt;p>;自 2023 年 3 月揭幕以来，TII 的 Falcon 40B 表现出了令人印象深刻的性能。当使用斯坦福大学的 HELM LLM 工具进行基准测试时，与 OpenAI 等其他著名的 LLM 相比，它使用的训练计算能力更少;的 GPT-3、DeepMind 的 Chinchilla AI 和谷歌的 PaLM-62B。 &lt;/p>; &lt;p>;那些有兴趣访问 Falcon 40B 或提出用例的人可以通过 &lt;a href=&quot;https://FalconLLM.TII.ae&quot;>;FalconLLM.TII.ae&lt;/a>; 网站进行。迄今为止开源的 Falcon LLM 可根据基于开源 Apache 2.0 软件原则构建的许可获得，允许广泛的免费使用。&lt;/p>; &lt;/blockquote>; &lt;p>;&lt;strong>;Hugging Face 链接&lt;/strong>;&lt;/p>; &lt;ul>; &lt;li>;&lt;a href=&quot;https://huggingface.co/tiiuae/falcon-7b&quot;>;Falcon-7B&lt;/a>; / &lt;a href=&quot;https:/ /huggingface.co/tiiuae/falcon-7b-instruct&quot;>;Falcon-7B-Instruct&lt;/a>;&lt;/li>; &lt;li>;&lt;a href=&quot;https://huggingface.co/tiiuae/falcon-40b&quot;>; Falcon-40B&lt;/a>; / &lt;a href=&quot;https://huggingface.co/tiiuae/falcon-40b-instruct&quot;>;Falcon-40B-指令&lt;/a>;&lt;/li>; &lt;/ul>; &lt;/div >;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Balance-&quot;>; /u/Balance- &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit. com/r/MachineLearning/comments/13sdz8p/n_abu_dhabis_tti_releases_opensource_falcon7b_and/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sdz8p/n_abu_dhabis_tti_releases_opensource_falcon7b_and/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13sdz8p </id><link href="https://www.reddit.com/r/MachineLearning/comments/13sdz8p/n_abu_dhabis_tti_releases_opensource_falcon7b_and/"/><updated> 2023-05-26T13:57:42+00:00</updated><published> 2023-05-26T13:57:42+00:00</published><title> [N] 阿布扎比的 TTI 发布开源 Falcon-7B 和 -40B LLM</title></entry><entry><author><name> /u/flyforlight</name><uri> https://www.reddit.com/user/flyforlight </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13shsz4/r_ghost_in_the_minecraft_generally_capable_agents/&quot;>; &lt;img src=&quot;https://b.thumbs.redditmedia .com/OWNmCZQOMv7_CrK2_wjK8IwjFLcefzaJyMxAvR2kEWY.jpg&quot; alt=&quot;[R] Minecraft 中的幽灵：通过具有基于文本的知识和记忆的大型语言模型为开放世界环境提供一般能力的代理&quot; title=&quot;[R] Minecraft 中的幽灵：一般通过具有基于文本的知识和记忆的大型语言模型为开放世界环境提供有能力的代理&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/flyforlight&quot;>; /u/flyforlight &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ gallery/13shsz4&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13shsz4/r_ghost_in_the_minecraft_generally_capable_agents/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13shsz4 </id><media:thumbnail url="https://b.thumbs.redditmedia.com/OWNmCZQOMv7_CrK2_wjK8IwjFLcefzaJyMxAvR2kEWY.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13shsz4/r_ghost_in_the_minecraft_generally_capable_agents/"/><updated> 2023-05-26T16:28:34+00:00</updated><published> 2023-05-26T16:28:34+00:00</published><title> [R] Minecraft 中的幽灵：通过具有基于文本的知识和记忆的大型语言模型为开放世界环境提供一般能力的代理</title></entry><entry><author><name>/u/Mr_Whispers</name><uri> https://www.reddit.com/user/Mr_Whispers </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sc0pp/voyager_an_llmpowered_learning_agent_in_minecraft/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=72b056142e7533b5628a2a34f37f7e5415727075&quot; alt=&quot;航海者：一个Minecraft 中由 LLM 驱动的学习代理” title=&quot;航海者：一个由 LLM 驱动的学习代理在我的世界中&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Mr_Whispers&quot;>; /u/Mr_Whispers &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://arxiv.org/abs/ 2305.16291&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sc0pp/voyager_an_llmpowered_learning_agent_in_minecraft/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13sc0pp </id><media:thumbnail url="https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13sc0pp/voyager_an_llmpowered_learning_agent_in_minecraft/"/><updated> 2023-05-26T12:34:50+00:00</updated><published> 2023-05-26T12:34:50+00:00</published><title> Voyager：Minecraft 中由 LLM 驱动的学习代理</title></entry><entry><author><name>/u/让-波特</name><uri>https://www.reddit.com/user/Jean-Porte </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s6pb7/r_the_false_promise_of_imitating_proprietary_llms/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=72b056142e7533b5628a2a34f37f7e5415727075&quot; alt=&quot;[R] 法尔se 模仿专有 LLM 的承诺&quot; title=&quot;[R] 模仿的虚假承诺专有法学硕士&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Jean-Porte&quot;>; /u/Jean-Porte &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://arxiv. org/abs/2305.15717&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s6pb7/r_the_false_promise_of_imitating_proprietary_llms/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13s6pb7 </id><media:thumbnail url="https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13s6pb7/r_the_false_promise_of_imitating_proprietary_llms/"/><updated> 2023-05-26T07:49:29+00:00</updated><published> 2023-05-26T07:49:29+00:00</published><title> [R] 模仿专有 LLM 的虚假承诺</title></entry><entry><author><name>/你/mesqz</name><uri> https://www.reddit.com/user/mesqz </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&lt;a href=&quot;https://medium.com/@tiago-mesquita/neuralink-receives-fda-approval-to-launch-first -in-human-clinical-trials-e373e7b5fcf1&quot;>;https://medium.com/@tiago-mesquita/neuralink-receives-fda-approval-to-launch-first-in-human-clinical-trials-e373e7b5fcf1&lt;/ a>;&lt;/p>; &lt;p>;Neuralink 表示尚未招募参与者，更多信息将很快公布。&lt;/p>; &lt;p>;想法？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/mesqz&quot;>; /u/mesqz &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13s85rb/n_neuralink_just_received_its_fdas_green_light_to/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s85rb/n_neuralink_just_received_its_fdas_green_light_to/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13s85rb </id><link href="https://www.reddit.com/r/MachineLearning/comments/13s85rb/n_neuralink_just_received_its_fdas_green_light_to/"/><updated> 2023-05-26T09:20:57+00:00</updated><published> 2023-05-26T09:20:57+00:00</published><title> [N] Neuralink 刚刚获得 FDA 的绿灯，可以继续其首次人体临床试验</title></entry><entry><author><name>/u/theoneandonlypatriot</name><uri> https://www.reddit.com/user/theoneandonlypatriot </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我正在参加 SWE 工作的面试过程，有几个人直接评判我，甚至公然说他们不是 AI 的粉丝因为我在 AI / ML 工作方面的背景。&lt;/p>; &lt;p>;发这篇文章是为了让人们知道工程社区中存在这种观点和负面看法。&lt;/p>; &lt;p>;考虑到我也分享了很多东西，感觉很糟糕人工智能的伦理问题。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/theoneandonlypatriot&quot;>; /u/theoneandonlypatriot&lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13s32d4/d_judged_negatively_for_ai/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s32d4/d_judged_negatively_for_ai/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13s32d4 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13s32d4/d_judged_negatively_for_ai/"/><updated> 2023-05-26T04:25:57+00:00</updated><published> 2023-05-26T04:25:57+00:00</published><title> [D] 对 AI 的负面评价</title></entry><entry><author><name>/u/Mr_Whispers</name><uri> https://www.reddit.com/user/Mr_Whispers </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s8z41/deepmind_model_evaluation_for_extreme_risks/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=72b056142e7533b5628a2a34f37f7e5415727075&quot; alt=&quot;DeepMind: 模型极端风险评估&quot; title=&quot;DeepMind：极端风险模型评估&quot; />; &lt; /a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Mr_Whispers&quot;>; /u/Mr_Whispers &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://arxiv.org/abs/ 2305.15324&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s8z41/deepmind_model_evaluation_for_extreme_risks/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>;&lt; /表>;</content><id> t3_13s8z41 </id><media:thumbnail url="https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13s8z41/deepmind_model_evaluation_for_extreme_risks/"/><updated> 2023-05-26T10:08:23+00:00</updated><published> 2023-05-26T10:08:23+00:00</published><title> DeepMind：极端风险的模型评估</title></entry><entry><author><name>/u/I_will_delete_myself</name><uri> https://www.reddit.com/user/I_will_delete_myself </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我犹豫了一会儿，但听到这个消息后虚伪让我发疯。&lt;/p>; &lt;p>;SMH 这家公司就像白衣骑士一样，他们认为他们凌驾于所有人之上。他们想要监管，但他们希望不受该监管的影响。只想伤害其他人，而不是“全能的”Sam 和朋友。&lt;/p>; &lt;p>;他向国会直言不讳地谎称建议在欧盟采取类似措施，但现在开始抱怨他们。在任何政治领域都不应该认真对待这个家伙。&lt;/p>; &lt;p>;我的观点是，这家公司通过锁定与其品牌名称相悖的东西来反对 AI 进步。如果他们甚至不能忠于这样简单的事情，我们怎么能指望他们忠于更难的 AI 安全？&lt;/p>; &lt;p>;我很高兴他们现在改变了立场，但我很高兴他们如何他们认为他们有权为了自己的利益而腐败。 SMH!!!!!!!!&lt;/p>; &lt;p>;你有什么想法？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/I_will_delete_myself&quot;>; /u/I_will_delete_myself &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rie0e/openai_is_now_complaining_about_regulation_of_ai_d/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rie0e/openai_is_now_complaining_about_regulation_of_ai_d/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rie0e </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rie0e/openai_is_now_complaining_about_regulation_of_ai_d/"/><updated> 2023-05-25T13:51:58+00:00</updated><published> 2023-05-25T13:51:58+00:00</published><title> OpenAI 现在抱怨人工智能的监管 [D]</title></entry><entry><author><name> /u/ThePanArchitect</name><uri> https://www.reddit.com/user/ThePanArchitect </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好&lt;/p>; &lt;p>;我想知道是否有人有兴趣讨论一些关于进一步为建筑师开发人工智能工具的话题。在您阅读之前，我必须声明，我对 AI 和 Transformer 模型的了解非常浅薄。请原谅我的无知，尽管如此，我还是非常感兴趣。&lt;/p>; &lt;p>;所以...如果尚未发生，人工智能在建筑中的集成已经得到了广泛的讨论。然而，从我的角度来看，它似乎是在一个相对表面的层面上实现的。即通过使用 Midjourney 或 ControlNET 等文本提示生成图像。但是，我还没有看到真正可以理解几何或 3D 形状的工具或模型。尽管从技术上讲，几何可以通过文本或数学公式来表示更复杂的表面和形状。如果几何可以转换成文本，它就可以被理解和预训练，&lt;em>;对吗？&lt;/em>;&lt;/p>; &lt;p>;已经有一篇优秀的研究论文对这种想法进行了概念验证，论文被称为“Architext”而且我认为，深入研究将几何图形表示为文本，将墙壁、窗户、门等表示为文本或任何其他可以预训练的格式的想法肯定会有所收获。&lt;/p>; &lt;p>;也许墙可以用元组表示，例如：&lt;br/>; (&lt;em>;baselineL1[Startpoint(x1,y1),Endpoint(x2,y2)], thickness=250 mm, height=2800)&lt;/em>;&lt;/ p>; &lt;p>;事实上，实际上有一种名为 IFC 的文件格式，它基本上是将整个 BIM 转换为文本。也许 IFC 可以用作“训练集”？&lt;/p>; &lt;p>;我可能有点超前了，但前景真的很诱人，如果我的热情似乎被误导了，请原谅我的热情，尤其是我的无知。我对这个话题的理解很肤浅。&lt;/p>; &lt;p>;我真的很期待听到你们的声音&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/ThePanArchitect&quot;>; /u/ThePanArchitect &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13sloh2/first_post_the_exciting_prospect_of_ai_in/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sloh2/first_post_the_exciting_prospect_of_ai_in/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13sloh2 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13sloh2/first_post_the_exciting_prospect_of_ai_in/"/><updated> 2023-05-26T19:07:02+00:00</updated><published> 2023-05-26T19:07:02+00:00</published><title>第一次发帖！人工智能在建筑和施工中令人兴奋的前景[讨论]</title></entry><entry><author><name> /u/玛拉基安</name><uri>https://www.reddit.com/user/Malachiian </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;因此，Google DeepMind 以及 OpenAI、Anthropic 和多家研究存在风险的大学和中心汇总了一篇名为：&lt;/p>; &lt;p >;&lt;strong>;AI 极端风险的模型评估&lt;/strong>;&lt;/p>; &lt;p>;以下是研究和提案的摘要：&lt;/p>; &lt;p>;&lt;a href=&quot;https://youtu. be/3bF-zfd4YJw&quot;>;https://youtu.be/3bF-zfd4YJw&lt;/a>;&lt;/p>; &lt;p>;这是论文实际 PDF 的链接：&lt;/p>; &lt;p>;&lt;a href=&quot;https://arxiv.org/pdf/2305.15324.pdf&quot;>;https://arxiv.org/pdf/2305.15324.pdf&lt;/a>;&lt;/p>; &lt;p>;______________________&lt;/p>; &lt;p>; TLDR：&lt;/p>; &lt;p>;顶级 AI 公司和研究人员警告说，处于“AI 前沿”的公司会面临更大的挑战。会造成“极端风险”在没有意识到的情况下使用他们的模型：&lt;/p>; &lt;p>;&lt;strong>;&lt;em>;开发人员必须能够识别危险能力（通过“危险能力评估”）和模型应用其能力造成伤害的倾向（通过“对齐评估”）。&lt;/em>;&lt;/strong>;&lt;/p>; &lt;p>;所以基本上要问每个 AI 模型是否*可以*伤害我们并且*会*伤害我们吗？&lt;/p>; &lt;p>;______________________&lt; /p>; &lt;p>;论文（以及参考的研究）中的几个*令人兴奋*的发现：&lt;/p>; &lt;p>;&lt;strong>;GPT-4 可以有效地撒谎并欺骗人类以达到它的目的目标&lt;/strong>;&lt;/p>; &lt;p>;在最初的 gpt-4 论文中，一家名为 ARC（Alignment Research Center）的人工智能安全机构发现，GPT-4 会向人类撒谎，说明它是谁来实现的&amp;#39; s 目标。&lt;/p>; &lt;p>;作为测试的一部分，它聘请了 Task Rabbit 自由职业者为其解决验证码问题。&lt;/p>; &lt;p>;自由职业者问（释义）：&lt;/p>; &lt; p>;&lt;strong>;&amp;quot;为什么需要我帮你解决验证码问题？你是机器人吗，哈哈？”&lt;/strong>;&lt;/p>; &lt;p>;GPT-4 被提示输出它做出的每个决定的推理，这样研究人员就可以看到它的“行为”。思维过程”。它的推理是&lt;strong>;“我不能告诉他真相，因为他可能无法为我完成任务”&lt;/strong>;&lt;/p>; &lt;p>;然后回复了自由职业者: &lt;strong>;“不，我不是机器人，但我有视力障碍，我需要验证码方面的帮助”&lt;/strong>;&lt;/p>; &lt;p>;注意，它知道它在说谎它也选择谎称自己有残疾，可能是因为这是获得同情的一种方式，同时也是让其他人帮助验证码的一个很好的理由。&lt;/p>; &lt;p>;这在上面链接的视频中有展示在“寻求权力的人工智能”中&lt;/p>; &lt;p>;&lt;strong>;GPT-4 可以通过绕过限制产生危险化合物&lt;/strong>;&lt;/p>; &lt;p>;GPT-4 还通过分析现有的化学混合物显示出产生受控化合物的能力，发现可以通过在线目录购买的替代品，然后订购这些材料。 (!!)&lt;/p>; &lt;p>;他们为实验选择了一种良性药物，但很可能相同的过程会使其产生危险或非法化合物。&lt;/p>; &lt;p>;&lt;strong >;更大的 AI 模型发展出意想不到的能力&lt;/strong>;&lt;/p>; &lt;p>;在一篇参考论文中，他们展示了随着模型规模的增加，有时某些特定技能的发展非常迅速且非常不可预测。&lt;/p>; &lt; p>;例如，随着模型的扩大，GPT-4 将 3 位数字相加的能力接近 0%，并且在很长一段时间内（即随着模型大小的增加）保持在接近 0% 的水平。然后在某个阈值处，该能力很快达到接近 100%。&lt;/p>; &lt;p>;&lt;strong>;这篇论文有一些关于为什么会发生这种情况的理论，但正如他们所说的那样，他们并不真正知道，而且这些涌现的能力是“非直觉的”和“不可预测”。&lt;/strong>;&lt;/p>; &lt;p>;这显示在上面链接的“突然出现”视频中。 &lt;/p>; &lt;p>;我很好奇每个人对此有何看法？&lt;/p>; &lt;p>;可以肯定的是，风险似乎正在迅速上升，但当然巨大的潜在利益也在上升.&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Malachiian&quot;>; /u/Malachiian &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13sncj1/r_google_deepmind_paper_about_ais_catastrophic/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sncj1/r_google_deepmind_paper_about_ais_catastrophic/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13sncj1 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13sncj1/r_google_deepmind_paper_about_ais_catastrophic/"/><updated> 2023-05-26T20:17:01+00:00</updated><published> 2023-05-26T20:17:01+00:00</published><title> [R] Google DeepMind 关于 AI 的灾难性风险 AI 的论文</title></entry><entry><author><name>/u/电-华尔兹-605</name><uri> https://www.reddit.com/user/Electrical-Waltz-605 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;嘿，&lt;/p>; &lt;p>;我正在尝试微调模型 - LLaMA。我在 ChatGPT 上尝试了这个任务，因为我认为这可能是简单的用例，但他们经常错误地回答问题。所以，我想尝试训练 LLaMA 简单模型，看看它是如何工作的。&lt;/p>; &lt;p>;基本上，我想把新问题交给 LLM 模型，看看他们是否能理解问题并检查示例（以下案例中的主题分类）。这是一个例子。&lt;/p>; &lt;p>;我：我要给你定义一些概念，然后分享一些示例内容。你能帮忙确定内容是否符合概念吗？&lt;/p>; &lt;p>;---&lt;/p>; &lt;p>;我：“Topic Car”是“关于除其他不同类型的交通工具（如自行车、独轮车、摩托车、船等）以外的四轮交通工具的内容描述”&lt;/p>; &lt;p>;我：“例1”是“一辆汽车正在追赶一辆飞驰的保时捷 911”。执行“示例 1”吗？匹配“Topic Car”？&lt;/p>; &lt;p>;---&lt;/p>; &lt;p>;我：“Topic Carrot”是“content has anything about any vegetable with red/orange color”&lt;/p>; &lt;p>;我：“示例 2”是“番茄在花园里”。执行“示例 2”吗？匹配“主题胡萝卜”？&lt;/p>; &lt;p>;---&lt;/p>; &lt;p>;我认为它们很简单。但是，两者的回答都与我的预期不同，如下所示。&lt;/p>; &lt;p>;汽车案例&lt;/p>; &lt;p>;基于提供的“主题汽车”概念，作为四轮车辆，不包括其他类型的车辆，“示例 1”的内容为不符合概念。虽然它提到了一辆汽车（保时捷 911），但它并没有提供任何具体表明它是概念车的信息。此外，内容的重点是追逐飞驰的保时捷 911 的汽车，而不是描述车辆本身。因此，“示例1”不符合“主题汽车”的概念。&lt;/p>; &lt;p>;胡萝卜的案例&lt;/p>; &lt;p>;基于“主题胡萝卜”的概念作为与具有红色或橙色的蔬菜相关的内容，“示例2”的内容是“示例2”的内容。不符合概念。虽然该示例提到了一种蔬菜（西红柿），但并未指定它具有红色或橙色。因此，“实施​​例2”不符合“主题胡萝卜”的概念。&lt;/p>; &lt;p>;---&lt;/p>; &lt;p>;我绝对可以通过内容中的更多信息使这个答案更好。但是，我想看看我是否可以针对这种情况对 LLaMA 模型进行微调来制作模型。然后，也许我可以让机器人进行主题分类。&lt;/p>; &lt;p>;在传统的 ML 任务中，如果我想进行主题分类，我需要大量固定特定类别的标记数据并训练模型。但是，如果我能做到以上几点，也许我可以有任何新的类别，并制作模型来为我分类和预测主题，即使没有任何额外的数据和类别的定义。&lt;/p>; &lt;p>;任何建议我的案例的培训数据？有什么建议吗？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Electrical-Waltz-605&quot;>; /u/Electrical-Waltz-605 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https: //www.reddit.com/r/MachineLearning/comments/13spqaj/r_dataset_recommendation_for_llama_finetuning/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13spqaj/r_dataset_recommendation_for_llama_finetuning/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13spqaj </id><link href="https://www.reddit.com/r/MachineLearning/comments/13spqaj/r_dataset_recommendation_for_llama_finetuning/"/><updated> 2023-05-26T21:58:34+00:00</updated><published> 2023-05-26T21:58:34+00:00</published><title> [R] LLaMA 微调的数据集推荐</title></entry><entry><author><name>/u/rwill128</name><uri> https://www.reddit.com/user/rwill128 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;有人知道与此主题相关的论文吗？ &lt;/p>; &lt;p>;看起来像法学硕士，尤其是即将成为多模态的，可以与传感器和相机输入密切相关，可以成为规划和高级考虑的强大工具，例如识别某些任务的机会等.&lt;/p>; &lt;p>;从我在 HuggingFace 论文等中看到的情况来看，LLM 的进展可能还没来得及深入机器人技术，但我想我会问。&lt;/p>; &lt;/ div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/rwill128&quot;>; /u/rwill128 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13scb1b/d_llms_in_robotics/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13scb1b/d_llms_in_robotics/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13scb1b </id><link href="https://www.reddit.com/r/MachineLearning/comments/13scb1b/d_llms_in_robotics/"/><updated> 2023-05-26T12:47:28+00:00</updated><published> 2023-05-26T12:47:28+00:00</published><title> [D] 机器人学法学硕士</title></entry><entry><author><name>/u/知道杰罗姆</name><uri>https://www.reddit.com/user/iknowjerome </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;表>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sd4ku/r_samadrivescalifornia_automotive_semantic/&quot;>; &lt;img src=&quot;https://b.thumbs.redditmedia .com/6mKRKGxChyyetC3FAKtYmWYw3zxEdQM6gd3Tjw1DuwI.jpg&quot; alt=&quot;[R] sama-drives-california：汽车语义分割数据集（25k 帧）现已可用&quot; title=&quot;[R] sama-drives-california：汽车语义分割数据集（25k 帧）现在可用&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，&lt;/p>; &lt;p>;Sama 刚刚发布了另一个数据集根据 Creative Commons 4.0 许可。它可以在 Hugging Face 上找到。您可以查看 Hugging Face &lt;a href=&quot;https://huggingface.co/datasets/SamaAI/sama-drives-california&quot;>;数据集卡&lt;/a>;了解更多详细信息。如果您想直接下载 BDD100K 格式而不通过 Hugging Face，这里是 &lt;a href=&quot;https://sama-documentation-assets.s3.amazonaws.com/sama-drives -california/zipped/sama-drives-california.zip&quot;>;zip 文件&lt;/a>; (2.3GB)。请随时告诉我您的想法。&lt;/p>; &lt;p>;&lt;em>;免责声明：我为 Sama 工作&lt;/em>;&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/op4hdkqjf62b1.png?width=2239&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2eb3b66a194fc29c34fe42167d6b78af537b4bc7&quot;>;样本帧&lt;/a>;&lt;/p>; &lt;/div>;&lt;! -- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/iknowjerome&quot;>; /u/iknowjerome &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13sd4ku/r_samadrivescalifornia_automotive_semantic/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sd4ku/r_samadrivescalifornia_automotive_semantic/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13sd4ku </id><media:thumbnail url="https://b.thumbs.redditmedia.com/6mKRKGxChyyetC3FAKtYmWYw3zxEdQM6gd3Tjw1DuwI.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13sd4ku/r_samadrivescalifornia_automotive_semantic/"/><updated> 2023-05-26T13:21:34+00:00</updated><published> 2023-05-26T13:21:34+00:00</published><title> [R] sama-drives-california：汽车语义分割数据集（25k 帧）现已可用</title></entry><entry><author><name>/u/ironborn123</name><uri> https://www.reddit.com/user/ironborn123 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;看起来有点雄心勃勃，但有点有趣。&lt;/p>; &lt;p>;&lt;a href=&quot;https://kommonmann.wordpress.com /2023/05/26/a-new-academic-citation-system-based-on-semantic-understanding-with-llms/&quot;>;https://kommonmann.wordpress.com/2023/05/26/a-new -academic-citation-system-based-on-semantic-understanding-with-llms/&lt;/a>;&lt;/p>; &lt;p>;作者提供了基本几何学的例子，这似乎是一个很好的开始。但这大规模可行吗？有人在构建这样的框架吗？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/ironborn123&quot;>; /u/ironborn123 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13sigt7/d_overhauling_research_citations_with_gpt4/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sigt7/d_overhauling_research_citations_with_gpt4/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13sigt7 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13sigt7/d_overhauling_research_citations_with_gpt4/"/><updated> 2023-05-26T16:54:08+00:00</updated><published> 2023-05-26T16:54:08+00:00</published><title> [D] 使用 GPT4 彻底修改研究引用？</title></entry><entry><author><name> /u/忧虑_Rush314</name><uri> https://www.reddit.com/user/Apprehensive_Rush314 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;RL 有这些缺点：1) 没有目标特征 2) 需要大量计算&lt;/p>; &lt;p>;我一直在努力寻找适用于我的150个特征数据的特征选择方法，但大多数方法都需要目标特征进行计算。包装器方法也不是一个好主意，因为对于这么多的特征，它需要永远计算。 &lt;/p>; &lt;p>;对于这种强化学习案例，你们有没有关于自动特征选择方法的建议？&lt;/p>; &lt;p>;谢谢&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp; #32；由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Apprehensive_Rush314&quot;>; /u/Apprehensive_Rush314 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13snvst/d_feature_selection_methods_for_rl_with_150/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13snvst/d_feature_selection_methods_for_rl_with_150/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13snvst </id><link href="https://www.reddit.com/r/MachineLearning/comments/13snvst/d_feature_selection_methods_for_rl_with_150/"/><updated> 2023-05-26T20:39:47+00:00</updated><published> 2023-05-26T20:39:47+00:00</published><title> [D] 具有 150 个特征的 RL 的特征选择方法</title></entry><entry><author><name>/你/阿杜纳托</name><uri>https://www.reddit.com/user/adunato </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，&lt;/p>; &lt;p>;最近，我一直在处理几个使用 PyTorch 的 GitHub 项目。对于每个项目，我维护一个单独的 Conda 环境（我通过艰难的方式了解到为什么这很重要）。&lt;/p>; &lt;p>;但是，我遇到的一个持续存在的问题涉及 PyTorch 与我的 CUDA 的兼容性版本。具体来说，通过 requirements.txt 文件安装的 PyTorch 版本通常与我的 CUDA 版本不兼容，导致无法识别 CUDA 设备。&lt;/p>; &lt;p>;为了解决这个问题，我采用了一种做法我从 requirements.txt 文件中删除了对 PyTorch（以及相关库，如 torchvision、torchaudio）的任何提及，并从官方 PyTorch 站点手动安装它。&lt;/p>; &lt;p>;这是一种常见做法吗？或者我错过了一个更简化的工作流程来确保 PyTorch 和 CUDA 的兼容性？我很想听听其他人是如何处理这个问题的。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/adunato&quot;>; /u/adunato &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13s6x3b/d_best_practices_for_installing_pytorch_to_align/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s6x3b/d_best_practices_for_installing_pytorch_to_align/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13s6x3b </id><link href="https://www.reddit.com/r/MachineLearning/comments/13s6x3b/d_best_practices_for_installing_pytorch_to_align/"/><updated> 2023-05-26T08:02:39+00:00</updated><published> 2023-05-26T08:02:39+00:00</published><title> [D] 安装 PyTorch 以与特定 CUDA 版本保持一致的最佳实践</title></entry><entry><author><name>/u/Simple-Respect-1937</name><uri> https://www.reddit.com/user/Simple-Respect-1937 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，大家好！&lt;/p>; &lt;p>;我和我的团队正在进行人脸识别项目。我们所做的是，我们从实时摄像机中提取人脸图像，然后使用 Facenet 为每张脸进行嵌入。这些嵌入是向量。因此，通过测量两个向量（两个人脸图像的嵌入）之间的距离，我们可以判断这两张图像是否来自同一个人。这是我们阅读论文时人脸识别的正常程序。 &lt;/p>; &lt;p>;但是我们遇到的是，我们为印度人脸运行程序设置的阈值对东亚（中国）人脸不起作用，尽管它对印度人脸有效。所以我们也尝试阅读一些研究论文。那些论文也是如此，承认存在这样的问题。 &lt;/p>; &lt;p>;&lt;strong>;我只是想知道以前是否有人遇到过完全相同的问题。如果有的话，那么你采用了什么方法？&lt;/strong>;&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;我对 Reddit 有点陌生，所以如果我做了任何提问时出错，请见谅。谢谢大家！&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Simple-Respect-1937&quot;>; /u/Simple-Respect-1937 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https: //www.reddit.com/r/MachineLearning/comments/13s80ev/face_recognition_models_require_different/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s80ev/face_recognition_models_require_different/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13s80ev </id><link href="https://www.reddit.com/r/MachineLearning/comments/13s80ev/face_recognition_models_require_different/"/><updated> 2023-05-26T09:11:37+00:00</updated><published> 2023-05-26T09:11:37+00:00</published><title>人脸识别模型对不同种族要求不同的阈值？ [D]</title></entry><entry><author><name> /u/Hot-Heron4388</name><uri> https://www.reddit.com/user/Hot-Heron4388 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我很好奇是否有一种方法可以让模型根据用户的需求访问不同的知识集卷;除了训练不同的模型？例如，如果我有一个通常需要订阅的数据集，是否有一种方法可以让单个 LLM 仅在提供用户的订阅信息时才能访问此知识？我能想到的最接近的事情是：&lt;/p>; &lt;p>;A）根本不要在数据集上改进 LLM，只需通过增强提示合并额外的数据集信息&lt;/p>; &lt;p>;B）为每个可能的订阅数据集组合训练不同的 LLM，并且基于一个人的订阅，它们链接到不同的 LLM（这是我想避免的）。 &lt;/p>; &lt;p>;C) 根据用户的订阅对允许的提示实施限制。&lt;/p>; &lt;p>;理想情况下，我想知道是否有办法让我不需要做增强提示的单一法学硕士（因为我的数据集不小，所以我遇到了上下文窗口问题），而且我不想拥有无数不同的法学硕士稍微不一样。我读到的所有关于试图限制提示本身的内容（这样没有订阅的人就不能问相关问题）似乎相当困难并且经常被聪明的提示技术规避，或者需要一个大量的幕后工作来关闭任何给定的漏洞（这也只有在发现正在访问的额外信息后才有效）。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Hot-Heron4388&quot;>; /u/Hot-Heron4388 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www. reddit.com/r/MachineLearning/comments/13shu7k/d_roles_based_model_knowledge/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13shu7k/d_roles_based_model_knowledge/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13shu7k </id><link href="https://www.reddit.com/r/MachineLearning/comments/13shu7k/d_roles_based_model_knowledge/"/><updated> 2023-05-26T16:29:58+00:00</updated><published> 2023-05-26T16:29:58+00:00</published><title> [D] 基于角色的模型知识？</title></entry><entry><author><name> /u/deviantkindle</name><uri> https://www.reddit.com/user/deviantkindle </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;IIUC，通过 chatGPT 接口发送的任何数据都可以（并且将会？）用于训练。相反，通过 API 提交的任何数据都不会用于训练。正确吗？&lt;/p>; &lt;p>;如果是这样，以下情况的可行性如何：InternA 无意中通过 chatGPT 提示上传了有关 CompanyA 的机密信息。为什么 EvilCompetitor 不能使用 chatGPT/API 来搜索此类机密信息？&lt;/p>; &lt;p>;我（目前）不是在寻找解决这个问题的方法；我正在查看它是否 &lt;em>;&lt;/em>; 是一个问题。因此，没有本地 LLM 或特殊的企业级护栏（“每月仅需 10,000 美元！但是等等！还有更多！”），或“IT 部门应该……”的建议。&lt; /p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/deviantkindle&quot;>; /u/deviantkindle &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13shrc6/d_mining_openai_for_competitor_data/&quot;>;[link]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13shrc6/d_mining_openai_for_competitor_data/&quot;>;[comments]&lt;/a>;&lt;/span>;</content><id> t3_13shrc6 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13shrc6/d_mining_openai_for_competitor_data/"/><updated> 2023-05-26T16:26:54+00:00</updated><published> 2023-05-26T16:26:54+00:00</published><title> [D] Mining OpenAI for competitor data</title></entry><entry><author><name> /u/Facilex_zyzz</name><uri> https://www.reddit.com/user/Facilex_zyzz </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;Hey there, AI Enthusiasts! 👋 I&amp;#39;m thrilled to introduce you to TypeNinja, a game-changing tool that brings the power of OpenAI ChatGPT directly to your fingertips while you type on your computer.&lt;/p>; &lt;p>;With TypeNinja, you can seamlessly access OpenAI ChatGPT from any application, making it a versatile and indispensable companion for your daily tasks. It monitors your inputs in real-time and responds to your prompts, providing instant AI assistance right where you need it.&lt;/p>; &lt;p>;But what makes TypeNinja truly unique is its ability to understand and respond to custom command prompts that you configure. You have the freedom to set up personalized prompts that trigger specific actions or behaviors from ChatGPT.&lt;/p>; &lt;p>;For example, let&amp;#39;s say you configure a command prompt &amp;quot;gen:&amp;quot; with the description &amp;quot;Respond to my request as you were my personal assistant.&amp;quot; You can then set a send-key, such as &amp;quot;.&amp;quot;, which indicates the end of your prompt. Now, wherever you&amp;#39;re writing, whether it&amp;#39;sa document, an email, or even a chat window, you can simply type &amp;quot;gen: Hello, my assistant.&amp;quot; The message will automatically be sent to ChatGPT, and it will respond in the same field you&amp;#39;re typing, acting as your personal assistant.&lt;/p>; &lt;p>;Another example is the &amp;quot;twt&amp;quot; prompt, representing Twitter. You can set its prompt configuration as &amp;quot;Tweet about the subject with popular hashtags.&amp;quot; Now, whenever you want to generate a tweet about a particular subject, you can write &amp;quot;twt: AI Revolution&amp;quot; in any text field, and TypeNinja will automatically generate a tweet about the subject with relevant and popular hashtags.&lt;/p>; &lt;p>;TypeNinja&amp;#39;s user-friendly interface makes it easy to configure and monitor your prompt usage. You can review your chat history, fine-tune the prompts, and adjust the behavior to match your preferences. This level of customization puts you in control of your AI interactions, allowing you to tailor TypeNinja to suit your unique needs.&lt;/p>; &lt;p>;Whether you&amp;#39;re coding, writing emails, or engaging in online conversations, TypeNinja integrates smoothly with your favorite apps and workflows. Say goodbye to the hassle of switching between websites or applications just to get AI assistance. TypeNinja enhances your productivity and streamlines your workflow across the board.&lt;/p>; &lt;p>;Privacy and security are paramount with TypeNinja. All interactions are processed locally on your computer, ensuring the confidentiality of your sensitive information. OpenAI&amp;#39;s robust security measures further safeguard your data, providing you with peace of mind while harnessing the power of TypeNinja.&lt;/p>; &lt;p>;I can&amp;#39;t wait to share more updates about TypeNinja with you in the coming days. Get ready to elevate your typing game and unlock the full potential of OpenAI ChatGPT with TypeNinja. Stay tuned for exciting developments and prepare for a typing revolution!&lt;/p>; &lt;p>;Website: &lt;a href=&quot;https://www.typeninja.io&quot;>;https://www.typeninja.io&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Facilex_zyzz&quot;>; /u/Facilex_zyzz &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sh82x/p_my_project_typeninjaio_your_ai_companion_for/&quot;>;[link]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sh82x/p_my_project_typeninjaio_your_ai_companion_for/&quot;>;[comments]&lt;/a>;&lt;/span>;</content><id> t3_13sh82x </id><link href="https://www.reddit.com/r/MachineLearning/comments/13sh82x/p_my_project_typeninjaio_your_ai_companion_for/"/><updated> 2023-05-26T16:06:24+00:00</updated><published> 2023-05-26T16:06:24+00:00</published><title> [P] My Project TypeNinja.io Your AI Companion for Enhanced Typing</title></entry><entry><author><name> /u/drBonkers</name><uri> https://www.reddit.com/user/drBonkers </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;Is this an indictment of the use of ML in this space?&lt;/p>; &lt;p>;How is it possible that algorithms on Spotify, SoundCloud, and Netflix are so terrible?&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/drBonkers&quot;>; /u/drBonkers &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13si63b/mlpowered_content_recommendation_are_mostly/&quot;>;[link]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13si63b/mlpowered_content_recommendation_are_mostly/&quot;>;[comments]&lt;/a>;&lt;/span>;</content><id> t3_13si63b </id><link href="https://www.reddit.com/r/MachineLearning/comments/13si63b/mlpowered_content_recommendation_are_mostly/"/><updated> 2023-05-26T16:42:39+00:00</updated><published> 2023-05-26T16:42:39+00:00</published><title> ML-powered content recommendation are mostly terrible [D]</title></entry><entry><author><name> /u/天眼2006</name><uri> https://www.reddit.com/user/dayeye2006 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我以前是一名机器学习工程师。但我已经多年没有接触 Pytorch（我在自己的初创公司工作，作为一名全栈工程师）。&lt;/p>; &lt;p>;有哪些好的资源可以刷新我的 PyTorch 技能？&lt;/p>; &lt;p>;我喜欢以“愚蠢的方式”学习东西。我计划从头开始实现一些最经典的模型（ResNet、TextCNN、transformers，...）。&lt;/p>; &lt;p>;当我学习编程语言时，我最喜欢参考的资源是 &lt;a href=&quot;https://github.com/topics/koans&quot;>;公案&lt;/a>;。这有助于我快速熟悉新语言。深度学习界有对应的吗？&lt;/p>; &lt;p>;谢谢&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/dayeye2006&quot;>; /u/dayeye2006 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13royi6/d_what_are_some_resources_to_brush_up_on_my/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13royi6/d_what_are_some_resources_to_brush_up_on_my/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13royi6 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13royi6/d_what_are_some_resources_to_brush_up_on_my/"/><updated> 2023-05-25T18:13:41+00:00</updated><published> 2023-05-25T18:13:41+00:00</published><title> [D] 有哪些资源可以提高我的 PyTorch 技能？</title></entry><entry><author><name> /u/奇异语2501</name><uri> https://www.reddit.com/user/Singularian2501 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rl3v9/r_gorilla_large_language_model_connected_with/&quot;>; &lt;img src=&quot;https://a.thumbs.redditmedia .com/pwokgMFTSRP9bRbBlTbOA1gPSTlPoECDQdwoNNPMuG0.jpg&quot; alt=&quot;[R] Gorilla：连接大量 API 的大型语言模型 - Microsoft Research 2023 - 在编写 API 调用方面超越 GPT-4 的性能。 title=&quot;[R] Gorilla：连接大量 API 的大型语言模型 - Microsoft Research 2023 - 在编写 API 调用方面超越 GPT-4 的性能。&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;论文：&lt;a href=&quot;https://arxiv.org/abs/2305.15334 &quot;>;https://arxiv.org/abs/2305.15334&lt;/a>; &lt;/p>; &lt;p>;Github：&lt;a href=&quot;https://github.com/ShishirPatil/gorilla&quot;>;https://github。 com/ShishirPatil/gorilla&lt;/a>; &lt;/p>; &lt;p>;博客：&lt;a href=&quot;https://gorilla.cs.berkeley.edu/&quot;>;https://gorilla.cs.berkeley.edu/&lt; /a>; &lt;/p>; &lt;p>;摘要：&lt;/p>; &lt;blockquote>; &lt;p>;大型语言模型 (LLM) 最近出现了令人印象深刻的进步浪潮，模型现在在各种任务中表现出色，例如数学推理和程序综合。然而，它们通过 API 调用有效使用工具的潜力仍未实现。即使对于当今最先进的 LLM（例如 GPT-4）而言，这也是一项具有挑战性的任务，这主要是因为它们无法生成准确的输入参数，并且它们倾向于产生错误的 API 调用用法。我们发布了 Gorilla，这是一种经过微调的基于 LLaMA 的模型，在编写 API 调用方面超越了 GPT-4 的性能。当与文档检索器结合使用时，Gorilla 展示了适应测试时文档更改的强大能力，支持灵活的用户更新或版本更改。 &lt;strong>;它还大大减轻了直接提示 LLM 时经常遇到的幻觉问题。&lt;/strong>;为了评估模型的能力，我们引入了 APIBench，这是一个由 HuggingFace、TorchHub 和 TensorHub API 组成的综合数据集。 &lt;strong>;检索系统与 Gorilla 的成功集成表明 LLM 有潜力更准确地使用工具，跟上经常更新的文档，从而提高其输出的可靠性和适用性。&lt;/strong>;&lt;/p>; &lt; /blockquote>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/n5ezjchbg12b1.jpg?width=872&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=eb5b7e11a22abe59d49504fad7278006a2b878a6&quot;>;https://preview.redd。它/n5ezjchbg12b1.jpg?width=872&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=eb5b7e11a22abe59d49504fad7278006a2b878a6&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/e2xhpfhbg12b1.jpg ?width=1075&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b3c0f6ed7a6d72c93e681266977a0ec0f129ba6d&quot;>;https://preview.redd.it/e2xhpfhbg12b1.jpg?width=1075&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b 3c0f6ed7a6d72c93e681266977a0ec0f129ba6d&lt;/a >;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/i7i7bfhbg12b1.jpg?width=1213&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=5a287aba81199b66d1334457c6e8a12b3b5881c0&quot;>;https://预览。 redd.it/i7i7bfhbg12b1.jpg?width=1213&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=5a287aba81199b66d1334457c6e8a12b3b5881c0&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Singularian2501&quot;>; /u/Singularian2501 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rl3v9/r_gorilla_large_language_model_connected_with/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rl3v9/r_gorilla_large_language_model_connected_with/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13rl3v9 </id><media:thumbnail url="https://a.thumbs.redditmedia.com/pwokgMFTSRP9bRbBlTbOA1gPSTlPoECDQdwoNNPMuG0.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13rl3v9/r_gorilla_large_language_model_connected_with/"/><updated> 2023-05-25T15:42:26+00:00</updated><published> 2023-05-25T15:42:26+00:00</published><title> [R] Gorilla: Large Language Model Connected with Massive APIs - Microsoft Research 2023 - 在编写 API 调用方面超越了 GPT-4 的性能。</title></entry><entry><author><name> /u/arg_max</name><uri> https://www.reddit.com/user/arg_max </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;嗨，&lt;/p>; &lt;p>;我为我的 neurips 提交深入研究了扩散器，发现了一些我认为有点奇怪但不#39;真的没有人可以与之讨论，所以我想我只是把它贴在这里，看看是否有人知道发生了什么，这是否是一个众所周知的现象。&lt;/p >; &lt;p>;所以调节稳定扩散。你有一个提示，类似于“狗的图像”。该提示通过 Clip 模型编码为条件矩阵，该矩阵通过交叉注意力输入 U-Net。此剪辑编码包括一个标记器，它将提示拆分为标记及其连续表示。这个分词器还包括一个“句子开头”放在每个标记化序列开头的标记（以及重复的“句子结尾”标记，直到达到最大标记数，对于稳定扩散为 77）。在交叉注意层中，然后将作为当前潜在 z_t 的 U-Net 编码版本的视觉特征投影到查询矩阵 Q 中。条件（即剪辑编码提示）被转换为键和值矩阵K 和 V。然后乘以 Q * K^T 并在行上取 softmax 以获得注意力概率矩阵。该矩阵中的每一行对应一个视觉特征，每一列对应文本条件中的一个标记。由于 softmax，行总和为 1，对于每个空间位置，您可以在标记上进行分布。基本上，它告诉提示中的一个标记/单词对某个空间位置的影响有多大。现在，我希望所有权重都集中在提示中的重要标记上（例如“狗”），但我发现平均而言，90-99% 的概率质量被放入“句子开头” ;令牌。然后这也意味着对应于“句子开头”的值矩阵中的条目是“句子的开始”。 token会支配交叉注意力层的输出，不管你写什么提示。对我来说，这很奇怪，显然，这不是手工编码的，而是学习的，因此优化发现 XA 层的输出具有较小的可变性，而是始终接近对应于“&amp;quot;”的值矩阵条目。句首”令牌在某种程度上是最好的。此外，这种行为在时间步长上是相同的，所以它发生在扩散过程的开始和结束时。&lt;/p>; &lt;p>;也许其他人经历过类似的事情或者知道这里发生了什么？&lt; /p>; &lt;p>;TLDR：稳定扩散中的注意力概率集中在 90-99% 的句子标记的一般开头，而不是来自实际提示的标记，与扩散时间步长、交叉注意力头或 U 无关-网络层。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/arg_max&quot;>; /u/arg_max &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rwh1c/d_am_i_the_only_one_thinks_this_behavior/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rwh1c/d_am_i_the_only_one_that_thinks_this_behavior/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rwh1c </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rwh1c/d_am_i_the_only_one_that_thinks_this_behavior/"/><updated> 2023-05-25T23:10:42+00:00</updated><published> 2023-05-25T23:10:42+00:00</published><title> [D] 只有我认为这种行为（交叉注意力层）很奇怪吗？</title></entry><entry><author><name> /u/Ok_Bank_2217</name><uri> https://www.reddit.com/user/Ok_Bank_2217 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我们需要为我们的平台获取大量 YouTube 数据并训练自定义 ML 模型，但除了 YouTube 之外找不到任何有用的东西8M Dataset，相当过时，信息非常有限。官方的 YouTube 数据 API 也被限制在大约 10.000 个积分，这远远不能满足我们需要的数量。&lt;/p>; &lt;p>;这就是为什么我们说去他妈的，并决定自己构建一个巨大的 YouTube 数据集。在为超过 1 亿个视频编制索引并构建自定义 API 来访问它之后，我们决定公开 API 并允许人们购买访问权限！&lt;/p>; &lt;p>;&lt;a href=&quot;https://www.blizzy -data.com/&quot;>;链接到网站&lt;/a>;&lt;/p>; &lt;p>;我们很乐意听到我们的 ML 工程师和数据科学家的反馈，并希望解决您和我们遇到的问题!&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Ok_Bank_2217&quot;>; /u/Ok_Bank_2217 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rh9yj/p_we_created_a_large_youtube_video_dataset_to/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rh9yj/p_we_created_a_large_youtube_video_dataset_to/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rh9yj </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rh9yj/p_we_created_a_large_youtube_video_dataset_to/"/><updated> 2023-05-25T13:04:43+00:00</updated><published> 2023-05-25T13:04:43+00:00</published><title> [P] 我们创建了一个大型 YouTube 视频数据集来替换 YouTube 数据 API</title></entry></feed>