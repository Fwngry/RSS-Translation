<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category label="r/MachineLearning" term="MachineLearning"></category><updated> 2023-05-29T01:20:44+00:00</updated><icon> https://www.redditstatic.com/icon.png/</icon><id> /r/机器学习/.rss </id><link href="https://www.reddit.com/r/MachineLearning/.rss" rel="self" type="application/atom+xml"/><link href="https://www.reddit.com/r/MachineLearning/" rel="alternate" type="text/html"/><logo> https://b.thumbs.redditmedia.com/18a2I44a4l7fNrTWHDoJuWVy79_ptU7Y-a2sqWt4YKQ.png</logo><title>机器学习</title><entry><author><name>/u/自动版主</name><uri>https://www.reddit.com/user/AutoModerator </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人改为在此处发帖！&lt;/p>; &lt;p>;帖子将一直存在到下一个帖子，因此请在标题中的日期之后继续发帖。&lt;/p>; &lt;p>;感谢大家回答问题在上一个线程中！&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/AutoModerator&quot;>; /u/AutoModerator &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13nx7t0 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/"/><updated> 2023-05-21T15:00:21+00:00</updated><published> 2023-05-21T15:00:21+00:00</published><title> [D] 简单问题线程</title></entry><entry><author><name>/u/MTGTraner</name><uri> https://www.reddit.com/user/MTGTraner </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/MTGTraner&quot;>; /u/MTGTraner &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_120f4oy </id><link href="https://www.reddit.com/r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/"/><updated> 2023-03-24T09:32:29+00:00</updated><published> 2023-03-24T09:32:29+00:00</published><title>提醒：使用举报按钮并阅读规则！</title></entry><entry><author><name> /你/硬丸</name><uri>https://www.reddit.com/user/hardmaru </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13tqvdn/uncensored_models_finetuned_without_artificial/&quot;>; &lt;img src=&quot;https://preview.redd.it /jb5pl4n1xh2b1.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c1b0d8f5b3a6a9e5349d7a51af1b00ab5c575307&quot; alt=&quot;Uncensored models, fine-tuned without artificial moralizing, such as “Wizard-Vicuna-13B-Uncensored-HF”执行擅长LLM 评估基准，即使与更大的 65B、40B、30B 模型相比也是如此。有没有关于审查制度如何阻碍模型能力的研究？” title=&quot;Uncensored models, fine-tuned without artificial moralizing, such as “Wizard-Vicuna-13B-Uncensored-HF” 在 LLM 评估基准测试中表现良好，即使与更大的 65B、40B、30B 模型相比也是如此。是否有任何研究关于审查制度如何阻碍模型的能力？” />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/hardmaru&quot;>; /u/hardmaru &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://i.redd.it/ jb5pl4n1xh2b1.jpg&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13tqvdn/uncensored_models_finetuned_without_artificial/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13tqvdn </id><media:thumbnail url="https://preview.redd.it/jb5pl4n1xh2b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c1b0d8f5b3a6a9e5349d7a51af1b00ab5c575307"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13tqvdn/uncensored_models_finetuned_without_artificial/"/><updated> 2023-05-28T04:03:10+00:00</updated><published> 2023-05-28T04:03:10+00:00</published><title>未经审查的模型，在没有人工道德化的情况下进行微调，例如“Wizard-Vicuna-13B-Uncensored-HF”在 LLM 评估基准测试中表现良好，即使与更大的 65B、40B、30B 模型相比也是如此。是否有关于审查制度如何阻碍模型能力的研究？</title></entry><entry><author><name> /u/玛拉基安</name><uri>https://www.reddit.com/user/Malachiian </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;NVIDIA 使用 GPT-4 创建了一个围绕 Minecraft、探索和推进技术树的自主 AI 代理。&lt;/p>; &lt;p>;令人难以置信的是，该机器人会为自己编写脚本，使其更擅长玩游戏。所以如果它遇到一只蜘蛛，它会编写一个脚本来杀死那只蜘蛛。一旦该脚本开始工作，它就会将“技能”添加到该脚本中。到它的“技能库”。随着时间的推移，它不断进步并发展出更好的能力。&lt;/p>; &lt;p>;它的技能库也可以转移到其他 AI 代理，如 AutoGPT。&lt;/p>; &lt;p>;这是一个视频概述：&lt; /p>; &lt;p>;&lt;a href=&quot;https://youtu.be/7yI4yfYftfM&quot;>;https://youtu.be/7yI4yfYftfM&lt;/a>;&lt;/p>; &lt;p>;这是论文：&lt;/p >; &lt;p>;&lt;a href=&quot;https://arxiv.org/abs/2305.16291&quot;>;https://arxiv.org/abs/2305.16291&lt;/a>;&lt;/p>; &lt;p>;这是开源项目如果您想尝试或贡献：&lt;/p>; &lt;p>;&lt;a href=&quot;https://minedojo.org/&quot;>;https://minedojo.org/&lt;/a>;&lt;/p>; &lt;p >;这里的 GPT-4 被用作一种“推理引擎”。它决定在游戏中做什么，但它也创建代码以使自己变得更好并添加新技能供其使用。&lt;/p>; &lt;p>;另一件事是 GPT-4 没有视觉。所有数据都通过文本提示输入。&lt;/p>; &lt;p>;它被告知“你有一根钓鱼竿，你站在河边，你周围是沙块，并且一头猪。你想做什么？”。&lt;/p>; &lt;p>;&lt;strong>;这对软件开发人员意味着什么？&lt;/strong>;&lt;/p>; &lt;p>;似乎 GPT-4 现在可以自主创建，测试和优化代码。它决定它需要做什么，例如：&lt;/p>; &lt;p>;“Craft 1 Stone Ax”&lt;/p>; &lt;p>;然后它编写 JavaScript 代码来实现这一点，并进行测试以确保它&amp;#39;它正在工作，然后将它添加到一个库中，供以后使用。&lt;/p>; &lt;p>;&lt;strong>;这不能应用于工作任务 IRL 吗？&lt;/strong>;&lt;/p>; &lt;p>;相反的“craft AX”，为“write Email”制作一个脚本。&lt;/p>; &lt;p>;而不是“kill mob”为“为给定数据创建 excel 表”制作脚本&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Malachiian&quot;>; /u/Malachiian &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13ub8nq/r_nvidia_and_gpt4_create_a_minecraft_ai_that/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13ub8nq/r_nvidia_and_gpt4_create_a_minecraft_ai_that/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13ub8nq </id><link href="https://www.reddit.com/r/MachineLearning/comments/13ub8nq/r_nvidia_and_gpt4_create_a_minecraft_ai_that/"/><updated> 2023-05-28T21:09:14+00:00</updated><published> 2023-05-28T21:09:14+00:00</published><title> [R] NVIDIA 和 GPT-4 创建了一个可以编码和自我改进的 Minecraft AI。</title></entry><entry><author><name> /u/睡虎4</name><uri> https://www.reddit.com/user/Sleepin-tiger4 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;斯坦福发布了一个非凡的新二阶优化器，称为 Sophia，它使用估算器并利用裁剪机制。 &lt;/p>; &lt;blockquote>; &lt;p>;根据这篇论文，它的效率提高了 100K 步，计算所需的挂钟时间明显减少。&lt;/p>; &lt;/blockquote>; &lt;p>;这篇论文令人惊叹，是一个里程碑至少在我看来。他们没有提供任何代码，但提供了伪代码和算法来对优化器进行编程。我发现它有助于编程或理解代码，而不是仅仅阅读文献本身，甚至是它的伪代码。这就是为什么我花时间编写一个利用优化器的函数。 &lt;/p>; &lt;p>;如果您对他们使用的超参数感兴趣，在他们的论文中非常清楚，他们还提到使用网格搜索并基于 AdamW 获取 sophia 的超参数和 Lion 的参数选择。 &lt;/p>; &lt;p>;这是一个非常快的项目，所以我只能以非常基本的方式编写代码，没有任何 pytorch 或 jax。我很乐观地添加了一个训练脚本和一些漂亮的功能。直到几周后。 &lt;/p>; &lt;p>;我个人认为阅读代码和学习 Sophia 将非常有帮助，并且对许多人来说它可以提供一个新的研究方向（也许对你的论文也是如此）。我已将 github 链接添加到我的代码中。 &lt;/p>; &lt;p>;&lt;strong>;贡献：&lt;/strong>;&lt;/p>; &lt;p>;罗马不是自己建造的。如果您认为可以提供一些东西，请随时为存储库做出贡献。它会帮助其他人学习。你也是。如果您发现我的工作有趣或有帮助，请考虑给星标，这有助于许多人看到存储库，并有点激励我考虑为项目提供更新和很酷的东西。 &lt;/p>; &lt;p>;否则，这是 GitHub 代码和论文链接&lt;/p>; &lt;p>;&lt;strong>;GitHub 代码：&lt;/strong>; &lt;a href=&quot;https://github.com/ sleepingcat4/Sophia&quot;>;https://github.com/sleepingcat4/Sophia&lt;/a>;&lt;/p>; &lt;p>;&lt;strong>;论文链接：&lt;/strong>; &lt;a href=&quot;https://arxiv.org/ abs/2305.14342&quot;>;https://arxiv.org/abs/2305.14342&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Sleepin-tiger4&quot;>; /u/Sleepin-tiger4 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www. reddit.com/r/MachineLearning/comments/13u36x6/p_sophia_programmedout/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13u36x6/p_sophia_programmedout/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13u36x6 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13u36x6/p_sophia_programmedout/"/><updated> 2023-05-28T15:31:25+00:00</updated><published> 2023-05-28T15:31:25+00:00</published><title> [P] Sophia（程序外）</title></entry><entry><author><name> /你/塞拉施卡</name><uri>https://www.reddit.com/user/seraschka </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13u20mn/p_historical_tidbits_about_transformers_about/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/kUxj6CnxzIRDysMx6ikazH21j-o26FrLLdAlrUW-bCk.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=37090819bf367e44d271ed7dbdea2fe14d4fe5d9&quot; alt=&quot;[P] 关于变形金刚的历史花絮: 关于原始 Transformer 论文和 Schmidhuber 的 Fast 中的 LayerNorm 变体1990 年代的权重程序员&quot; title=&quot;[P] 关于 Transformers 的历史花絮：关于原始 Transformer 论文中的 LayerNorm 变体和 Schmidhuber 的 1990 年代的快速权重程序员&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &amp;# 32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/seraschka&quot;>; /u/seraschka &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://magazine.sebastianraschka.com/ p/why-the-original-transformer-figure&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13u20mn/p_historical_tidbits_about_transformers_about/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13u20mn </id><media:thumbnail url="https://external-preview.redd.it/kUxj6CnxzIRDysMx6ikazH21j-o26FrLLdAlrUW-bCk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=37090819bf367e44d271ed7dbdea2fe14d4fe5d9"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13u20mn/p_historical_tidbits_about_transformers_about/"/><updated> 2023-05-28T14:39:25+00:00</updated><published> 2023-05-28T14:39:25+00:00</published><title> [P] 关于 Transformers 的历史花絮：关于原始 Transformer 论文中的 LayerNorm 变体和 Schmidhuber 的 1990 年代的快速权重程序员</title></entry><entry><author><name>/u/crp1994</name><uri> https://www.reddit.com/user/crp1994 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13u49sz/r_umat_uncertaintyaware_single_image_high/&quot;>; &lt;img src=&quot;https://b.thumbs.redditmedia .com/aVU_c5UeVjr0WEbNcThOJybDF2JBq6PMv7gLgCiyvdk.jpg&quot; alt=&quot;[R] UMat：不确定性感知单图像高分辨率材料捕获&quot; title=&quot;[R] UMat：不确定性感知单图像高分辨率材料捕获&quot; />; &lt;/a>; &lt; /td>;&lt;td>; &lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;&lt;a href=&quot;https://i.redd.it /rhzc83xfkl2b1.gif&quot;>;https://i.redd.it/rhzc83xfkl2b1.gif&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/crp1994&quot;>; /u/crp1994 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13u49sz/r_umat_uncertaintyaware_single_image_high/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13u49sz/r_umat_uncertaintyaware_single_image_high/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>;&lt; /表>;</content><id> t3_13u49sz </id><media:thumbnail url="https://b.thumbs.redditmedia.com/aVU_c5UeVjr0WEbNcThOJybDF2JBq6PMv7gLgCiyvdk.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13u49sz/r_umat_uncertaintyaware_single_image_high/"/><updated> 2023-05-28T16:15:23+00:00</updated><published> 2023-05-28T16:15:23+00:00</published><title> [R] UMat：不确定性感知单图像高分辨率材料捕获</title></entry><entry><author><name>/u/__data_cactus__</name><uri> https://www.reddit.com/user/__data_cactus__ </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，&lt;/p>; &lt;p>;我教机器学习已经几年了，我写了一篇关于我使用的过程的文章用于我的 IT 专业人员培训课程。&lt;/p>; &lt;p>;这是关于我在短时间内（不需要 CS 数学课程）在神经网络上建立直觉的策略，同时它&amp;# 39;s 主要面向这个领域的教育工作者，我想你们中的许多人会喜欢阅读。&lt;/p>; &lt;p>;让我知道您的想法！ :D&lt;/p>; &lt;p>;&lt;a href=&quot;https://medium.com/@matei.simtinica/how-i-teach-the-intuition-behind-neural-networks-d7b7ca418873&quot;>;https:// medium.com/@matei.simtinica/how-i-teach-the-intuition-behind-neural-networks-d7b7ca418873&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/__data_cactus__&quot;>; /u/__data_cactus__ &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13ucjp6/d_teaching_the_intuition_behind_nns/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13ucjp6/d_teaching_the_intuition_behind_nns/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13ucjp6 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13ucjp6/d_teaching_the_intuition_behind_nns/"/><updated> 2023-05-28T22:05:11+00:00</updated><published> 2023-05-28T22:05:11+00:00</published><title> [D] 教授神经网络背后的直觉</title></entry><entry><author><name>/你/flerakml</name><uri> https://www.reddit.com/user/flerakml </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我正在尝试解析 Calvin Luo 的非常全面的论文 &lt;a href=&quot;https://arxiv.org/pdf/2208.11970.pdf&quot; >;https://arxiv.org/pdf/2208.11970.pdf.&lt;/a>;&lt;br/>;任何人都可以从数学上展示如何从等式 (43) -&amp;gt; (45) 使用期望方程和 PGM？我需要帮助来理解变量在预期中消失的位置。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/flerakml&quot;>; /u/flerakml &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13ufl4h/d_understanding_understanding_diffusion_models_a/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13ufl4h/d_understanding_understanding_diffusion_models_a/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13ufl4h </id><link href="https://www.reddit.com/r/MachineLearning/comments/13ufl4h/d_understanding_understanding_diffusion_models_a/"/><updated> 2023-05-29T00:16:52+00:00</updated><published> 2023-05-29T00:16:52+00:00</published><title> [D] 理解 - 理解扩散模型：一个统一的视角</title></entry><entry><author><name>/u/yachty66</name><uri> https://www.reddit.com/user/yachty66 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;你好 &lt;a href=&quot;/r/MachineLearning&quot;>;r/MachineLearning&lt;/a>;，我已经为基于 AI 的图像生成器，Midjourney。此 API 允许从 Python 脚本生成图像，提供比传统 Discord 服务器方法更大的灵活性。试试看，让我知道您的反馈：&lt;a href=&quot;https://github.com/yachty66/unofficial%5C_midjourney%5C_python%5C_api&quot;>;https://github.com/yachty66/unofficial\_midjourney\_python \_api&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/yachty66&quot;>; /u/yachty66 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13ufj97/ai_image_generation_with_an_opensource_python_api/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13ufj97/ai_image_generation_with_an_opensource_python_api/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13ufj97 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13ufj97/ai_image_generation_with_an_opensource_python_api/"/><updated> 2023-05-29T00:14:34+00:00</updated><published> 2023-05-29T00:14:34+00:00</published><title>使用开源 Python API 为 Midjourney 生成 AI 图像 [P]</title></entry><entry><author><name> /u/Awkward-Let-4628</name><uri> https://www.reddit.com/user/Awkward-Let-4628 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13tucgj/p_talkcodebase_is_a_powerful_tool_for_chatting/&quot;>; &lt;img src=&quot;https://preview.redd.it /qenc8ydfhk2b1.gif?width=640&amp;amp;crop=smart&amp;amp;s=fe9ee3e9bc818bf99d3bee2608091dad2777a11e&quot; alt=&quot;[P] talk-codebase 是一个与你的代码库聊天的强大工具&quot; title=&quot;[P] talk-codebase 是一个强大的工具与你的代码库聊天&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&lt;a href=&quot;https://github.com/ rsaryev/talk-codebase&quot;>;https://github.com/rsaryev/talk-codebase&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Awkward-Let-4628&quot;>; /u/Awkward-Let-4628 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https: //i.redd.it/qenc8ydfhk2b1.gif&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13tucgj/p_talkcodebase_is_a_powerful_tool_for_chatting/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13tucgj </id><media:thumbnail url="https://preview.redd.it/qenc8ydfhk2b1.gif?width=640&amp;crop=smart&amp;s=fe9ee3e9bc818bf99d3bee2608091dad2777a11e"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13tucgj/p_talkcodebase_is_a_powerful_tool_for_chatting/"/><updated> 2023-05-28T07:36:38+00:00</updated><published> 2023-05-28T07:36:38+00:00</published><title> [P] talk-codebase 是一个与你的代码库聊天的强大工具</title></entry><entry><author><name>/你/林康卡姆</name><uri>https://www.reddit.com/user/rinconcam </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13tzcni/p_gpt4_coding_chats_in_your_terminal/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/GoGPEZBSdLkPG4kx3Osg-I07ukCDiVYPI1mSoh3JMRc.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a03b1e2bffdbb908c09a223b162d8ab205189299&quot; alt=&quot;[P] GPT-4 编码聊天，在你的终端&quot; title=&quot;[P] GPT-4在您的终端中编写聊天代码&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/rinconcam&quot;>; /u/rinconcam &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://github.com/paul- gauthier/aider&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13tzcni/p_gpt4_coding_chats_in_your_terminal/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13tzcni </id><media:thumbnail url="https://external-preview.redd.it/GoGPEZBSdLkPG4kx3Osg-I07ukCDiVYPI1mSoh3JMRc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a03b1e2bffdbb908c09a223b162d8ab205189299"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13tzcni/p_gpt4_coding_chats_in_your_terminal/"/><updated> 2023-05-28T12:32:00+00:00</updated><published> 2023-05-28T12:32:00+00:00</published><title> [P] GPT-4 编码聊天，在你的终端</title></entry><entry><author><name>/u/CS-fan-101</name><uri> https://www.reddit.com/user/CS-fan-101 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13uca9c/p_introducing_model_lab_a_new_tool_to_make_sense/&quot;>; &lt;img src=&quot;https://b.thumbs.redditmedia ... >; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/CS-fan-101&quot;>; /u/CS-fan-101 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;/r /mlscaling/comments/13rvx0i/t_introducing_model_lab_a_new_tool_to_make_sense/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13uca9c/p_introducing_model_lab_a_new_tool_to_make_sense/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13uca9c </id><media:thumbnail url="https://b.thumbs.redditmedia.com/Mbp_hnrdO0qsteXoi5cnum-mSb8oV8S5FSUWahoaMmE.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13uca9c/p_introducing_model_lab_a_new_tool_to_make_sense/"/><updated> 2023-05-28T21:54:33+00:00</updated><published> 2023-05-28T21:54:33+00:00</published><title> [P] 介绍模型实验室 - 一种理解培训 LLM 的新工具</title></entry><entry><author><name>/u/伊梅内查比</name><uri>https://www.reddit.com/user/ImeneCharabi </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;论文中使用的是什么类型的Accuracy&lt;/p>; &lt;p>;所以，为了将你的模型与其他写在journal上的模型和方法进行比较论文，你需要使用相同的指标。他们通常使用准确性。但我不确定什么类型的准确性，是训练或验证还是测试准确性？提前感谢您的回答。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/ImeneCharabi&quot;>; /u/ImeneCharabi &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13ub1xp/what_type_of_accuracy_is_used_in_papers_r/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13ub1xp/what_type_of_accuracy_is_used_in_papers_r/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13ub1xp </id><link href="https://www.reddit.com/r/MachineLearning/comments/13ub1xp/what_type_of_accuracy_is_used_in_papers_r/"/><updated> 2023-05-28T21:01:25+00:00</updated><published> 2023-05-28T21:01:25+00:00</published><title>论文中使用什么类型的准确性 [R]</title></entry><entry><author><name> /u/BlackLands123</name><uri> https://www.reddit.com/user/BlackLands123 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，&lt;/p>; &lt;p>;我写这篇文章是为了寻求你对一个问题的帮助（&lt;a href= &quot;https://en.wikipedia.org/wiki/Nurse_scheduling_problem&quot;>;护士调度问题&lt;/a>;) 我正在尝试使用遗传算法来解决。&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt; p>;我的问题如下：我需要为一个由一定数量的人组成的团队自动生成花名册。每个人都有不同的雇佣合同，包括不同的每周工作时间和不同的休息天数。&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;因为我还处于起步阶段点，我设定了我的初始目标，即分配给每个人的每周工作时间与他或她的合同中的工作时间相等。&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;每个人在population 由长度等于的二进制向量组成：7（一周中的天数）* 8（商店每天营业的小时数）* N（团队中的人数）。该向量将代表每个团队成员的每周工作班次。如果算法对索引1和2的数组位置赋值为11，则表示周一第一个人的工作时间为9点到10点（每一位为一小时的工作），依此类推。&lt;/p>; &lt;p >;&amp;#x200B;&lt;/p>; &lt;p>;算法还传递了一个数组，指示每个人每周必须工作的小时数，例如，[40,40,32,32] 表示第一个人必须工作 40小时，第二个 40，依此类推。&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;我的问题是算法始终固定在一个解决方案上，同时改变变异概率或种群大小。如果一个团队由 4 名成员组成，他们必须分别工作 40、40、32 和 32 小时，则算法为所有成员分配 36 小时的池。&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p >; &lt;p>;下面我展示了适应度函数的部分代码（我使用了 Python 和 DEAP 库），其中我分配了一个惩罚，该惩罚与解决方案与每个员工每周必须工作的正确小时数的距离成正比&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;&lt;code>;def countWeeklyHoursViolations(self, employeeShiftDict):&lt;/code>;&lt;br/>; &lt;code>;“””&lt;/ code>;&lt;br/>; &lt;code>;:param employeeShiftDict: 以员工姓名为键，以周班次为值的员工班次字典&lt;/code>;&lt;br/>; &lt;code>;:return: 周班次数hours violations&lt;/code>;&lt;br/>; &lt;code>;&amp;quot;&amp;quot;&amp;quot;&lt;/code>;&lt;br/>; &lt;code>;#模拟退火会尝试最小化这个函数&lt;/code>; &lt;/p>; &lt;p>; &lt;code>;weeklyHoursViolation = 0&lt;/code>;&lt;br/>; &lt;code>;对于 self.employees 中的员工：&lt;/code>;&lt;br/>; &lt;code>;weekly_hours_calculated = sum(employeeShiftDict[employee])&lt;/code>;&lt;br />; &lt;code>;weekly_hours_expected = self.weeklyHours[self.employees.index(employee)]&lt;/code>;&lt;br/>; &lt;code>;# 对预期和计算的每周小时数的平方差求和 - 差值越大惩罚越大&lt; /code>;&lt;br/>; &lt;code>;weeklyHoursViolation += self.hardConstraintPenalty * abs(weekly_hours_calculated - weekly_hours_expected)**2&lt;/code>;&lt;br/>; &lt;code>;返回 weeklyHoursViolation&lt;/code>;&lt;/p>; &lt;p>; &amp;#x200B;&lt;/p>; &lt;p>;你建议我做什么？你有什么想法？在此先感谢您！&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/BlackLands123&quot;>; /u/BlackLands123 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13u8krw/p_genetic_algorithm_gots_stuck_variation_of/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13u8krw/p_genetic_algorithm_gots_stuck_variation_of/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13u8krw </id><link href="https://www.reddit.com/r/MachineLearning/comments/13u8krw/p_genetic_algorithm_gots_stuck_variation_of/"/><updated> 2023-05-28T19:17:32+00:00</updated><published> 2023-05-28T19:17:32+00:00</published><title> [P] 遗传算法卡住了 - Nurses 问题的变体</title></entry><entry><author><name>/u/BidImpossible555</name><uri> https://www.reddit.com/user/BidImpossible555 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13t83xv/r_improving_factuality_and_reasoning_in_language/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=72b056142e7533b5628a2a34f37f7e5415727075&quot; alt=&quot;[R] 改善事实通过多主体辩论在语言模型中的质量和推理&quot; title=&quot;[R] 改善事实通过多智能体辩论在语言模型中进行和推理&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/BidImpossible555&quot;>; /u/BidImpossible555 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://arxiv.org/abs/ 2305.14325&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13t83xv/r_improving_factuality_and_reasoning_in_language/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>;&lt; /表>;</content><id> t3_13t83xv </id><media:thumbnail url="https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13t83xv/r_improving_factuality_and_reasoning_in_language/"/><updated> 2023-05-27T13:53:41+00:00</updated><published> 2023-05-27T13:53:41+00:00</published><title> [R] 通过多主体辩论改善语言模型中的事实和推理</title></entry><entry><author><name>/你/玛雅桑</name><uri>https://www.reddit.com/user/mayasang </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;你好，我最近在接受一家科技公司的采访时遇到了这个问题。我回答说它会比 L2 项有更显着的效果，使权重系数更小。面试官说还有一个更重要的方面：它现在使问题非凸，因为三阶函数不再是凸函数。谁能进一步详细说明这个解释？添加具有对数似然的 L3 项是否也会使成本函数非凸？我试着问这个 Google 和 ChatGPT，ChatGPT 说逻辑回归模型仍然是凸的：&lt;/p>; &lt;blockquote>; &lt;p>;在逻辑回归中，目标函数通常是最大化的对数似然函数，或者等效地，一个最小化的负对数似然函数。添加正则化时，将正则化项添加到负对数似然以创建正则化目标函数。添加 L3 正则化不会引入非凸性。 &lt;/p>; &lt;p>;通过分析目标函数的Hessian矩阵，可以从数学上证明带L3正则化的逻辑回归模型的凸性。 Hessian矩阵是正半定的，这证实了凸性。 &lt;/p>; &lt;p>;因此，即使包含 L3 正则化项，逻辑回归模型仍然是凸的，可以使用凸优化技术来有效地找到最优解。&lt;/p>; &lt;/blockquote>; &lt;/ div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/mayasang&quot;>; /u/mayasang &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13tq3p8/d_interview_question_what_happens_if_we_add_l3/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13tq3p8/d_interview_question_what_happens_if_we_add_l3/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13tq3p8 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13tq3p8/d_interview_question_what_happens_if_we_add_l3/"/><updated> 2023-05-28T03:21:12+00:00</updated><published> 2023-05-28T03:21:12+00:00</published><title> [D]（面试问题）如果我们将 L3 项添加到逻辑回归模型中会发生什么？</title></entry><entry><author><name> /你/卡尔法斯扬</name><uri>https://www.reddit.com/user/kalfasyan </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13tu09b/p_plakakia_tiles_in_greek_is_an_image_tiling/&quot;>; &lt;img src=&quot;https://b.thumbs.redditmedia ... .这是我制作的第一个开源库，所以希望我能向更有经验的人学习。” title=&quot;[P] Plakakia（希腊语中的 tiles）是我制作的一个图像平铺库，用于从图像快速生成平铺。如果人们尝试它并在 github 上提供一些反馈/提出问题，那就太好了。它是第一个开源我做过的图书馆，所以希望我能向更有经验的人学习。” />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/kalfasyan&quot;>; /u/kalfasyan &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://github.com/kalfasyan/ plakakia&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13tu09b/p_plakakia_tiles_in_greek_is_an_image_tiling/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13tu09b </id><media:thumbnail url="https://b.thumbs.redditmedia.com/jje0KypwRW1CZuUVf5fmUp4TjijHWX006uJQRoOfzHY.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13tu09b/p_plakakia_tiles_in_greek_is_an_image_tiling/"/><updated> 2023-05-28T07:15:17+00:00</updated><published> 2023-05-28T07:15:17+00:00</published><title> [P] Plakakia（希腊语中的 tiles）是我制作的一个图像平铺库，用于从图像快速生成平铺。如果人们尝试它并在 github 上提供一些反馈/提出问题，那就太好了。这是我创建的第一个开源库，所以希望我能向更有经验的人学习。</title></entry><entry><author><name> /你/莫伊尔</name><uri>https://www.reddit.com/user/moyle </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&lt;strong>;简短摘要&lt;/strong>;：使用 LLM 根据给定文档中问题的可能性对给定的一组文档进行排名——显示与全监督检索系统性能相当。&lt;/p>; &lt;p>;&lt;strong>;Arxiv：&lt;/strong>; &lt;a href=&quot;https://arxiv.org/abs/2205.12650&quot;>;https://arxiv.org /abs/2205.12650&lt;/a>;&lt;/p>; &lt;p>;&lt;strong>;Github：&lt;/strong>; &lt;a href=&quot;https://github.com/mukhal/PromptRank&quot;>;https://github.com/ mukhal/PromptRank&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/moyle&quot;>; /u/moyle &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13tpnb5/r_using_llms_for_multihop_document_reranking_with/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13tpnb5/r_using_llms_for_multihop_document_reranking_with/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13tpnb5 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13tpnb5/r_using_llms_for_multihop_document_reranking_with/"/><updated> 2023-05-28T02:57:05+00:00</updated><published> 2023-05-28T02:57:05+00:00</published><title> [R] 使用 LLM 进行多跳文档重新排序，仅使用几个示例。</title></entry><entry><author><name> /u/莱维西</name><uri>https://www.reddit.com/user/Levissie </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好。我遇到了&lt;a href=&quot;https://cardcastle.co/&quot;>;这个&lt;/a>;识别交易卡的应用程序。我很好奇他们用什么方法来实现它。您认为他们使用了什么/什么是实现此类功能的好方法？&lt;/p>; &lt;p>;例如，这里仅对图像进行分类是否可行，或者首先执行文本提取是否是一个好的策略, 然后使用文本进行分类？&lt;/p>; &lt;p>;欢迎任何见解/想法！&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Levissie&quot;>; /u/Levissie &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13tvtxt/d_tcg_card_recognizer_app/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13tvtxt/d_tcg_card_recognizer_app/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13tvtxt </id><link href="https://www.reddit.com/r/MachineLearning/comments/13tvtxt/d_tcg_card_recognizer_app/"/><updated> 2023-05-28T09:13:14+00:00</updated><published> 2023-05-28T09:13:14+00:00</published><title> [D] TCG 卡片识别应用</title></entry><entry><author><name>/u/天创电子</name><uri>https://www.reddit.com/user/AGASTRONICS </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13ua621/anticipating_technological_advancements_the/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/bHNqc2tqMzU5bzJiMZDxwJXaG8VyHFHS4qkIDvRF5odt63WqLGKdEPVVh90f.png?width=140&amp;amp;height=78&amp;amp;crop=140:78,smart&amp;amp;format=jpg&amp;amp;v=enabled&amp;amp;lthumb=true&amp;amp;s=c0c6 c446008ab7ca19de1b4e0ca760c34c0902ce&quot; alt=&quot;预期技术进步​​：不断变化的景观到 2040 年的工作自动化 [R] [D] [N]&quot; title=&quot;预期技术进步​​：到 2040 年工作自动化的变化格局 [R] [D] [N]&quot; />; &lt;/a>; &lt;/td>;&lt; TD>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/AGASTRONICS&quot;>; /u/AGASTRONICS &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://v.redd.it/ nt5sawb59o2b1&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13ua621/anticipating_technological_advancements_the/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13ua621 </id><media:thumbnail url="https://external-preview.redd.it/bHNqc2tqMzU5bzJiMZDxwJXaG8VyHFHS4qkIDvRF5odt63WqLGKdEPVVh90f.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=c0c6c446008ab7ca19de1b4e0ca760c34c0902ce"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13ua621/anticipating_technological_advancements_the/"/><updated> 2023-05-28T20:24:01+00:00</updated><published> 2023-05-28T20:24:01+00:00</published><title>预测技术进步：到 2040 年工作自动化的变化格局 [R] [D] [N]</title></entry><entry><author><name> /u/弥次郎部404</name><uri> https://www.reddit.com/user/Yajirobe404 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Yajirobe404&quot;>; /u/Yajirobe404 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://github.com/EniasCailliau/ GirlfriendGPT&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13tvo7v/p_girlfriendgpt_build_your_own_ai_girlfriend/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13tvo7v </id><link href="https://www.reddit.com/r/MachineLearning/comments/13tvo7v/p_girlfriendgpt_build_your_own_ai_girlfriend/"/><updated> 2023-05-28T09:03:08+00:00</updated><published> 2023-05-28T09:03:08+00:00</published><title> [P] GirlfriendGPT - 打造属于你的AI女友</title></entry><entry><author><name>/你/极客酋长</name><uri>https://www.reddit.com/user/geekinchief </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13td5dn/n_chatgpt_plugins_open_security_holes_from_pdfs/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/Gr_l7Uhimc3HczO9byDTrfXh4AtZ94m2eQCZWEmcrqU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=fd67794f48b02fb7dd23df376ce13a37444034ee&quot; alt=&quot;[N] ChatGPT 插件ins 从 PDF、网站打开安全漏洞&quot; title=&quot;[N] ChatGPT 插件打开安全漏洞来自 PDF、网站&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/geekinchief&quot;>; /u/geekinchief &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.tomshardware.com/新闻/chatgpt-plugins-prompt-injection&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13td5dn/n_chatgpt_plugins_open_security_holes_from_pdfs/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>;&lt; /表>;</content><id> t3_13td5dn </id><media:thumbnail url="https://external-preview.redd.it/Gr_l7Uhimc3HczO9byDTrfXh4AtZ94m2eQCZWEmcrqU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd67794f48b02fb7dd23df376ce13a37444034ee"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13td5dn/n_chatgpt_plugins_open_security_holes_from_pdfs/"/><updated> 2023-05-27T17:25:21+00:00</updated><published> 2023-05-27T17:25:21+00:00</published><title> [N] ChatGPT 插件从 PDF、网站打开安全漏洞</title></entry><entry><author><name>/u/关注mesamurai</name><uri> https://www.reddit.com/user/followmesamurai </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;你好，我不太擅长这个主题，所以有很多东西我不明白。我做了这个小项目，我使用神经网络来识别书面数字。为了创建这个，我在 youtube 上观看了一段视频，我能够理解大部分代码。我的问题是我能否可视化一个神经网络图来显示神经元实际如何工作（在我的项目中）&lt;/p>; &lt;p>;这是代码：&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p >;导入 os&lt;/p>; &lt;p>;导入 cv2&lt;/p>; &lt;p>;导入 numpy 为 np&lt;/p>; &lt;p>;导入 matplotlib.pyplot 为 plt&lt;/p>; &lt;p>;导入 tensorflow 为 tf&lt;/p >; &lt;p>;# mnist = tf.keras.datasets.mnist&lt;/p>; &lt;p>;# (x_train, y_train), (x_test, y_test) = mnist.load_data()&lt;/p>; &lt;p>;# x_train = tf .keras.utils.normalize(x_train, axis=1)&lt;/p>; &lt;p>;# x_test = tf.keras.utils.normalize(x_test, axis=1)&lt;/p>; &lt;p>;# model = tf.keras .models.Sequential()&lt;/p>; &lt;p>;#model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))&lt;/p>; &lt;p>;#model.add(tf.keras .layers.Dense(128, activation=&quot;relu&quot;))&lt;/p>; &lt;p>;#model.add(tf.keras.layers.Dense(128, activation=&quot;relu&quot;))&lt;/p>; &lt; p>;#model.add(tf.keras.layers.Dense(10, activation=“softmax”))&lt;/p>; &lt;p>;#model.compile(optimizer=“adam”,&lt;/p>; &lt;p >;# loss=&amp;quot;sparse_categorical_crossentropy&amp;quot;, metrics=[&amp;quot;accuracy&amp;quot;])&lt;/p>; &lt;p>;# &lt;a href=&quot;https://model.fit/&quot;>;model.fit&lt;/a>;(x_train , y_train, epochs=3)&lt;/p>; &lt;p>;# &lt;a href=&quot;https://model.save/&quot;>;model.save&lt;/a>;(&quot;handwrtitten.model&quot;)&lt;/p>; &lt; p>;model = tf.keras.models.load_model(&amp;#39;handwrtitten.model&amp;#39;)&lt;/p>; &lt;p>;# loss, accuracy = model.evaluate(x_test, y_test)&lt;/p>; &lt;p>; # print(loss)&lt;/p>; &lt;p>;# print(accuracy)&lt;/p>; &lt;p>;image_number = 1&lt;/p>; &lt;p>;while os.path.isfile(f&quot;digits/digit{image_number}. png&quot;):&lt;/p>; &lt;p>;尝试：&lt;/p>; &lt;p>;img = cv2.imread(f&quot;digits/digit{image_number}.png&quot;)[:, :, 0]&lt;/p>; &lt; p>;img = np.invert(np.array([img]))&lt;/p>; &lt;p>;prediction = model.predict(img)&lt;/p>; &lt;p>;print(&quot;数字是：&quot;, np.argmax(预测))&lt;/p>; &lt;p>;plt.imshow(img[0], cmap=plt.cm.binary)&lt;/p>; &lt;p>;&lt;a href=&quot;https://plt.show /&quot;>;plt.show&lt;/a>;()&lt;/p>; &lt;p>;除了：&lt;/p>; &lt;p>;print(&quot;Error&quot;)&lt;/p>; &lt;p>;最后：&lt;/p>; &lt;p >;image_number += 1&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/followmesamurai&quot;>; /u/followmesamurai &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13u1je2/pvisualizing_a_neural_network/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13u1je2/pvisualizing_a_neural_network/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13u1je2 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13u1je2/pvisualizing_a_neural_network/"/><updated> 2023-05-28T14:17:27+00:00</updated><published> 2023-05-28T14:17:27+00:00</published><title> [P]可视化神经网络。</title></entry><entry><author><name> /u/ThePanArchitect</name><uri> https://www.reddit.com/user/ThePanArchitect </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;首先，请原谅我对此事缺乏适当的术语和技术知识，AI 和 IT 不是我的专业领域，但我&amp;#39;我是一名对 AI 充满热情的建筑师，喜欢与该领域的人讨论。&lt;/p>; &lt;p>;所以我的问题是，为什么我们没有看到更多的 AI 开发来生成建筑，包括墙壁、门、窗户和构成建筑物的所有其他元素……听我说完。&lt;/p>; &lt;p>;AI 在建筑中的集成即使尚未发生，也已得到深入讨论。然而，从我的角度来看，它似乎是在一个相对表面的层面上实现的。即通过使用 Midjourney 或 ControlNET 等文本提示生成图像。但是，我还没有看到真正可以理解几何或 3D 形状的工具或模型。尽管从技术上讲，几何可以通过文本或数学公式来表示更复杂的表面和形状。如果几何可以转换成文本，它就可以被理解和预训练，&lt;em>;对吗？&lt;/em>;&lt;/p>; &lt;p>;已经有一篇优秀的研究论文对这种想法进行了概念验证，论文被称为“Architext”而且我认为，深入研究将几何图形表示为文本，将墙壁、窗户、门等表示为文本或任何其他可以预训练的格式的想法肯定会有所收获。&lt;/p>; &lt;p>;也许墙可以用元组表示，例如：&lt;br/>; (&lt;em>;baselineL1[Startpoint(x1,y1),Endpoint(x2,y2)], thickness=250 mm, height=2800)&lt;/em>;&lt;/ p>; &lt;p>;事实上，实际上有一种名为 IFC 的文件格式，它基本上是将整个 BIM 转换为文本。也许 IFC 可以用作“训练集”？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/ThePanArchitect&quot;>; /u/ThePanArchitect &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13u3qdy/are_ai_developers_not_paying_enough_attention_to/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13u3qdy/are_ai_developers_not_paying_enough_attention_to/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13u3qdy </id><link href="https://www.reddit.com/r/MachineLearning/comments/13u3qdy/are_ai_developers_not_paying_enough_attention_to/"/><updated> 2023-05-28T15:53:42+00:00</updated><published> 2023-05-28T15:53:42+00:00</published><title> AI开发者是否对此不够重视？ [D]</title></entry><entry><author><name> /u/穆罕默德·拉沙德</name><uri>https://www.reddit.com/user/MohamedRashad </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我一直在阅读与 ChatGPT 和 GPT-4 相当的开源 LLM，但当我尝试它们时，我发现它们与 OpenAI 相去甚远&amp;#39 ;s 模型。&lt;/p>; &lt;p>;我发现与我的发现一致的最佳指标是 lmsys（Vicuna 的作者）的 ELO 评级。&lt;/p>; &lt;p>;还有哪些其他指标用于真正评估 LLM 和给我们关于他们能力的真实数字？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/MohamedRashad&quot;>; /u/MohamedRashad &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13t4kul/d_what_evaluation_metrics_that_actually_matters/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13t4kul/d_what_evaluation_metrics_that_actually_matters/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13t4kul </id><link href="https://www.reddit.com/r/MachineLearning/comments/13t4kul/d_what_evaluation_metrics_that_actually_matters/"/><updated> 2023-05-27T11:09:14+00:00</updated><published> 2023-05-27T11:09:14+00:00</published><title> [D] 哪些评估指标真正重要？</title></entry><entry><author><name> /你/陈兹</name><uri>https://www.reddit.com/user/chenzzzy </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我一直想知道如何通过一些深度模型重用学到的知识。像 LLM 这样的 Seq-In-Seq-Out 范式对 LLM 应用程序提出了严格的限制，例如自动定理证明（现在主要通过符号回归实现）、空间关系理解（部分由 LLM 捕获但以序列模式方式）、算术计算（以满足简单的场景，以类似的空间关系方式）等。&lt;/p>; &lt;p>;最近 Nature MI 发表了一项关于使用图模型进行多模态学习的有前途的工作，其中异构数据被集成到一个统一的神经网络模型中。在我看来，这说明了通过图范式学习建立可解释知识系统的一些可能性。&lt;/p>; &lt;p>;&lt;a href=&quot;https://www.nature.com/articles/s42256-023-00624-6 &quot;>;https://www.nature.com/articles/s42256-023-00624-6&lt;/a>;&lt;/p>; &lt;p>;我最近关于通用知识表示的思考的类似想法也朝着同一个方向前进。总结在帖子 &lt;a href=&quot;http://xiaming.site/2023/05/27/kr-and-lgm-part1/&quot;>;http://xiaming.site/2023/05/27/kr-and- lgm-part1/&lt;/a>;&lt;/p>; &lt;p>;你们有什么想法吗？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/chenzzzy&quot;>; /u/chenzzzy &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13t291u/d_is_gnn_or_large_graph_model_promising_for_an/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13t291u/d_is_gnn_or_large_graph_model_promising_for_an/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13t291u </id><link href="https://www.reddit.com/r/MachineLearning/comments/13t291u/d_is_gnn_or_large_graph_model_promising_for_an/"/><updated> 2023-05-27T08:49:10+00:00</updated><published> 2023-05-27T08:49:10+00:00</published><title> [D] GNN 或大型图模型是否有望用于可解释的知识密集型系统？</title></entry></feed>