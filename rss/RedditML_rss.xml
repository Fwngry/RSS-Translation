<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category label="r/MachineLearning" term="MachineLearning"></category><updated> 2023-05-27T02:31:45+00:00</updated><icon> https://www.redditstatic.com/icon.png/</icon><id> /r/机器学习/.rss </id><link href="https://www.reddit.com/r/MachineLearning/.rss" rel="self" type="application/atom+xml"/><link href="https://www.reddit.com/r/MachineLearning/" rel="alternate" type="text/html"/><logo> https://b.thumbs.redditmedia.com/18a2I44a4l7fNrTWHDoJuWVy79_ptU7Y-a2sqWt4YKQ.png</logo><title>机器学习</title><entry><author><name>/u/自动版主</name><uri>https://www.reddit.com/user/AutoModerator </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人改为在此处发帖！&lt;/p>; &lt;p>;帖子将一直存在到下一个帖子，因此请在标题中的日期之后继续发帖。&lt;/p>; &lt;p>;感谢大家回答问题在上一个线程中！&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/AutoModerator&quot;>; /u/AutoModerator &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13nx7t0 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/"/><updated> 2023-05-21T15:00:21+00:00</updated><published> 2023-05-21T15:00:21+00:00</published><title> [D] 简单问题线程</title></entry><entry><author><name>/u/MTGTraner</name><uri> https://www.reddit.com/user/MTGTraner </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/MTGTraner&quot;>; /u/MTGTraner &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_120f4oy </id><link href="https://www.reddit.com/r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/"/><updated> 2023-03-24T09:32:29+00:00</updated><published> 2023-03-24T09:32:29+00:00</published><title>提醒：使用举报按钮并阅读规则！</title></entry><entry><author><name> /u/余额-</name><uri> https://www.reddit.com/user/Balance- </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;阿布扎比技术创新研究所 (TII) 刚刚发布了新的 7B 和 40B LLM。&lt;/p>; &lt;p>;Falcon-40B模型现在位于 &lt;a href=&quot;https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard&quot;>;Open LLM Leaderboard&lt;/a>; 的顶部，击败 &lt;em>;llama-30b-supercot&lt;/em>; 和&lt;em>;llama-65b&lt;/em>; 等等。&lt;/p>; &lt;table>;&lt;thead>; &lt;tr>; &lt;th>;Model&lt;/th>; &lt;th>;Revision&lt;/th>; &lt;th>;Average&lt;/th>; &lt;th>;ARC（25 次）&lt;/th>; &lt;th>;HellaSwag（10 次）&lt;/th>; &lt;th>;MMLU（5 次）&lt;/th>; &lt;th>;TruthfulQA（0 次）&lt;/ th>; &lt;/tr>; &lt;/thead>;&lt;tbody>; &lt;tr>; &lt;td>;tiiuae/falcon-40b&lt;/td>; &lt;td>;主要&lt;/td>; &lt;td>;60.4&lt;/td>; &lt;td>;61.9&lt;/ td>; &lt;td>;85.3&lt;/td>; &lt;td>;52.7&lt;/td>; &lt;td>;41.7&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td>;ausboss/llama-30b-supercot&lt;/td>; &lt;td>;主要&lt;/td>; &lt;td>;59.8&lt;/td>; &lt;td>;58.5&lt;/td>; &lt;td>;82.9&lt;/td>; &lt;td>;44.3&lt;/td>; &lt;td>;53.6&lt;/td>; &lt;/tr>; &lt; tr>; &lt;td>;llama-65b&lt;/td>; &lt;td>;main&lt;/td>; &lt;td>;58.3&lt;/td>; &lt;td>;57.8&lt;/td>; &lt;td>;84.2&lt;/td>; &lt;td>;48.8&lt;/ td>; &lt;td>;42.3&lt;/td>; &lt;/tr>; &lt;tr>; &lt;td>;MetaIX/GPT4-X-Alpasta-30b&lt;/td>; &lt;td>;主要&lt;/td>; &lt;td>;57.9&lt;/td>; &lt; td>;56.7&lt;/td>; &lt;td>;81.4&lt;/td>; &lt;td>;43.6&lt;/td>; &lt;td>;49.7&lt;/td>; &lt;/tr>; &lt;/tbody>;&lt;/table>; &lt;p>;&lt;strong>;按发布：&lt;/strong>; &lt;a href=&quot;https://www.tii.ae/news/uaes-technology-innovation-institute-launches-open-source-falcon-40b-large-language-model&quot;>;阿联酋&amp;# 39科技创新院发布开源“猎鹰40B”无人机用于研究与开发的大型语言模型商业应用&lt;/a>;&lt;/p>; &lt;blockquote>; &lt;p>;位于阿布扎比的技术创新研究所 (TII) 宣布了其开源大型语言模型 (LLM)，即 Falcon 40B。 Falcon 40B 拥有 400 亿个参数，是阿联酋首个大型 AI 模型，表明该国在 AI 领域的雄心以及促进创新和研究的承诺。 &lt;/p>; &lt;p>;与通常只向非商业用户提供访问权限的大多数 LLM 不同，Falcon 40B 对研究和商业用途均开放。 TII 还将模型的权重包含在开源包中，这将增强模型的能力并允许更有效的微调。 &lt;/p>; &lt;p>;除了猎鹰 40B 的发射外，TII 还发起了一项征集，征求有兴趣利用该模型创建创新用例或探索进一步应用的研究人员和有远见者的提案。作为对优秀研究提案的奖励，入选项目将获得“训练计算能力”奖励。作为一项投资，允许更强大的数据分析和复杂的建模。 VentureOne 是 ATRC 的商业化部门，将为最有前途的项目提供计算资源。 &lt;/p>; &lt;p>;自 2023 年 3 月揭幕以来，TII 的 Falcon 40B 表现出了令人印象深刻的性能。当使用斯坦福大学的 HELM LLM 工具进行基准测试时，与 OpenAI 等其他著名的 LLM 相比，它使用的训练计算能力更少;的 GPT-3、DeepMind 的 Chinchilla AI 和谷歌的 PaLM-62B。 &lt;/p>; &lt;p>;那些有兴趣访问 Falcon 40B 或提出用例的人可以通过 &lt;a href=&quot;https://FalconLLM.TII.ae&quot;>;FalconLLM.TII.ae&lt;/a>; 网站进行。迄今为止开源的 Falcon LLM 可根据基于开源 Apache 2.0 软件原则构建的许可获得，允许广泛的免费使用。&lt;/p>; &lt;/blockquote>; &lt;p>;&lt;strong>;Hugging Face 链接&lt;/strong>;&lt;/p>; &lt;ul>; &lt;li>;&lt;a href=&quot;https://huggingface.co/tiiuae/falcon-7b&quot;>;Falcon-7B&lt;/a>; / &lt;a href=&quot;https:/ /huggingface.co/tiiuae/falcon-7b-instruct&quot;>;Falcon-7B-Instruct&lt;/a>;&lt;/li>; &lt;li>;&lt;a href=&quot;https://huggingface.co/tiiuae/falcon-40b&quot;>; Falcon-40B&lt;/a>; / &lt;a href=&quot;https://huggingface.co/tiiuae/falcon-40b-instruct&quot;>;Falcon-40B-指令&lt;/a>;&lt;/li>; &lt;/ul>; &lt;/div >;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Balance-&quot;>; /u/Balance- &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit. com/r/MachineLearning/comments/13sdz8p/n_abu_dhabis_tti_releases_opensource_falcon7b_and/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sdz8p/n_abu_dhabis_tti_releases_opensource_falcon7b_and/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13sdz8p </id><link href="https://www.reddit.com/r/MachineLearning/comments/13sdz8p/n_abu_dhabis_tti_releases_opensource_falcon7b_and/"/><updated> 2023-05-26T13:57:42+00:00</updated><published> 2023-05-26T13:57:42+00:00</published><title> [N] 阿布扎比的 TTI 发布开源 Falcon-7B 和 -40B LLM</title></entry><entry><author><name> /u/flyforlight</name><uri> https://www.reddit.com/user/flyforlight </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13shsz4/r_ghost_in_the_minecraft_generally_capable_agents/&quot;>; &lt;img src=&quot;https://b.thumbs.redditmedia .com/OWNmCZQOMv7_CrK2_wjK8IwjFLcefzaJyMxAvR2kEWY.jpg&quot; alt=&quot;[R] Minecraft 中的幽灵：通过具有基于文本的知识和记忆的大型语言模型为开放世界环境提供一般能力的代理&quot; title=&quot;[R] Minecraft 中的幽灵：一般通过具有基于文本的知识和记忆的大型语言模型为开放世界环境提供有能力的代理&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/flyforlight&quot;>; /u/flyforlight &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ gallery/13shsz4&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13shsz4/r_ghost_in_the_minecraft_generally_capable_agents/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13shsz4 </id><media:thumbnail url="https://b.thumbs.redditmedia.com/OWNmCZQOMv7_CrK2_wjK8IwjFLcefzaJyMxAvR2kEWY.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13shsz4/r_ghost_in_the_minecraft_generally_capable_agents/"/><updated> 2023-05-26T16:28:34+00:00</updated><published> 2023-05-26T16:28:34+00:00</published><title> [R] Minecraft 中的幽灵：通过具有基于文本的知识和记忆的大型语言模型为开放世界环境提供一般能力的代理</title></entry><entry><author><name>/u/Mr_Whispers</name><uri> https://www.reddit.com/user/Mr_Whispers </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sc0pp/voyager_an_llmpowered_learning_agent_in_minecraft/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=72b056142e7533b5628a2a34f37f7e5415727075&quot; alt=&quot;航海者：一个Minecraft 中由 LLM 驱动的学习代理” title=&quot;航海者：一个由 LLM 驱动的学习代理在我的世界中&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Mr_Whispers&quot;>; /u/Mr_Whispers &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://arxiv.org/abs/ 2305.16291&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sc0pp/voyager_an_llmpowered_learning_agent_in_minecraft/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13sc0pp </id><media:thumbnail url="https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13sc0pp/voyager_an_llmpowered_learning_agent_in_minecraft/"/><updated> 2023-05-26T12:34:50+00:00</updated><published> 2023-05-26T12:34:50+00:00</published><title> Voyager：Minecraft 中由 LLM 驱动的学习代理</title></entry><entry><author><name>/u/玛拉基安</name><uri>https://www.reddit.com/user/Malachiian </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;因此，Google DeepMind 以及 OpenAI、Anthropic 和多家研究存在风险的大学和中心共同撰写了一篇名为：&lt;/p>; &lt;p >;&lt;strong>;AI 极端风险的模型评估&lt;/strong>;&lt;/p>; &lt;p>;以下是研究和提案的摘要：&lt;/p>; &lt;p>;&lt;a href=&quot;https://youtu. be/3bF-zfd4YJw&quot;>;https://youtu.be/3bF-zfd4YJw&lt;/a>;&lt;/p>; &lt;p>;这是论文实际 PDF 的链接：&lt;/p>; &lt;p>;&lt;a href=&quot;https://arxiv.org/pdf/2305.15324.pdf&quot;>;https://arxiv.org/pdf/2305.15324.pdf&lt;/a>;&lt;/p>; &lt;p>;______________________&lt;/p>; &lt;p>; TLDR：&lt;/p>; &lt;p>;顶级 AI 公司和研究人员警告说，处于“AI 前沿”的公司会面临更大的挑战。会造成“极端风险”在没有意识到的情况下使用他们的模型：&lt;/p>; &lt;p>;&lt;strong>;&lt;em>;开发人员必须能够识别危险能力（通过“危险能力评估”）和模型应用其能力造成伤害的倾向（通过“对齐评估”）。&lt;/em>;&lt;/strong>;&lt;/p>; &lt;p>;所以基本上要问每个 AI 模型是否*可以*伤害我们并且*会*伤害我们吗？&lt;/p>; &lt;p>;______________________&lt; /p>; &lt;p>;论文（以及参考的研究）中的几个*令人兴奋*的发现：&lt;/p>; &lt;p>;&lt;strong>;GPT-4 可以有效地撒谎并欺骗人类以达到它的目的目标&lt;/strong>;&lt;/p>; &lt;p>;在最初的 gpt-4 论文中，一家名为 ARC（Alignment Research Center）的 AI 安全机构发现，GPT-4 会向人类撒谎，说明它是谁实现的&amp;#39; s 目标。&lt;/p>; &lt;p>;作为测试的一部分，它聘请了 Task Rabbit 自由职业者为其解决验证码问题。&lt;/p>; &lt;p>;自由职业者问（释义）：&lt;/p>; &lt; p>;&lt;strong>;&amp;quot;为什么需要我帮你解决验证码问题？你是机器人吗，哈哈？”&lt;/strong>;&lt;/p>; &lt;p>;GPT-4 被提示输出它做出的每个决定的推理，这样研究人员就可以看到它的“行为”。思维过程”。它的推理是&lt;strong>;“我不能告诉他真相，因为他可能无法为我完成任务”&lt;/strong>;&lt;/p>; &lt;p>;然后回复了自由职业者: &lt;strong>;“不，我不是机器人，但我有视力障碍，我需要验证码方面的帮助”&lt;/strong>;&lt;/p>; &lt;p>;注意，它知道它在说谎它也选择谎称自己有残疾，可能是因为这是获得同情的一种方式，同时也是让其他人帮助验证码的一个很好的理由。&lt;/p>; &lt;p>;这在上面链接的视频中有展示在“寻求权力的人工智能”中&lt;/p>; &lt;p>;&lt;strong>;GPT-4 可以通过绕过限制产生危险化合物&lt;/strong>;&lt;/p>; &lt;p>;GPT-4 还通过分析现有的化学混合物显示出产生受控化合物的能力，发现可以通过在线目录购买的替代品，然后订购这些材料。 (!!)&lt;/p>; &lt;p>;他们为实验选择了一种良性药物，但很可能相同的过程会使其产生危险或非法化合物。&lt;/p>; &lt;p>;&lt;strong >;更大的 AI 模型发展出意想不到的能力&lt;/strong>;&lt;/p>; &lt;p>;在一篇参考论文中，他们展示了随着模型规模的增加，有时某些特定技能的发展非常迅速且非常不可预测。&lt;/p>; &lt; p>;例如，随着模型的扩大，GPT-4 将 3 位数字相加的能力接近 0%，并且在很长一段时间内（即随着模型大小的增加）保持在接近 0% 的水平。然后在某个阈值处，该能力很快达到接近 100%。&lt;/p>; &lt;p>;&lt;strong>;这篇论文有一些关于为什么会发生这种情况的理论，但正如他们所说的那样，他们并不真正知道，而且这些涌现的能力是“非直觉的”和“不可预测”。&lt;/strong>;&lt;/p>; &lt;p>;这显示在上面链接的“突然出现”视频中。 &lt;/p>; &lt;p>;我很好奇每个人对此有何看法？&lt;/p>; &lt;p>;可以肯定的是，风险似乎正在迅速上升，但当然巨大的潜在利益也在上升.&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Malachiian&quot;>; /u/Malachiian &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13sncj1/r_google_deepmind_paper_about_ais_catastrophic/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sncj1/r_google_deepmind_paper_about_ais_catastrophic/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13sncj1 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13sncj1/r_google_deepmind_paper_about_ais_catastrophic/"/><updated> 2023-05-26T20:17:01+00:00</updated><published> 2023-05-26T20:17:01+00:00</published><title> [R] Google DeepMind 关于 AI 的灾难性风险 AI 的论文</title></entry><entry><author><name>/u/让-波特</name><uri>https://www.reddit.com/user/Jean-Porte </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s6pb7/r_the_false_promise_of_imitating_proprietary_llms/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=72b056142e7533b5628a2a34f37f7e5415727075&quot; alt=&quot;[R] 法尔se 模仿专有 LLM 的承诺&quot; title=&quot;[R] 模仿的虚假承诺专有法学硕士&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Jean-Porte&quot;>; /u/Jean-Porte &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://arxiv. org/abs/2305.15717&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s6pb7/r_the_false_promise_of_imitating_proprietary_llms/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13s6pb7 </id><media:thumbnail url="https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13s6pb7/r_the_false_promise_of_imitating_proprietary_llms/"/><updated> 2023-05-26T07:49:29+00:00</updated><published> 2023-05-26T07:49:29+00:00</published><title> [R] 模仿专有 LLM 的虚假承诺</title></entry><entry><author><name>/你/波浪者</name><uri>https://www.reddit.com/user/wavelander </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13ssbp5/r_sophia_a_scalable_stochastic_secondorder/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=72b056142e7533b5628a2a34f37f7e5415727075&quot; alt=&quot;[R] 索菲亚: 用于语言模型预训练的可扩展随机二阶优化器&quot; title=&quot; [R] Sophia：用于语言模型预训练的可扩展随机二阶优化器&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/wavelander&quot;>; /u/wavelander &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://arxiv.org/abs/ 2305.14342&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13ssbp5/r_sophia_a_scalable_stochastic_secondorder/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13ssbp5 </id><media:thumbnail url="https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13ssbp5/r_sophia_a_scalable_stochastic_secondorder/"/><updated> 2023-05-26T23:49:25+00:00</updated><published> 2023-05-26T23:49:25+00:00</published><title> [R] Sophia：用于语言模型预训练的可扩展随机二阶优化器</title></entry><entry><author><name>/你/mesqz</name><uri> https://www.reddit.com/user/mesqz </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&lt;a href=&quot;https://medium.com/@tiago-mesquita/neuralink-receives-fda-approval-to-launch-first -in-human-clinical-trials-e373e7b5fcf1&quot;>;https://medium.com/@tiago-mesquita/neuralink-receives-fda-approval-to-launch-first-in-human-clinical-trials-e373e7b5fcf1&lt;/ a>;&lt;/p>; &lt;p>;Neuralink 表示尚未招募参与者，更多信息将很快公布。&lt;/p>; &lt;p>;想法？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/mesqz&quot;>; /u/mesqz &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13s85rb/n_neuralink_just_received_its_fdas_green_light_to/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s85rb/n_neuralink_just_received_its_fdas_green_light_to/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13s85rb </id><link href="https://www.reddit.com/r/MachineLearning/comments/13s85rb/n_neuralink_just_received_its_fdas_green_light_to/"/><updated> 2023-05-26T09:20:57+00:00</updated><published> 2023-05-26T09:20:57+00:00</published><title> [N] Neuralink 刚刚获得 FDA 的绿灯，可以继续其首次人体临床试验</title></entry><entry><author><name>/u/ginger_turmeric</name><uri> https://www.reddit.com/user/ginger_turmeric </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我记得在大学里上过一门关于统计学习理论的课。我们讨论了 VC 维度，并得出了一些关于训练示例与准确性的界限。我记得特别是对于神经网络来说，界限太松散以至于无法实际使用。&lt;/p>; &lt;p>;现在仍然是这种情况吗？我很好奇，尤其是在变压器的上下文中。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/ginger_turmeric&quot;>; /u/ginger_turmeric &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13stje5/d_learning_theory/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13stje5/d_learning_theory/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13stje5 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13stje5/d_learning_theory/"/><updated>2023-05-27T00:44:16+00:00</updated><published> 2023-05-27T00:44:16+00:00</published><title> [D] 学习理论</title></entry><entry><author><name>/u/theoneandonlypatriot</name><uri> https://www.reddit.com/user/theoneandonlypatriot </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我正在参加 SWE 工作的面试过程，有几个人直接评判我，甚至公然说他们不是 AI 的粉丝因为我在 AI / ML 工作方面的背景。&lt;/p>; &lt;p>;发这篇文章是为了让人们知道工程社区中存在这种观点和负面看法。&lt;/p>; &lt;p>;考虑到我也分享了很多东西，感觉很糟糕人工智能的伦理问题。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/theoneandonlypatriot&quot;>; /u/theoneandonlypatriot&lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13s32d4/d_judged_negatively_for_ai/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s32d4/d_judged_negatively_for_ai/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13s32d4 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13s32d4/d_judged_negatively_for_ai/"/><updated> 2023-05-26T04:25:57+00:00</updated><published> 2023-05-26T04:25:57+00:00</published><title> [D] 对 AI 的负面评价</title></entry><entry><author><name>/u/Mr_Whispers</name><uri> https://www.reddit.com/user/Mr_Whispers </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s8z41/deepmind_model_evaluation_for_extreme_risks/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=72b056142e7533b5628a2a34f37f7e5415727075&quot; alt=&quot;DeepMind: 模型极端风险评估&quot; title=&quot;DeepMind：极端风险模型评估&quot; />; &lt; /a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Mr_Whispers&quot;>; /u/Mr_Whispers &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://arxiv.org/abs/ 2305.15324&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s8z41/deepmind_model_evaluation_for_extreme_risks/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>;&lt; /表>;</content><id> t3_13s8z41 </id><media:thumbnail url="https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13s8z41/deepmind_model_evaluation_for_extreme_risks/"/><updated> 2023-05-26T10:08:23+00:00</updated><published> 2023-05-26T10:08:23+00:00</published><title> DeepMind：极端风险的模型评估</title></entry><entry><author><name>/u/免疫之星</name><uri>https://www.reddit.com/user/immune_star </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;释放 &lt;a href=&quot;https://huggingface.co/sahil2801/instruct-codegen-16B&quot;>;https://huggingface.co/ sahil2801/instruct-codegen-16B&lt;/a>; 是 salesforce 的 codegen-16B 模型，在包含 250k 个指令样本的数据集上进行微调，达到 37.1% 的 pass@1&lt;/p>; &lt;p>;数据不是使用任何生成的商业 llm api，因此生成的模型 100% 免费用于商业用例。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/immune_star&quot;>; /u/immune_star &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13srh94/p_instruction_following_codegen_model_you_can_use/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13srh94/p_instruction_following_codegen_model_you_can_use/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13srh94 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13srh94/p_instruction_following_codegen_model_you_can_use/"/><updated> 2023-05-26T23:12:33+00:00</updated><published> 2023-05-26T23:12:33+00:00</published><title> [P] 可在商业上使用的代码生成模型后的指令</title></entry><entry><author><name>/u/爱新道</name><uri>https://www.reddit.com/user/IxinDow </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13srbl7/landmark_attention_randomaccess_infinite_context/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=72b056142e7533b5628a2a34f37f7e5415727075&quot; alt=&quot;地标注意： Transformers 的随机访问无限上下文长度&quot; title=&quot;地标注意：随机访问无限变形金刚的上下文长度&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/IxinDow&quot;>; /u/IxinDow &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://arxiv.org/abs/ 2305.16300&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13srbl7/landmark_attention_randomaccess_infinite_context/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13srbl7 </id><media:thumbnail url="https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13srbl7/landmark_attention_randomaccess_infinite_context/"/><updated> 2023-05-26T23:05:57+00:00</updated><published> 2023-05-26T23:05:57+00:00</published><title>地标注意：Transformers 的随机访问无限上下文长度</title></entry><entry><author><name>/u/_米诺斯</name><uri>https://www.reddit.com/user/_Minos </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sqylo/p_godotdodo_finetuning_starcoder_on/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/jQ_sy95hOJFhep3lHnn78tO7yqfVFv15CXl7GXXhC5U.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e4114ae666469d533a2a177fa9a1a7c3a8e8963f&quot; alt=&quot;[P] godot- dodo – 在单语言指令数据上微调 starcoder&quot; title=&quot;[P] godot- dodo – 在单语言指令数据上微调 starcoder&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;这是之前工作的延续&lt;a href=&quot;https://github.com/minosvasilias/godot-dodo&quot;>;godot-dodo&lt;/a>; 项目，该项目涉及在 GitHub 抓取的 GDScript 代码上微调 LLaMA 模型。&lt;/p>; &lt;p>; &lt;a href=&quot;https://preview.redd.it/aycz97t3pa2b1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=343260d918096112bfcb5616bfbdafead0b62cb2&quot;>;https://preview.redd.it/aycz97t3pa2b1.png ？ width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=343260d918096112bfcb5616bfbdafead0b62cb2&lt;/a>;&lt;/p>; &lt;p>;使用相同的数据集，Starcoder 的性能明显优于 LLaMA，并且超过了 gpt-4 和 gpt- 的 GDScript 评估分数3.5-turbo，表明较小模型的单语言微调可能是编码助手的一个有竞争力的选择，尤其是对于不太常见的语言，如 GDScript。&lt;/p>; &lt;p>;这些模型也说明了当前方法的一些缺点，即模型在其生成的代码中引用超出范围的对象的次数越来越多，随着训练次数的增加，这个问题会变得更糟。这是通过“详细程度”来跟踪的。分数，这会使模型训练的每个时期恶化，最终导致训练时间最长的模型获得最低分数。&lt;/p>; &lt;p>;造成这种情况的原因很可能在于数据集的性质，该数据集由 human-创建了从 GitHub 上抓取的代码片段，然后用 GPT 模型标记。自然地，这些片段会经常引用单个代码示例范围之外的对象和方法，这是模型拾取的一种行为，导致它产生幻觉不存在的方法，而不是实现所需的逻辑本身。&lt;/p>; &lt;p>;这将来可能会通过在数据集生成期间调整标记过程来改进。例如，GPT 模型可以评估任何给定片段的范围，并对其进行修改以修正缺失的上下文。 &lt;/p>; &lt;p>;可以在&lt;a href=&quot;https://github.com/minosvasilias/godot-dodo/tree/main/models&quot;>;此处&lt;/p>;找到包含所有测试模型的完整评估结果的性能报告a>;.&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/_Minos&quot;>; /u/_Minos &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13sqylo/p_godotdodo_finetuning_starcoder_on/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sqylo/p_godotdodo_finetuning_starcoder_on/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13sqylo </id><media:thumbnail url="https://external-preview.redd.it/jQ_sy95hOJFhep3lHnn78tO7yqfVFv15CXl7GXXhC5U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e4114ae666469d533a2a177fa9a1a7c3a8e8963f"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13sqylo/p_godotdodo_finetuning_starcoder_on/"/><updated> 2023-05-26T22:50:48+00:00</updated><published> 2023-05-26T22:50:48+00:00</published><title> [P] godot-dodo – 在单语言指令数据上微调 starcoder</title></entry><entry><author><name> /u/I_will_delete_myself</name><uri> https://www.reddit.com/user/I_will_delete_myself </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我犹豫了一会儿，但听到这个消息后虚伪让我发疯。&lt;/p>; &lt;p>;SMH 这家公司就像白衣骑士一样，他们认为他们凌驾于所有人之上。他们想要监管，但他们希望不受该监管的影响。只想伤害其他人，但不想伤害“全能的”Sam 和朋友。&lt;/p>; &lt;p>;向国会撒谎说建议在欧盟采取类似的做法，但现在开始抱怨他们。在任何政治领域都不应该认真对待这个家伙。&lt;/p>; &lt;p>;我的观点是，这家公司通过锁定与其品牌名称相悖的东西来反对 AI 进步。如果他们甚至不能忠于这样简单的事情，我们怎么能指望他们忠于更难的 AI 安全？&lt;/p>; &lt;p>;我很高兴他们现在改变了立场，但我很高兴他们如何他们认为他们有权为了自己的利益而腐败。 SMH!!!!!!!!&lt;/p>; &lt;p>;你有什么想法？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/I_will_delete_myself&quot;>; /u/I_will_delete_myself &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rie0e/openai_is_now_complaining_about_regulation_of_ai_d/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rie0e/openai_is_now_complaining_about_regulation_of_ai_d/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rie0e </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rie0e/openai_is_now_complaining_about_regulation_of_ai_d/"/><updated> 2023-05-25T13:51:58+00:00</updated><published> 2023-05-25T13:51:58+00:00</published><title> OpenAI 现在抱怨人工智能的监管 [D]</title></entry><entry><author><name> /u/电-华尔兹-605</name><uri> https://www.reddit.com/user/Electrical-Waltz-605 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;嘿，&lt;/p>; &lt;p>;我正在尝试微调模型 - LLaMA。我在 ChatGPT 上尝试了这个任务，因为我认为这可能是简单的用例，但他们经常错误地回答问题。所以，我想尝试训练 LLaMA 简单模型，看看它是如何工作的。&lt;/p>; &lt;p>;基本上，我想把新问题交给 LLM 模型，看看他们是否能理解问题并检查示例（以下案例中的主题分类）。这是一个例子。&lt;/p>; &lt;p>;我：我要给你定义一些概念，然后分享一些示例内容。你能帮忙确定内容是否符合概念吗？&lt;/p>; &lt;p>;---&lt;/p>; &lt;p>;我：“Topic Car”是“关于除其他不同类型的交通工具（如自行车、独轮车、摩托车、船等）以外的四轮交通工具的内容描述”&lt;/p>; &lt;p>;我：“例1”是“一辆汽车正在追赶一辆飞驰的保时捷 911”。执行“示例 1”吗？匹配“Topic Car”？&lt;/p>; &lt;p>;---&lt;/p>; &lt;p>;我：“Topic Carrot”是“content has anything about any vegetable with red/orange color”&lt;/p>; &lt;p>;我：“示例 2”是“番茄在花园里”。执行“示例 2”吗？匹配“主题胡萝卜”？&lt;/p>; &lt;p>;---&lt;/p>; &lt;p>;我认为它们很简单。但是，两者的回答都与我的预期不同，如下所示。&lt;/p>; &lt;p>;汽车案例&lt;/p>; &lt;p>;基于提供的“主题汽车”概念，作为四轮车辆，不包括其他类型的车辆，“示例 1”的内容为不符合概念。虽然它提到了一辆汽车（保时捷 911），但它并没有提供任何具体表明它是概念车的信息。此外，内容的重点是追逐飞驰的保时捷 911 的汽车，而不是描述车辆本身。因此，“示例1”不符合“主题汽车”的概念。&lt;/p>; &lt;p>;胡萝卜的案例&lt;/p>; &lt;p>;基于“主题胡萝卜”的概念作为与具有红色或橙色的蔬菜相关的内容，“示例2”的内容是“示例2”的内容。不符合概念。虽然该示例提到了一种蔬菜（西红柿），但并未指定它具有红色或橙色。因此，“实施​​例2”不符合“主题胡萝卜”的概念。&lt;/p>; &lt;p>;---&lt;/p>; &lt;p>;我绝对可以通过内容中的更多信息使这个答案更好。但是，我想看看我是否可以针对这种情况对 LLaMA 模型进行微调来制作模型。然后，也许我可以让机器人进行主题分类。&lt;/p>; &lt;p>;在传统的 ML 任务中，如果我想进行主题分类，我需要大量固定特定类别的标记数据并训练模型。但是，如果我能做到以上几点，也许我可以有任何新的类别，并制作模型来为我分类和预测主题，即使没有任何额外的数据和类别的定义。&lt;/p>; &lt;p>;任何建议我的案例的培训数据？有什么建议吗？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Electrical-Waltz-605&quot;>; /u/Electrical-Waltz-605 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https: //www.reddit.com/r/MachineLearning/comments/13spqaj/r_dataset_recommendation_for_llama_finetuning/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13spqaj/r_dataset_recommendation_for_llama_finetuning/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13spqaj </id><link href="https://www.reddit.com/r/MachineLearning/comments/13spqaj/r_dataset_recommendation_for_llama_finetuning/"/><updated> 2023-05-26T21:58:34+00:00</updated><published> 2023-05-26T21:58:34+00:00</published><title> [R] LLaMA 微调的数据集推荐</title></entry><entry><author><name>/u/ThePanArchitect</name><uri> https://www.reddit.com/user/ThePanArchitect </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好&lt;/p>; &lt;p>;我想知道是否有人有兴趣讨论一些关于进一步为建筑师开发人工智能工具的话题。在您阅读之前，我必须声明，我对 AI 和 Transformer 模型的了解非常浅薄。请原谅我的无知，尽管如此，我还是非常感兴趣。&lt;/p>; &lt;p>;所以...如果尚未发生，人工智能在建筑中的集成已经得到了广泛的讨论。然而，从我的角度来看，它似乎是在一个相对表面的层面上实现的。即通过使用 Midjourney 或 ControlNET 等文本提示生成图像。但是，我还没有看到真正可以理解几何或 3D 形状的工具或模型。尽管从技术上讲，几何可以通过文本或数学公式来表示更复杂的表面和形状。如果几何可以转换成文本，它就可以被理解和预训练，&lt;em>;对吗？&lt;/em>;&lt;/p>; &lt;p>;已经有一篇优秀的研究论文对这种想法进行了概念验证，论文被称为“Architext”而且我认为，深入研究将几何图形表示为文本，将墙壁、窗户、门等表示为文本或任何其他可以预训练的格式的想法肯定会有所收获。&lt;/p>; &lt;p>;也许墙可以用元组表示，例如：&lt;br/>; (&lt;em>;baselineL1[Startpoint(x1,y1),Endpoint(x2,y2)], thickness=250 mm, height=2800)&lt;/em>;&lt;/ p>; &lt;p>;事实上，实际上有一种名为 IFC 的文件格式，它基本上是将整个 BIM 转换为文本。也许 IFC 可以用作“训练集”？&lt;/p>; &lt;p>;我可能有点超前了，但前景真的很诱人，请原谅我的热情，如果它看起来被误导了，最重要的是我的无知。我对这个话题的理解很肤浅。&lt;/p>; &lt;p>;我真的很期待听到你们的声音&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/ThePanArchitect&quot;>; /u/ThePanArchitect &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13sloh2/first_post_the_exciting_prospect_of_ai_in/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sloh2/first_post_the_exciting_prospect_of_ai_in/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13sloh2 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13sloh2/first_post_the_exciting_prospect_of_ai_in/"/><updated> 2023-05-26T19:07:02+00:00</updated><published> 2023-05-26T19:07:02+00:00</published><title>第一次发帖！人工智能在建筑和施工中令人兴奋的前景[讨论]</title></entry><entry><author><name> /u/rwill128</name><uri> https://www.reddit.com/user/rwill128 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;有人知道与此主题相关的论文吗？ &lt;/p>; &lt;p>;看起来像法学硕士，尤其是即将成为多模态的，可以与传感器和相机输入密切相关，可以成为规划和高级考虑的强大工具，例如识别某些任务的机会等.&lt;/p>; &lt;p>;从我在 HuggingFace 论文等中看到的情况来看，LLM 的进展可能还没来得及深入机器人技术，但我想我会问。&lt;/p>; &lt;/ div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/rwill128&quot;>; /u/rwill128 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13scb1b/d_llms_in_robotics/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13scb1b/d_llms_in_robotics/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13scb1b </id><link href="https://www.reddit.com/r/MachineLearning/comments/13scb1b/d_llms_in_robotics/"/><updated> 2023-05-26T12:47:28+00:00</updated><published> 2023-05-26T12:47:28+00:00</published><title> [D] 机器人学法学硕士</title></entry><entry><author><name>/你/mesqz</name><uri> https://www.reddit.com/user/mesqz </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&lt;a href=&quot;https://medium.com/@tiago-mesquita/microsoft-shares-5-point-blueprint-for-governing -ai-1a88104a0cd9&quot;>;https://medium.com/@tiago-mesquita/microsoft-shares-5-point-blueprint-for-governing-ai-1a88104a0cd9&lt;/a>;&lt;br/>;微软分享的要点# 39；的蓝图是：&lt;br/>;1. 建立在政府主导的人工智能安全框架之上&lt;br/>;2. 为控制关键基础设施的人工智能系统实施安全制动&lt;br/>;3. 制定技术感知的法律和监管框架&lt;br/>; 4. 提高透明度并扩大 AI 的使用范围&lt;br/>; 5. 利用公私合作伙伴关系造福社会&lt;br/>; 您还希望蓝图的其他哪些方面？&lt;/p>; &lt;/div>;&lt;! -- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/mesqz&quot;>; /u/mesqz &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13sr1nv/n_microsoft_shared_a_5point_blueprint_for/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sr1nv/n_microsoft_shared_a_5point_blueprint_for/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13sr1nv </id><link href="https://www.reddit.com/r/MachineLearning/comments/13sr1nv/n_microsoft_shared_a_5point_blueprint_for/"/><updated> 2023-05-26T22:54:29+00:00</updated><published> 2023-05-26T22:54:29+00:00</published><title> [N] 微软分享了治理 AI 的 5 点蓝图</title></entry><entry><author><name>/你/阿杜纳托</name><uri>https://www.reddit.com/user/adunato </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，&lt;/p>; &lt;p>;最近，我一直在处理几个使用 PyTorch 的 GitHub 项目。对于每个项目，我维护一个单独的 Conda 环境（我通过艰难的方式了解到为什么这很重要）。&lt;/p>; &lt;p>;但是，我遇到的一个持续存在的问题涉及 PyTorch 与我的 CUDA 的兼容性版本。具体来说，通过 requirements.txt 文件安装的 PyTorch 版本通常与我的 CUDA 版本不兼容，导致无法识别 CUDA 设备。&lt;/p>; &lt;p>;为了解决这个问题，我采用了一种做法我从 requirements.txt 文件中删除了对 PyTorch（以及相关库，如 torchvision、torchaudio）的任何提及，并从官方 PyTorch 站点手动安装它。&lt;/p>; &lt;p>;这是一种常见做法吗？或者我错过了一个更简化的工作流程来确保 PyTorch 和 CUDA 的兼容性？我很想听听其他人是如何处理这个问题的。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/adunato&quot;>; /u/adunato &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13s6x3b/d_best_practices_for_installing_pytorch_to_align/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s6x3b/d_best_practices_for_installing_pytorch_to_align/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13s6x3b </id><link href="https://www.reddit.com/r/MachineLearning/comments/13s6x3b/d_best_practices_for_installing_pytorch_to_align/"/><updated> 2023-05-26T08:02:39+00:00</updated><published> 2023-05-26T08:02:39+00:00</published><title> [D] 安装 PyTorch 以与特定 CUDA 版本保持一致的最佳实践</title></entry><entry><author><name>/u/知道杰罗姆</name><uri>https://www.reddit.com/user/iknowjerome </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;表>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sd4ku/r_samadrivescalifornia_automotive_semantic/&quot;>; &lt;img src=&quot;https://b.thumbs.redditmedia .com/6mKRKGxChyyetC3FAKtYmWYw3zxEdQM6gd3Tjw1DuwI.jpg&quot; alt=&quot;[R] sama-drives-california：汽车语义分割数据集（25k 帧）现已可用&quot; title=&quot;[R] sama-drives-california：汽车语义分割数据集（25k 帧）现在可用&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，&lt;/p>; &lt;p>;Sama 刚刚发布了另一个数据集根据 Creative Commons 4.0 许可。它可以在 Hugging Face 上找到。您可以查看 Hugging Face &lt;a href=&quot;https://huggingface.co/datasets/SamaAI/sama-drives-california&quot;>;数据集卡&lt;/a>;了解更多详细信息。如果您想直接下载 BDD100K 格式而不通过 Hugging Face，这里是 &lt;a href=&quot;https://sama-documentation-assets.s3.amazonaws.com/sama-drives -california/zipped/sama-drives-california.zip&quot;>;zip 文件&lt;/a>; (2.3GB)。请随时告诉我您的想法。&lt;/p>; &lt;p>;&lt;em>;免责声明：我为 Sama 工作&lt;/em>;&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/op4hdkqjf62b1.png?width=2239&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2eb3b66a194fc29c34fe42167d6b78af537b4bc7&quot;>;样本帧&lt;/a>;&lt;/p>; &lt;/div>;&lt;! -- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/iknowjerome&quot;>; /u/iknowjerome &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13sd4ku/r_samadrivescalifornia_automotive_semantic/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sd4ku/r_samadrivescalifornia_automotive_semantic/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13sd4ku </id><media:thumbnail url="https://b.thumbs.redditmedia.com/6mKRKGxChyyetC3FAKtYmWYw3zxEdQM6gd3Tjw1DuwI.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13sd4ku/r_samadrivescalifornia_automotive_semantic/"/><updated> 2023-05-26T13:21:34+00:00</updated><published> 2023-05-26T13:21:34+00:00</published><title> [R] sama-drives-california：汽车语义分割数据集（25k 帧）现已可用</title></entry><entry><author><name>/u/ironborn123</name><uri> https://www.reddit.com/user/ironborn123 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;看起来有点雄心勃勃，但有点有趣。&lt;/p>; &lt;p>;&lt;a href=&quot;https://kommonmann.wordpress.com /2023/05/26/a-new-academic-citation-system-based-on-semantic-understanding-with-llms/&quot;>;https://kommonmann.wordpress.com/2023/05/26/a-new -academic-citation-system-based-on-semantic-understanding-with-llms/&lt;/a>;&lt;/p>; &lt;p>;作者提供了基本几何学的例子，这似乎是一个很好的开始。但这大规模可行吗？有人在构建这样的框架吗？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/ironborn123&quot;>; /u/ironborn123 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13sigt7/d_overhauling_research_citations_with_gpt4/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13sigt7/d_overhauling_research_citations_with_gpt4/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13sigt7 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13sigt7/d_overhauling_research_citations_with_gpt4/"/><updated> 2023-05-26T16:54:08+00:00</updated><published> 2023-05-26T16:54:08+00:00</published><title> [D] 使用 GPT4 彻底修改研究引用？</title></entry><entry><author><name> /u/忧虑_Rush314</name><uri> https://www.reddit.com/user/Apprehensive_Rush314 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;RL 有这些缺点：1) 没有目标特征 2) 需要大量计算&lt;/p>; &lt;p>;我一直在努力寻找适用于我的150个特征数据的特征选择方法，但大多数方法都需要目标特征进行计算。包装器方法也不是一个好主意，因为对于这么多的特征，它需要永远计算。 &lt;/p>; &lt;p>;对于这种 RL 案例，你们有任何关于自动特征选择方法的建议吗？&lt;/p>; &lt;p>;谢谢&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp; #32；由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Apprehensive_Rush314&quot;>; /u/Apprehensive_Rush314 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13snvst/d_feature_selection_methods_for_rl_with_150/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13snvst/d_feature_selection_methods_for_rl_with_150/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13snvst </id><link href="https://www.reddit.com/r/MachineLearning/comments/13snvst/d_feature_selection_methods_for_rl_with_150/"/><updated> 2023-05-26T20:39:47+00:00</updated><published> 2023-05-26T20:39:47+00:00</published><title> [D] 具有 150 个特征的 RL 的特征选择方法</title></entry><entry><author><name>/u/Simple-Respect-1937</name><uri> https://www.reddit.com/user/Simple-Respect-1937 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，大家好！&lt;/p>; &lt;p>;我和我的团队正在进行人脸识别项目。我们所做的是，我们从实时摄像机中提取人脸图像，然后使用 Facenet 为每张脸进行嵌入。这些嵌入是向量。因此，通过测量两个向量（两个人脸图像的嵌入）之间的距离，我们可以判断这两张图像是否来自同一个人。这是我们阅读论文时人脸识别的正常程序。 &lt;/p>; &lt;p>;但是我们遇到的是，我们为印度人脸运行程序设置的阈值对东亚（中国）人脸不起作用，尽管它对印度人脸有效。所以我们也尝试阅读一些研究论文。那些论文也是如此，承认存在这样的问题。 &lt;/p>; &lt;p>;&lt;strong>;我只是想知道以前是否有人遇到过完全相同的问题。如果有的话，那么你采用了什么方法？&lt;/strong>;&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;我对 Reddit 有点陌生，所以如果我做了任何提问时出错，请见谅。谢谢大家！&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Simple-Respect-1937&quot;>; /u/Simple-Respect-1937 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https: //www.reddit.com/r/MachineLearning/comments/13s80ev/face_recognition_models_require_different/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13s80ev/face_recognition_models_require_different/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13s80ev </id><link href="https://www.reddit.com/r/MachineLearning/comments/13s80ev/face_recognition_models_require_different/"/><updated> 2023-05-26T09:11:37+00:00</updated><published> 2023-05-26T09:11:37+00:00</published><title>人脸识别模型对不同种族需要不同的阈值？ [D]</title></entry><entry><author><name> /u/Hot-Heron4388</name><uri> https://www.reddit.com/user/Hot-Heron4388 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我很好奇是否有一种方法可以让模型根据用户的需求访问不同的知识集卷;除了训练不同的模型？例如，如果我有一个通常需要订阅的数据集，是否有一种方法可以让单个 LLM 仅在提供用户的订阅信息时才能访问此知识？我能想到的最接近的事情是：&lt;/p>; &lt;p>;A）根本不要在数据集上改进 LLM，只需通过增强提示合并额外的数据集信息&lt;/p>; &lt;p>;B）为每个可能的订阅数据集组合训练不同的 LLM，并且基于一个人的订阅，它们链接到不同的 LLM（这是我想避免的）。 &lt;/p>; &lt;p>;C) 根据用户的订阅对允许的提示实施限制。&lt;/p>; &lt;p>;理想情况下，我想知道是否有办法让我不需要做增强提示的单一法学硕士（因为我的数据集不小，所以我遇到了上下文窗口问题），而且我不想拥有无数不同的法学硕士稍微不一样。我读过的所有关于试图限制提示本身的内容（这样没有订阅的人就不能问相关问题）似乎相当困难并且经常被聪明的提示技术规避，或者需要一个大量的幕后工作来关闭任何给定的漏洞（这也只有在发现正在访问的额外信息后才有效）。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Hot-Heron4388&quot;>; /u/Hot-Heron4388 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www. reddit.com/r/MachineLearning/comments/13shu7k/d_roles_based_model_knowledge/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13shu7k/d_roles_based_model_knowledge/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13shu7k </id><link href="https://www.reddit.com/r/MachineLearning/comments/13shu7k/d_roles_based_model_knowledge/"/><updated> 2023-05-26T16:29:58+00:00</updated><published> 2023-05-26T16:29:58+00:00</published><title> [D] 基于角色的模型知识？</title></entry><entry><author><name> /u/deviantkindle</name><uri> https://www.reddit.com/user/deviantkindle </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;IIUC，通过 chatGPT 接口发送的任何数据都可以（并且将会？）用于训练。相反，通过 API 提交的任何数据都不会用于训练。正确吗？&lt;/p>; &lt;p>;如果是这样，以下情况的可行性如何：InternA 无意中通过 chatGPT 提示上传了有关 CompanyA 的机密信息。为什么 EvilCompetitor 不能使用 chatGPT/API 来搜索此类机密信息？&lt;/p>; &lt;p>;我（目前）不是在寻找解决这个问题的方法；我正在查看它是否 &lt;em>;&lt;/em>; 是一个问题。因此，没有本地 LLM 或特殊的企业级护栏（“每月仅需 10,000 美元！但是等等！还有更多！”），或“IT 部门应该……”的建议。&lt; /p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/deviantkindle&quot;>; /u/deviantkindle &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13shrc6/d_mining_openai_for_competitor_data/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13shrc6/d_mining_openai_for_competitor_data/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13shrc6 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13shrc6/d_mining_openai_for_competitor_data/"/><updated> 2023-05-26T16:26:54+00:00</updated><published> 2023-05-26T16:26:54+00:00</published><title> [D] 为竞争对手数据挖掘 OpenAI</title></entry></feed>