<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category label="r/MachineLearning" term="MachineLearning"></category><updated> 2023-05-25T16:19:22+00:00</updated><icon> https://www.redditstatic.com/icon.png/</icon><id> /r/机器学习/.rss </id><link href="https://www.reddit.com/r/MachineLearning/.rss" rel="self" type="application/atom+xml"/><link href="https://www.reddit.com/r/MachineLearning/" rel="alternate" type="text/html"/><logo> https://b.thumbs.redditmedia.com/18a2I44a4l7fNrTWHDoJuWVy79_ptU7Y-a2sqWt4YKQ.png</logo><title>机器学习</title><entry><author><name>/u/自动版主</name><uri>https://www.reddit.com/user/AutoModerator </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;请在此处发布您的问题，而不是创建新线程。鼓励其他为问题创建新帖子的人改为在此处发帖！&lt;/p>; &lt;p>;帖子将一直存在到下一个帖子，因此请在标题中的日期之后继续发帖。&lt;/p>; &lt;p>;感谢大家回答问题在上一个线程中！&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/AutoModerator&quot;>; /u/AutoModerator &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13nx7t0 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13nx7t0/d_simple_questions_thread/"/><updated> 2023-05-21T15:00:21+00:00</updated><published> 2023-05-21T15:00:21+00:00</published><title> [D] 简单问题线程</title></entry><entry><author><name>/u/MTGTraner</name><uri> https://www.reddit.com/user/MTGTraner </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/MTGTraner&quot;>; /u/MTGTraner &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_120f4oy </id><link href="https://www.reddit.com/r/MachineLearning/comments/120f4oy/reminder_use_the_report_button_and_read_the_rules/"/><updated> 2023-03-24T09:32:29+00:00</updated><published> 2023-03-24T09:32:29+00:00</published><title>提醒：使用举报按钮并阅读规则！</title></entry><entry><author><name> /u/I_will_delete_myself</name><uri> https://www.reddit.com/user/I_will_delete_myself </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我犹豫了一会儿，但听到这个消息后虚伪让我发疯。&lt;/p>; &lt;p>;SMH 这家公司就像白衣骑士一样，他们认为他们凌驾于所有人之上。他们想要监管，但他们希望不受该监管的影响。只想伤害其他人，但不想伤害“全能的”Sam 和朋友。&lt;/p>; &lt;p>;向国会撒谎说建议在欧盟采取类似的做法，但现在开始抱怨他们。在任何政治领域都不应该认真对待这个家伙。&lt;/p>; &lt;p>;我的观点是，这家公司通过锁定与其品牌名称相悖的东西来反对 AI 进步。如果他们甚至不能忠于这样简单的事情，我们怎么能指望他们忠于更难的 AI 安全？&lt;/p>; &lt;p>;我很高兴他们现在改变了立场，但我很高兴他们如何他们认为他们有权为了自己的利益而腐败。 SMH!!!!!!!!&lt;/p>; &lt;p>;你有什么想法？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/I_will_delete_myself&quot;>; /u/I_will_delete_myself &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rie0e/openai_is_now_complaining_about_regulation_of_ai_d/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rie0e/openai_is_now_complaining_about_regulation_of_ai_d/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rie0e </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rie0e/openai_is_now_complaining_about_regulation_of_ai_d/"/><updated> 2023-05-25T13:51:58+00:00</updated><published> 2023-05-25T13:51:58+00:00</published><title> OpenAI 现在抱怨人工智能的监管 [D]</title></entry><entry><author><name> /u/Ok_Bank_2217</name><uri> https://www.reddit.com/user/Ok_Bank_2217 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我们需要为我们的平台获取大量 YouTube 数据并训练自定义 ML 模型，但除了 YouTube 之外找不到任何有用的东西8M Dataset，相当过时，信息非常有限。官方的 YouTube 数据 API 也被限制在大约 10.000 个积分，这远远不能满足我们需要的数量。&lt;/p>; &lt;p>;这就是为什么我们说去他妈的，并决定自己构建一个巨大的 YouTube 数据集。在为超过 1 亿个视频编制索引并构建自定义 API 来访问它之后，我们决定公开 API 并允许人们购买访问权限！&lt;/p>; &lt;p>;&lt;a href=&quot;https://www.blizzy -data.com/&quot;>;链接到网站&lt;/a>;&lt;/p>; &lt;p>;我们很乐意听到我们的 ML 工程师和数据科学家的反馈，并希望解决您和我们遇到的问题!&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Ok_Bank_2217&quot;>; /u/Ok_Bank_2217 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rh9yj/p_we_created_a_large_youtube_video_dataset_to/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rh9yj/p_we_created_a_large_youtube_video_dataset_to/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rh9yj </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rh9yj/p_we_created_a_large_youtube_video_dataset_to/"/><updated> 2023-05-25T13:04:43+00:00</updated><published> 2023-05-25T13:04:43+00:00</published><title> [P] 我们创建了一个大型 YouTube 视频数据集来替换 YouTube 数据 API</title></entry><entry><author><name> /u/我是布兰妮</name><uri>https://www.reddit.com/user/ISpearedBritney </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;如果你的很多工作都涉及 AI 或 ML（无论标题如何），你能分享一下你的典型工作日是怎样的吗？您将时间花在什么上，最终经常使用哪些工具或资源？其中有多少是数据争论，你使用了多少数学？谢谢！&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/ISpearedBritney&quot;>; /u/ISpearedBritney &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rct07/d_for_those_of_you_who_work_in_mlai_what_are_your/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rct07/d_for_those_of_you_who_work_in_mlai_what_are_your/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rct07 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rct07/d_for_those_of_you_who_work_in_mlai_what_are_your/"/><updated> 2023-05-25T09:21:06+00:00</updated><published> 2023-05-25T09:21:06+00:00</published><title> [D] 对于那些从事 ML/AI 工作的人，您的工作和工作日是什么样的？</title></entry><entry><author><name> /u/弗兰克米勒MC</name><uri> https://www.reddit.com/user/FrankMillerMC </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&lt;a href=&quot;https://huggingface.co/tiiuae&quot;>;https://huggingface.co/tiiuae&lt;/a>;&lt;/ p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/FrankMillerMC&quot;>; /u/FrankMillerMC &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rizo0/new_large_language_model_for_use_commercial/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rizo0/new_large_language_model_for_use_commercial/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rizo0 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rizo0/new_large_language_model_for_use_commercial/"/><updated> 2023-05-25T14:16:29+00:00</updated><published> 2023-05-25T14:16:29+00:00</published><title>用于商业的新大型语言模型（开源）[N]</title></entry><entry><author><name> /你/米勒</name><uri>https://www.reddit.com/user/mierle </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13r1hkg/qlora_efficient_finetuning_of_quantized_llms/&quot;>; &lt;img src=&quot;https://external-preview.redd .it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=72b056142e7533b5628a2a34f37f7e5415727075&quot; alt=&quot;QLoRA: Effi量化 LLM 的 cient Finetuning&quot; title=&quot;QLoRA：量化 LLM 的高效微调&quot; />; &lt; /a>; &lt;/td>;&lt;td>; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/mierle&quot;>; /u/mierle &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://arxiv.org/abs/ 2305.14314&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13r1hkg/qlora_efficient_finetuning_of_quantized_llms/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13r1hkg </id><media:thumbnail url="https://external-preview.redd.it/0HhwdU6MKIAKjL9Y8-B_iH374a3NiPTy0ib8lmloRzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b056142e7533b5628a2a34f37f7e5415727075"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13r1hkg/qlora_efficient_finetuning_of_quantized_llms/"/><updated> 2023-05-24T23:29:47+00:00</updated><published> 2023-05-24T23:29:47+00:00</published><title> QLoRA：量化 LLM 的高效微调</title></entry><entry><author><name>/u/奇异语2501</name><uri> https://www.reddit.com/user/Singularian2501 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rkhzx/r_reasoning_with_language_model_is_planning_with/&quot;>; &lt;img src=&quot;https://b.thumbs.redditmedia .com/huTwcaqVaNrBZzikekNSL9XJi3tfEGZsggLCg50LMYM.jpg&quot; alt=&quot;[R] 用语言模型推理就是用世界模型进行规划 - Shibo Hao 等加州大学圣地亚哥分校 - LLAMA-33B 上的 RAP 超过 GPT-4 上的 CoT，计划相对改进了 33%世代设定！” title=&quot;[R] 用语言模型推理就是用世界模型进行规划 - Shibo Hao 等加州大学圣地亚哥分校 - LLAMA-33B 上的 RAP 超过 GPT-4 上的 CoT，在计划生成设置中相对改进了 33%！” />; &lt;/a>; &lt;/td>;&lt;td>; &lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;论文：&lt;a href=&quot;https://arxiv.org/abs/2305.14992 &quot;>;https://arxiv.org/abs/2305.14992&lt;/a>; &lt;/p>; &lt;p>;摘要：&lt;/p>; &lt;blockquote>; &lt;p>;大型语言模型 (LLM) 已显示出非凡的推理能力，尤其是当提示生成中间推理步骤（例如，Chain-of-Thought，CoT）。然而，LLM 仍然难以解决对人类来说很容易的问题，例如为在给定环境中执行任务生成行动计划，或者执行复杂的数学、逻辑和常识推理。缺陷源于一个关键事实，即 LLM 缺乏内部&lt;em>;世界模型&lt;/em>;来预测世界&lt;em>;状态&lt;/em>;（例如，环境状态、中间变量值）并模拟长期结果动作。这可以防止 LLM 执行类似于人脑的深思熟虑的计划，这涉及探索替代推理路径、预测未来状态和奖励，以及迭代改进现有推理步骤。为了克服这些限制，我们提出了一个新的 LLM 推理框架，&lt;strong>;&lt;em>;R&lt;/em>;&lt;/strong>;&lt;strong>;––&lt;/strong>;&lt;strong>;&lt;em>;easoning via&lt;/em>; /strong>;&lt;strong>;––&lt;/strong>;&lt;strong>;&lt;em>;P&lt;/em>;&lt;/strong>;&lt;strong>;––&lt;/strong>;&lt;strong>;&lt;em>;规划&lt;/em>;&lt;/strong >; &lt;strong>;(RAP).&lt;/strong>; RAP 将 &lt;strong>;LLM 重新定位为世界模型和推理代理，并结合原则性规划算法（基于蒙托卡罗树搜索）在广阔的推理中进行战略探索&lt;/strong>; 在推理过程中，LLM（作为代理）在LLM（作为世界模型）和任务特定奖励的指导下，增量构建推理树，并在适当的平衡下高效地获得高奖励推理路径在探索 &lt;em>; 与 &lt;/em>; 开发之间。我们将 RAP 应用于各种具有挑战性的推理问题，包括计划生成、数学推理和逻辑推理。这些任务的实证结果证明了 RAP 优于各种强大的基线，包括 CoT 和自洽性从最少到最多的提示。 &lt;strong>;LLAMA-33B 上的 RAP 超过了 GPT-4 上的 CoT，计划生成设置相对改进了 33%。&lt;/strong>;&lt;/p>; &lt;/blockquote>; &lt;p>;&lt;a href=&quot;https://preview .redd.it/jaoiil2mc12b1.jpg?width=747&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=28086d47e9c9ba38fdda8afbd9f15464bfb07a53&quot;>;https://preview.redd.it/jaoiil2mc12b1.jpg?width=747&amp;amp;format= pjpg&amp;auto= webp&amp;amp;s=28086d47e9c9ba38fdda8afbd9f15464bfb07a53&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/pq9c0o2mc12b1.jpg?width=1356&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7389d75d0ff7 d1d8787c7c5f9add4787b02b47be &quot;>;https://preview.redd.it/pq9c0o2mc12b1.jpg?width=1356&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7389d75d0ff7d1d8787c7c5f9add4787b02b47be&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https:/ /preview.redd.it/ykpqvp2mc12b1.jpg?width=980&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=834c39fb3e549418b8396725e86ddff3c6584077&quot;>;https://preview.redd.it/ykpqvp2mc12b1.jpg?width=9 80&amp;amp;格式=pjpg&amp;amp; auto=webp&amp;amp;s=834c39fb3e549418b8396725e86ddff3c6584077&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/zlqb8q2mc12b1.jpg?width=1294&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s =9c5192d6c012bfe4390fa67b010580b8e4508daa&quot;>;https://preview.redd.it/zlqb8q2mc12b1.jpg?width=1294&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=9c5192d6c012bfe4390fa67b010580 b8e4508daa&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https //preview.redd.it/qd8pjo2mc12b1.jpg?width=1400&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=1017764e376aa1a8bfa9fd03eef22fb455bd7bea&quot;>;https://preview.redd.it/qd8pjo2mc12b1.jpg?width=140 0&amp;格式= pjpg&amp;amp;auto=webp&amp;amp;s=1017764e376aa1a8bfa9fd03eef22fb455bd7bea&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Singularian2501&quot;>; /u/Singularian2501 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rkhzx/r_reasoning_with_language_model_is_planning_with/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rkhzx/r_reasoning_with_language_model_is_planning_with/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13rkhzx </id><media:thumbnail url="https://b.thumbs.redditmedia.com/huTwcaqVaNrBZzikekNSL9XJi3tfEGZsggLCg50LMYM.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13rkhzx/r_reasoning_with_language_model_is_planning_with/"/><updated> 2023-05-25T15:17:59+00:00</updated><published> 2023-05-25T15:17:59+00:00</published><title> [R] 使用语言模型进行推理就是使用世界模型进行规划 - Shibo Hao 等人，加州大学圣地亚哥分校 - LLAMA-33B 上的 RAP 超过 GPT-4 上的 CoT，计划生成设置相对改进了 33%！</title></entry><entry><author><name> /你/sann540</name><uri> https://www.reddit.com/user/sann540 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&lt;a href=&quot;https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2&quot; >;https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/sann540&quot;>; /u/sann540 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13qrtek/n_state_of_gpt_by_andrej_karpathy_in_msbuild_2023/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13qrtek/n_state_of_gpt_by_andrej_karpathy_in_msbuild_2023/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13qrtek </id><link href="https://www.reddit.com/r/MachineLearning/comments/13qrtek/n_state_of_gpt_by_andrej_karpathy_in_msbuild_2023/"/><updated> 2023-05-24T17:25:33+00:00</updated><published> 2023-05-24T17:25:33+00:00</published><title> [N] Andrej karpathy 在 MSBuild 2023 中的 GPT 状态</title></entry><entry><author><name>/u/_negativeonetwelfth</name><uri> https://www.reddit.com/user/_negativeonetwelfth </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;在从许多不同的来源阅读了这些算法的实现之后，我仍然看到了关于此的相互矛盾的信息。一些消息来源说（或暗示）你可以获得更高的帧率，因为你可以更少地运行深度学习对象检测器，并连续几帧使用卡尔曼滤波器预测框。另一方面，一些消息来源表明情况并非如此，因为过滤器仅用于根据先前位置预测当前（而非未来）位置，并且需要在每次迭代中使用深度学习检测进行更新。&lt; /p>; &lt;p>;我想知道是否有人对这些算法有经验并且能够提供一个真实而明确的答案。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32 ;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/_negativeonetwelfth&quot;>; /u/_negativeonetwelfth &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rgy1g/d_do_tracking_algorithms_that_use_a_kalman_filter/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rgy1g/d_do_tracking_algorithms_that_use_a_kalman_filter/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rgy1g </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rgy1g/d_do_tracking_algorithms_that_use_a_kalman_filter/"/><updated> 2023-05-25T12:50:26+00:00</updated><published> 2023-05-25T12:50:26+00:00</published><title> [D] 使用卡尔曼滤波器（如 SORT 和 DeepSORT）的跟踪算法是否会增加系统的帧率？</title></entry><entry><author><name> /u/双倍体</name><uri>https://www.reddit.com/user/Gaploid </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rhgt5/p_using_gpt4_to_automatically_extract_insights/&quot;>; &lt;img src=&quot;https://b.thumbs.redditmedia .com/SESB3xwR0W4B6ja9sC1v5aZbQ7rHU_rvGpMiqXUef5g.jpg&quot; alt=&quot;[P] 使用 GPT-4 自动从数据仪表板中提取见解&quot; title=&quot;[P] 使用 GPT-4 自动从数据仪表板中提取见解&quot; />; &lt;/a>; &lt; /td>;&lt;td>; &lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;大家好，&lt;/p>; &lt;p>;我们刚刚推出了一个新的 GPT-4 驱动的我们的数据分析平台的功能，并希望征求社区的意见。 &lt;/p>; &lt;p>;&lt;a href=&quot;https://i.redd.it/cb151k919z1b1.gif&quot;>;https://i.redd.it/cb151k919z1b1.gif&lt;/a>;&lt;/p>; &lt;p >;借助新功能，现在用户只需单击一下即可获得图表或仪表板上显示的数据的简单而全面的解释。 ChatGPT 无需任何特殊提示即可根据特定领域的知识生成适用的见解、解释甚至建议。这是可能的，因为我们开发了一种从图表中提取数据并将其以柱状格式传递到引擎盖下的提示的机制。这允许系统理解图表的上下文并使用深入分析所需的原始数据。&lt;/p>; &lt;p>;同时与您分享我们在开发新功能时发现的一些发现可能是对其他人有用：&lt;/p>; &lt;ol>; &lt;li>;提示的措辞至关重要；问题越具体，答案往往越准确。 &lt;strong>;所需语言、答案的最大长度和数据解释&lt;/strong>;等清晰的规范有助于改善结果。角色扮演或模拟专家也可以指导模型在特定知识领域内提供更详细的响应。&lt;/li>; &lt;li>;ChatGPT 擅长解析和&lt;strong>;处理表格数据&lt;/strong>;，包括 CSV。由于其紧凑性、准确性和可读性，我们选择这种格式将原始数据传输到模型。该模型甚至可以概念化来自此类表格的数据可以使用不同图表类型表示的方式，并可以使用这些可视化来解释数据。&lt;/li>; &lt;li>;值得注意的是，ChatGPT 似乎在挣扎具有&lt;strong>;大值和小数&lt;/strong>;的小数点。为了克服这个问题，我们将数字四舍五入到最多 2-3 位小数。这种做法不仅提高了准确性，而且减少了使用的令牌数量。&lt;/li>; &lt;/ol>; &lt;p>;我们想邀请大家试用我们的新功能并与我们分享您的想法。请点击&lt;a href=&quot;https://double.cloud/services/doublecloud-visualization/&quot;>;此链接访问&lt;/a>;我们的免费试用版——无需信用卡或 ChatGPT API 密钥。&lt;/p>; &lt;p >;我们很想听听您对我们开发的产品的看法。我们非常欢迎任何改进建议或潜在用途示例。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Gaploid&quot;>; /u/Gaploid &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rhgt5/p_using_gpt4_to_automatically_extract_insights/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rhgt5/p_using_gpt4_to_automatically_extract_insights/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>;&lt; /表>;</content><id> t3_13rhgt5 </id><media:thumbnail url="https://b.thumbs.redditmedia.com/SESB3xwR0W4B6ja9sC1v5aZbQ7rHU_rvGpMiqXUef5g.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13rhgt5/p_using_gpt4_to_automatically_extract_insights/"/><updated> 2023-05-25T13:12:40+00:00</updated><published> 2023-05-25T13:12:40+00:00</published><title> [P] 使用 GPT-4 自动从数据仪表板中提取见解</title></entry><entry><author><name>/u/行星</name><uri>https://www.reddit.com/user/planetoryd </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;独裁政权（例如中国）一直在使用盲水印，以简单和隐写的方式，通过嵌入隐藏信息来迫害举报人/发起人在应用程序界面中。我不是专家，但我认为待办事项是：&lt;/p>; &lt;ul>; &lt;li>;用于局部盲水印去除的高效 ML 模型（或者，ML 是否合适）&lt;/li>; &lt;li>;加速它的推理引擎，例如 Rust。&lt;/li>; &lt;li>;开源移动和桌面应用程序界面。 （可能集成到现有的 EXIF 去除器工作流程中）&lt;/li>; &lt;/ul>; &lt;p>;现有方法包括拍照而不是屏幕截图。 （屏幕摄像头攻击）它可能不那么安全。 &lt;a href=&quot;https://ieeexplore.ieee.org/document/9136707&quot;>;https://ieeexplore.ieee.org/document/9136707&lt;/a>;&lt;/p>; &lt;p>;它经常被中文提及持不同政见的 Reddit 社区。 （搜索 &lt;code>;reddit 盲水印&lt;/code>;）该技术也可能被出口。中国已经在与伊朗合作开发防火墙。我们需要做好准备。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/planetoryd&quot;>; /u/planetoryd &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rj2wp/d_a_call_to_implement_a_blind_watermark_removal/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rj2wp/d_a_call_to_implement_a_blind_watermark_removal/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rj2wp </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rj2wp/d_a_call_to_implement_a_blind_watermark_removal/"/><updated> 2023-05-25T14:20:08+00:00</updated><published> 2023-05-25T14:20:08+00:00</published><title> [D] 呼吁实施盲水印去除应用程序以捍卫公民自由。</title></entry><entry><author><name> /u/铁叶神经元</name><uri>https://www.reddit.com/user/tiedyeneuron </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;诚然，我在标题问题的措辞上略显幼稚和片面，以引发讨论。我认为从事深度学习研究的学术实验室有一定的优势。然而，许多重大突破现在似乎确实发生在工业实验室，而不是小型大学实验室。这可能是由于 DL 从新兴研究领域成熟为工业技术。&lt;/p>; &lt;p>;鉴于 DL 的最新发展，人们对在工业中进行深度学习研究的相对优点有何看法与学术界？例如，如果有人可以选择在顶级学术实验室（如麻省理工学院、斯坦福大学、加州大学伯克利分校等）担任研究员或加入 OpenAI/Anthropic/DeepMind 等，他们为什么要选择学术路径？&lt;/p >; &lt;p>;我理解有些人可能出于成为教授的愿望而选择学术界，但似乎越来越多的顶尖大学乐于让行业研究人员担任客座教授或担任兼职教授。许多行业科学家也接受实习生，因此他们仍然可以充当导师，就像他们是学术实验室的 PI 一样。仍然，显然留在 AI 学术界仍然有一些独特的价值，因为我能想到许多选择这样做的顶级研究人员。我很想知道人们认为与行业实验室相比有什么好处。&lt;/p>; &lt;p>;（我知道这是一个与职业相关的帖子，但它看起来不像 &lt;a href=&quot;https:// www.reddit.com/r/cscareerquestions/&quot;>;r/cscareerquestions&lt;/a>; 拥有合适的受众或专业知识来推动这一讨论。此外，我认为目前这一讨论非常针对跨行业/学术界的 ML 社区及时。）&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/tiedyeneuron&quot;>; /u/tiedyeneuron &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rl1q6/d_given_the_scaling_up_of_deep_learning_methods/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rl1q6/d_given_the_scaling_up_of_deep_learning_methods/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rl1q6 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rl1q6/d_given_the_scaling_up_of_deep_learning_methods/"/><updated> 2023-05-25T15:40:05+00:00</updated><published> 2023-05-25T15:40:05+00:00</published><title> [D] 鉴于深度学习方法的扩展，作为 AI 研究人员留在学术界的剩余优点是什么？</title></entry><entry><author><name> /u/周杰伦</name><uri>https://www.reddit.com/user/JayCTee </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;嘿伙计们，我正在做一个（假设的）项目，我想在大量非结构化客户数据上训练预训练的 LLM，以获得大公司。这个想法是它可以作为来自所有数据源的客户的知识库，可用于超个性化（例如产品匹配、内容生成等）。&lt;/p>; &lt;p>;我对训练部分——如果我想让它“学习”客户数据，我是使用微调、提示调优还是 RAG（我将微调理解为调整现有参数的权重，提示调优为添加更多参数，并且很难理解 RAG 是什么）。我看到一些消息来源说微调不能用于学习新数据？&lt;/p>; &lt;p>;任何人都可以就此过程或需要考虑的事项（例如数据敏感性）提供任何指示。我的在线搜索并不是那么富有成果&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/JayCTee&quot;>; /u/JayCTee &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rgmyt/p_uptraining_a_pretrained_model_using_company_data/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rgmyt/p_uptraining_a_pretrained_model_using_company_data/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rgmyt </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rgmyt/p_uptraining_a_pretrained_model_using_company_data/"/><updated> 2023-05-25T12:36:29+00:00</updated><published> 2023-05-25T12:36:29+00:00</published><title> [P] 使用公司数据训练预训练模型？</title></entry><entry><author><name> /u/太极官方</name><uri>https://www.reddit.com/user/TaichiOfficial </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rbij5/p_taichi_nerf_develop_and_deploy_instant_ngp/&quot;>; &lt;img src=&quot;https://b.thumbs.redditmedia .com/yR2V61hG-MR6-c-B7hm1M_8QJ7LEXpdvxPUZ7Gq9xFI.jpg&quot; alt=&quot;[P] Taichi NeRF：无需编写 CUDA 即可开发和部署即时 NGP&quot; title=&quot;[P] Taichi NeRF：无需编写 CUDA 即可开发和部署即时 NGP&quot; / >; &lt;/a>; &lt;/td>;&lt;td>; &lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;Taichi NeRF 使用神经辐射场实现高效的 3D 场景重建和新视点合成，同时提供基于 Python 的工作流程，用于即时 NGP 开发和移动设备上的轻松部署。&lt;/p>; &lt;p>;查看博客：&lt;a href=&quot;https://docs.taichi-lang.org/blog/taichi-instant- ngp&quot;>;https://docs.taichi-lang.org/blog/taichi-instant-ngp&lt;/a>;&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;&lt;a href=&quot;https ://i.redd.it/gymp61re7z1b1.gif&quot;>;https://i.redd.it/gymp61re7z1b1.gif&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32 ;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/TaichiOfficial&quot;>; /u/TaichiOfficial &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rbij5/p_taichi_nerf_develop_and_deploy_instant_ngp/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rbij5/p_taichi_nerf_develop_and_deploy_instant_ngp/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>;&lt; /表>;</content><id> t3_13rbij5 </id><media:thumbnail url="https://b.thumbs.redditmedia.com/yR2V61hG-MR6-c-B7hm1M_8QJ7LEXpdvxPUZ7Gq9xFI.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13rbij5/p_taichi_nerf_develop_and_deploy_instant_ngp/"/><updated> 2023-05-25T08:03:13+00:00</updated><published> 2023-05-25T08:03:13+00:00</published><title> [P] Taichi NeRF：无需编写 CUDA 即可开发和部署即时 NGP</title></entry><entry><author><name> /你/sann540</name><uri> https://www.reddit.com/user/sann540 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&lt;a href=&quot;https://www.artisana.ai/articles/meta-ai-unleashes-megabyte-a-revolutionary-scalable-模型架构&quot;>;https://www.artisana.ai/articles/meta-ai-unleashes-megabyte-a-revolutionary-scalable-model-architecture&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/sann540&quot;>; /u/sann540 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13qroe9/n_meta_ai_unleashes_megabyte_a_revolutionary/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13qroe9/n_meta_ai_unleashes_megabyte_a_revolutionary/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13qroe9 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13qroe9/n_meta_ai_unleashes_megabyte_a_revolutionary/"/><updated> 2023-05-24T17:20:14+00:00</updated><published> 2023-05-24T17:20:14+00:00</published><title> [N] Meta AI 释放 Megabyte，一种革命性的可扩展模型架构</title></entry><entry><author><name>/u/Tomatomakko</name><uri> https://www.reddit.com/user/Tomatomakko </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;向量神经元 [&lt;a href=&quot;https://arxiv.org/pdf/2104.12229.pdf&quot;>;https://arxiv.org/ pdf/2104.12229.pdf&lt;/a>;] 是一种在 3D 点云处理网络中实现旋转等方差的方法。是否可以将相同的想法转移到 2D CNN？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Tomatomakko&quot;>; /u/Tomatomakko &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rfd15/d_can_vector_neurons_be_used_to_achive_rotational/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rfd15/d_can_vector_neurons_be_used_to_achive_rotational/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rfd15 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rfd15/d_can_vector_neurons_be_used_to_achive_rotational/"/><updated> 2023-05-25T11:36:16+00:00</updated><published> 2023-05-25T11:36:16+00:00</published><title> [D] 可以使用向量神经元在 2D CNN 中实现旋转等方差吗？</title></entry><entry><author><name> /u/panthsdger</name><uri> https://www.reddit.com/user/panthsdger </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;全文：&lt;a href=&quot;https://arxiv.org/abs/2305.11252v1&quot;>;https://arxiv.org/abs /2305.11252v1&lt;/a>;&lt;/p>; &lt;p>;人工神经网络 (ANN) 已成为机器学习的重要工具，在图像和语音生成、游戏和机器人技术等多个领域取得了显著成功。然而，人工神经网络之间存在根本差异。操作机制和生物大脑的机制，特别是关于学习过程。本文全面回顾了人工神经网络中当前受大脑启发的学习表征。我们研究整合更多生物学上合理的机制，例如突触可塑性，以增强这些网络的功能。能力。此外，我们深入研究了伴随这种方法的潜在优势和挑战。最终，我们为这个快速发展的领域的未来研究指出了有前途的途径，这可以使我们更接近理解智能的本质。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/panthsdger&quot;>; /u/panthsdger &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rinw8/r_braininspired_learning_in_artificial_neural/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rinw8/r_braininspired_learning_in_artificial_neural/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rinw8 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rinw8/r_braininspired_learning_in_artificial_neural/"/><updated> 2023-05-25T14:02:59+00:00</updated><published> 2023-05-25T14:02:59+00:00</published><title> [r] 人工神经网络中的类脑学习：综述</title></entry><entry><author><name>/你/mesqz</name><uri> https://www.reddit.com/user/mesqz </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&lt;a href=&quot;https://medium.com/@tiago-mesquita/transforming-youtube-shorts-google-deepminds-flamingo-reinvents -metadata-for-maximum-impact-f817e1141dde&quot;>;https://medium.com/@tiago-mesquita/transforming-youtube-shorts-google-deepminds-flamingo-reinvents-metadata-for-maximum-impact-f817e1141dde&lt;/ a>;&lt;br/>; ‍&lt;br/>; Google 的人工智能研究部门 DeepMind 最近与 Google Brain 合并，组成了一个专注于推进人工智能技术的强大团队。&lt;/p>; &lt;p>;他们的最新项目 Flamingo 是一种视觉语言模型 (VLM)，它被用于通过生成自动和准确的视频描述来提高 YouTube Shorts 的可发现性。&lt;/p>; &lt;p>;YouTube 短片创作者通常优先考虑快速制作而不是创建有用的标题，而 Flamingo 旨在解决&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/mesqz&quot;>; /u/mesqz &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rl49e/n_google_deepminds_flamingo_is_focusing_on/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rl49e/n_google_deepminds_flamingo_is_focusing_on/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rl49e </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rl49e/n_google_deepminds_flamingo_is_focusing_on/"/><updated> 2023-05-25T15:42:54+00:00</updated><published> 2023-05-25T15:42:54+00:00</published><title> [N] Google DeepMind 的 Flamingo 专注于改进 YouTube 短片的描述以提高可发现性</title></entry><entry><author><name>/u/奇异语2501</name><uri> https://www.reddit.com/user/Singularian2501 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;table>; &lt;tr>;&lt;td>; &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rl3v9/r_gorilla_large_language_model_connected_with/&quot;>; &lt;img src=&quot;https://a.thumbs.redditmedia .com/pwokgMFTSRP9bRbBlTbOA1gPSTlPoECDQdwoNNPMuG0.jpg&quot; alt=&quot;[R] Gorilla：连接大量 API 的大型语言模型 - Microsoft Research 2023 - 在编写 API 调用方面超越 GPT-4 的性能。 title=&quot;[R] Gorilla：连接大量 API 的大型语言模型 - Microsoft Research 2023 - 在编写 API 调用方面超越 GPT-4 的性能。&quot; />; &lt;/a>; &lt;/td>;&lt;td>; &lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;论文：&lt;a href=&quot;https://arxiv.org/abs/2305.15334 &quot;>;https://arxiv.org/abs/2305.15334&lt;/a>; &lt;/p>; &lt;p>;Github：&lt;a href=&quot;https://github.com/ShishirPatil/gorilla&quot;>;https://github。 com/ShishirPatil/gorilla&lt;/a>; &lt;/p>; &lt;p>;博客：&lt;a href=&quot;https://gorilla.cs.berkeley.edu/&quot;>;https://gorilla.cs.berkeley.edu/&lt; /a>; &lt;/p>; &lt;p>;摘要：&lt;/p>; &lt;blockquote>; &lt;p>;大型语言模型 (LLM) 最近出现了令人印象深刻的进步浪潮，模型现在在各种任务中表现出色，例如数学推理和程序综合。然而，它们通过 API 调用有效使用工具的潜力仍未实现。即使对于当今最先进的 LLM（例如 GPT-4）而言，这也是一项具有挑战性的任务，这主要是因为它们无法生成准确的输入参数，并且它们倾向于产生错误的 API 调用用法。我们发布了 Gorilla，这是一种经过微调的基于 LLaMA 的模型，在编写 API 调用方面超越了 GPT-4 的性能。当与文档检索器结合使用时，Gorilla 展示了适应测试时文档更改的强大能力，支持灵活的用户更新或版本更改。 &lt;strong>;它还大大减轻了直接提示 LLM 时经常遇到的幻觉问题。&lt;/strong>;为了评估模型的能力，我们引入了 APIBench，这是一个由 HuggingFace、TorchHub 和 TensorHub API 组成的综合数据集。 &lt;strong>;检索系统与 Gorilla 的成功集成表明 LLM 有潜力更准确地使用工具，跟上经常更新的文档，从而提高其输出的可靠性和适用性。&lt;/strong>;&lt;/p>; &lt; /blockquote>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/n5ezjchbg12b1.jpg?width=872&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=eb5b7e11a22abe59d49504fad7278006a2b878a6&quot;>;https://preview.redd。它/n5ezjchbg12b1.jpg?width=872&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=eb5b7e11a22abe59d49504fad7278006a2b878a6&lt;/a>;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/e2xhpfhbg12b1.jpg ?width=1075&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b3c0f6ed7a6d72c93e681266977a0ec0f129ba6d&quot;>;https://preview.redd.it/e2xhpfhbg12b1.jpg?width=1075&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b 3c0f6ed7a6d72c93e681266977a0ec0f129ba6d&lt;/a >;&lt;/p>; &lt;p>;&lt;a href=&quot;https://preview.redd.it/i7i7bfhbg12b1.jpg?width=1213&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=5a287aba81199b66d1334457c6e8a12b3b5881c0&quot;>;https://预览。 redd.it/i7i7bfhbg12b1.jpg?width=1213&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=5a287aba81199b66d1334457c6e8a12b3b5881c0&lt;/a>;&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Singularian2501&quot;>; /u/Singularian2501 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rl3v9/r_gorilla_large_language_model_connected_with/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rl3v9/r_gorilla_large_language_model_connected_with/&quot;>;[评论]&lt;/a>;&lt;/span>; &lt;/td>;&lt;/tr>; /表>;</content><id> t3_13rl3v9 </id><media:thumbnail url="https://a.thumbs.redditmedia.com/pwokgMFTSRP9bRbBlTbOA1gPSTlPoECDQdwoNNPMuG0.jpg"></media:thumbnail><link href="https://www.reddit.com/r/MachineLearning/comments/13rl3v9/r_gorilla_large_language_model_connected_with/"/><updated> 2023-05-25T15:42:26+00:00</updated><published> 2023-05-25T15:42:26+00:00</published><title> [R] Gorilla: Large Language Model Connected with Massive APIs - Microsoft Research 2023 - 在编写 API 调用方面超越了 GPT-4 的性能。</title></entry><entry><author><name> /u/联邦任务</name><uri>https://www.reddit.com/user/fedetask </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我对变形金刚没有太多经验，但我的理解是让它们如此强大的主要特征是它们不在输入之间有一个&lt;em>;连续&lt;/em>;隐藏状态来维护，以及它们对离散标记进行操作的事实。&lt;/p>; &lt;p>;在 RNN 中，在每个新输入之后，模型产生的连续隐藏状态甚至可能有很小的“错误” （由于精度、模型权重的不完善等）并且没有机制强制此输出“退回”到它的“正确”价值。这个输出然后用于 RNN 的下一步，但是没有硬性保证 RNN 能够正确地解释它并且不会开始偏离正确的轨迹。当然，这就是训练的目的，但由于神经网络总是有点嘈杂，问题仍然存在。&lt;/p>; &lt;p>;另一方面，变形金刚没有连续的隐藏状态在每一步更新，并产生离散的令牌。如果模型为当前标记生成不完美的 logits，则相应的离散输出不太可能发生变化。这种机制使得任何足够小的错误都可以被“重新吸收”。由模型。出于同样的原因，我们可以通过为前面的步骤提供正确的值来安全地进行教师强制并为序列的每一步训练模型——不需要在训练期间进行自动回归——。 &lt;/p>; &lt;p>;例如，如果对连续值进行操作的转换器执行类似，我会感到惊讶。我希望当使用自动回归时，输出中的任何小错误都会在该输出用作下一个输入时使模型漂移，因为模型仅使用完美输入进行训练。 &lt;/p>; &lt;p>;Transformers 还有其他不错的特性，Attention 可能是最重要的，但我认为这才是真正让 Transformers 在 NLP 任务上表现出色的原因。&lt;/p>; &lt;p>;你同意吗？是否有任何工作与上述推理相矛盾？还是我错过了一些重要的东西？如果我上面说的是正确的，是否有任何工作将注意力集中在其他可能的“错误吸收”方法上？机制还是架构？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/fedetask&quot;>; /u/fedetask &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13ri6tc/d_transformers_are_so_effective_because_they_are/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13ri6tc/d_transformers_are_so_effective_because_they_are/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13ri6tc </id><link href="https://www.reddit.com/r/MachineLearning/comments/13ri6tc/d_transformers_are_so_effective_because_they_are/"/><updated> 2023-05-25T13:43:42+00:00</updated><published> 2023-05-25T13:43:42+00:00</published><title> [D] 变形金刚之所以如此有效，是因为它们是离散的</title></entry><entry><author><name>/u/内部-Industry758</name><uri> https://www.reddit.com/user/Internal-Industry758 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;如果你在没有在顶级会议上发表任何论文的情况下完成了博士学位，你现在在做什么？你仍然觉得博士学位值得吗？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Internal-Industry758&quot;>; /u/Internal-Industry758 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www. reddit.com/r/MachineLearning/comments/13rm0uf/d_phds_without_tiptier_publications_what_are_you/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rm0uf/d_phds_without_tiptier_publications_what_are_you/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rm0uf </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rm0uf/d_phds_without_tiptier_publications_what_are_you/"/><updated> 2023-05-25T16:18:09+00:00</updated><published> 2023-05-25T16:18:09+00:00</published><title> [D] 没有顶级出版物的博士：你现在在做什么？</title></entry><entry><author><name> /u/No-Economy-5418</name><uri> https://www.reddit.com/user/No-Economy-5418 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;嗨，我是一名博士研究员，致力于创造可以被视为深度假货的东西。目前，大多数 AI 都在大力推动开源代码。我一直在考虑如何将其应用于我的领域。我发表了一篇简短的文章，涵盖了我所看到的利弊 (&lt;a href=&quot;https://medium.com/@jacksaunders909/should-deepfakes-be-open-sourced-87d7644a0765&quot;>;https://medium. com/@jacksaunders909/should-deepfakes-be-open-sourced-87d7644a0765&lt;/a>;)，我很想听听其他人的意见。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/No-Economy-5418&quot;>; /u/No-Economy-5418 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https: //www.reddit.com/r/MachineLearning/comments/13rkrsp/d_should_deepfakes_be_opensourced/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rkrsp/d_should_deepfakes_be_opensourced/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rkrsp </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rkrsp/d_should_deepfakes_be_opensourced/"/><updated> 2023-05-25T15:28:53+00:00</updated><published> 2023-05-25T15:28:53+00:00</published><title> [D] Deepfakes 应该开源吗？</title></entry><entry><author><name> /u/waa007</name><uri> https://www.reddit.com/user/waa007 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;显然，lager model 的能力更强，但由于电脑成本昂贵，能参与的人很少。如果有一些研究可以让小模型变得更好，更多的开发人员可以参与进来，行业可以更快地改进。如果有类似的研究，能给个关键词吗？&lt;/p>; &lt;p>;还有，大有必要吗？也许LLM的必要性是暂时的，也许多年后小模型可以具有与LLM相同的能力？&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/waa007&quot;>; /u/waa007 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13rk5cq/d_is_there_some_research_about_improve_the/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rk5cq/d_is_there_some_research_about_improve_the/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rk5cq </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rk5cq/d_is_there_some_research_about_improve_the/"/><updated> 2023-05-25T15:03:46+00:00</updated><published> 2023-05-25T15:03:46+00:00</published><title> [D] 是否有提高小语言模型能力的研究？</title></entry><entry><author><name> /u/深渊</name><uri>https://www.reddit.com/user/abystoma </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;如标题所示，任何人都可以向我推荐论文或任何使用启发式方法预测隐藏神经元和输出层输出的资源，因为我们有一个数据集的输入和输出。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/abystoma&quot;>; /u/abystoma &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13r8gzk/d_has_there_been_any_work_done_to_predict_the/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13r8gzk/d_has_there_been_any_work_done_to_predict_the/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13r8gzk </id><link href="https://www.reddit.com/r/MachineLearning/comments/13r8gzk/d_has_there_been_any_work_done_to_predict_the/"/><updated> 2023-05-25T05:03:18+00:00</updated><published> 2023-05-25T05:03:18+00:00</published><title> [D] 是否有任何工作通过使用启发式来预测隐藏神经元和输出层的输出？</title></entry><entry><author><name> /u/Usual-Shopping-9638</name><uri> https://www.reddit.com/user/Usual-Shopping-9638 </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;&lt;strong>;论文&lt;/strong>;&lt;br/>; &lt;a href=&quot;https://arxiv.org/abs/2210.05409&quot;>;https ://arxiv.org/abs/2210.05409&lt;/a>;&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;&lt;strong>;代码&lt;/strong>;&lt;/p>; &lt;p>;&lt;a href =&quot;https://github.com/kakaobrain/leco&quot;>;https://github.com/kakaobrain/leco&lt;/a>;&lt;/p>; &lt;p>;&amp;#x200B;&lt;/p>; &lt;p>;&lt;strong >;Abstract&lt;/strong>;&lt;/p>; &lt;p>;Episodic count 已被广泛用于设计一种简单而有效的内在动机，用于具有稀疏奖励的强化学习。然而，在高维状态空间以及长时间内使用情节计数需要彻底的状态压缩和快速散列，这阻碍了在如此困难和复杂的探索环境中对其进行严格的利用。此外，情节计数中与任务无关的观察的干扰可能会导致其内在动机忽略与任务相关的重要状态变化，而情节方式的新颖性会导致反复重访熟悉的状态。为了解决这些问题，在本文中，我们提出了一种可学习的基于哈希的情节计数，我们将其命名为 LECO，它可以在困难的探索问题中作为特定于任务的内在奖励有效地执行。特别是，所提出的内在奖励包括情节新颖性和特定于任务的调制，其中前者使用矢量量化变分自编码器自动获取离散状态代码以进行快速计数，而后者通过学习调制器来优化情节新颖性任务特定的外在奖励。拟议的 LECO 特别允许在强化学习期间从探索到利用的自动过渡。我们通过实验表明，与以前的探索方法相比，LECO 成功解决了困难的探索问题，并且还通过 MiniGrid 和 DMLab 环境中最困难的任务扩展到大状态空间。&lt;/p>; &lt;/div>;&lt;!-- SC_ON -- >; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/Usual-Shopping-9638&quot;>; /u/Usual-Shopping-9638 &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https: //www.reddit.com/r/MachineLearning/comments/13rbch6/r_leco_learnable_episodic_count_for_taskspecific/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13rbch6/r_leco_learnable_episodic_count_for_taskspecific/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13rbch6 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13rbch6/r_leco_learnable_episodic_count_for_taskspecific/"/><updated> 2023-05-25T07:53:14+00:00</updated><published> 2023-05-25T07:53:14+00:00</published><title> [R] LECO：针对特定任务的内在奖励的可学习情节计数</title></entry><entry><author><name>/你/nicku_a</name><uri> https://www.reddit.com/user/nicku_a </uri></author><category label="r/MachineLearning" term="MachineLearning"></category><content type="html">&lt;!-- SC_OFF -->;&lt;div class=&quot;md&quot;>;&lt;p>;我们刚刚更新了 AgileRL，我们的强化学习训练框架比 SOTA 快 10 倍，支持离线强化学习！ &lt;/p>; &lt;p>;许多有 RL 可解决问题的人无法访问模拟器，但有大量数据。&lt;/p>; &lt;p>;您现在可以轻松地在静态数据上训练代理，而无需模拟，并使用进化超参数优化来更快更好地学习！&lt;/p>; &lt;p>;此版本包括：&lt;/p>; &lt;ul>; &lt;li>;新的通用离线 RL 训练功能，可从静态数据中学习&lt;/li >; &lt;li>;Conservative Q-Learning (CQL)&lt;/li>; &lt;li>;与 Minari 完全兼容&lt;/li>; &lt;/ul>; &lt;p>;查看：&lt;a href=&quot;https://github.com/ AgileRL/AgileRL&quot;>;https://github.com/AgileRL/AgileRL&lt;/a>; &lt;/p>; &lt;p>;如果你想参与这个项目，或者只是想进行讨论，请加入我们的discord （链接在我们的 GitHub 存储库顶部）！&lt;/p>; &lt;/div>;&lt;!-- SC_ON -->; &amp;#32;由&amp;#32;提交&lt;a href=&quot;https://www.reddit.com/user/nicku_a&quot;>; /u/nicku_a &lt;/a>; &lt;br/>; &lt;span>;&lt;a href=&quot;https://www.reddit.com/ r/MachineLearning/comments/13qgzt5/p_offline_reinforcement_learning_10x_faster_than/&quot;>;[链接]&lt;/a>;&lt;/span>; &amp;#32; &lt;span>;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/13qgzt5/p_offline_reinforcement_learning_10x_faster_than/&quot;>;[评论]&lt;/a>;&lt;/span>;</content><id> t3_13qgzt5 </id><link href="https://www.reddit.com/r/MachineLearning/comments/13qgzt5/p_offline_reinforcement_learning_10x_faster_than/"/><updated> 2023-05-24T09:48:18+00:00</updated><published> 2023-05-24T09:48:18+00:00</published><title> [P] 离线强化学习 - 比具有进化 HPO 的 SOTA 快 10 倍</title></entry></feed>